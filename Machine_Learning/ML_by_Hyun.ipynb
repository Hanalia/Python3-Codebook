{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_learning_part.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aFbtD4uKrv3W",
        "g2jrKBzK7PZ8",
        "NjwDM4deM1V2",
        "toTWwIKsx8Ri",
        "NPd69rTc0sJb",
        "cpKSYEZYFMgd",
        "XqbLGgCqTwr8",
        "aFNrbmwwWcMP",
        "gTEdK2mn6fBk",
        "q2Q_WkdOaHqF",
        "FA2eofXEHNw0",
        "hf88nypWNXlO",
        "f1bGuT7XK9Jt",
        "hVCisNbZ9AmF",
        "gOzO9VKj9E-G",
        "J1GrLsHa9M5_",
        "RVZGnPXmn0Gs",
        "592LBZFKoWHT",
        "oXCo6vcWv-EG",
        "GwMzfX66ndvT",
        "_niQacgbZPlF",
        "N6CvgUU5kkvX",
        "fv3aapPouXm4",
        "XBqhuEbnugFM",
        "u6Ppo8GhRaCU",
        "Zu2H3HlgR75L",
        "RiEMrXR5Rgzi",
        "fW4SD0goRir5",
        "3TEB4Gp9SKaK",
        "FEItOgFcS3Iq",
        "LkShFY26KE3e",
        "-sxs7kF6P0PE",
        "NkNfAwhWs9Ft"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fZgmZciDdxN",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "# ┗(•̀へ •́  )ﾉ  Hyun's Code collection \n",
        "----\n",
        "Authored by HyunWoo Jung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxeoB5YsDkK0",
        "colab_type": "text"
      },
      "source": [
        "# Machine learning description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMkljiUUC6EQ",
        "colab_type": "text"
      },
      "source": [
        "![123123](https://wordstream-files-prod.s3.amazonaws.com/s3fs-public/styles/simple_image/public/images/machine-learning1.png?SnePeroHk5B9yZaLY7peFkULrfW8Gtaf&itok=yjEJbEKD)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFbtD4uKrv3W",
        "colab_type": "text"
      },
      "source": [
        "# ┗(•̀へ •́  )ﾉ **이것만 돌리면 다 돌아간다~~~**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRO8gtPDrySn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 기본\n",
        "import numpy as np\n",
        "from numpy.linalg import inv\n",
        "from numpy.linalg import solve\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "from pandas import Series, DataFrame\n",
        "import pandas_profiling\n",
        "import openpyxl\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.dates import bytespdate2num\n",
        "import matplotlib.ticker as ticker\n",
        "from matplotlib import font_manager, rc\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        "\n",
        "import itertools\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# 시계열 데이터 처리\n",
        "import calendar\n",
        "import dateutil\n",
        "from dateutil.parser import parse\n",
        "import datetime\n",
        "\n",
        "# Network 분석\n",
        "import networkx as nx\n",
        "\n",
        "# 지도시각화\n",
        "import folium\n",
        "from folium import plugins\n",
        "import html\n",
        "import json\n",
        "import geopy\n",
        "from geopy.geocoders import Nominatim\n",
        "import os\n",
        "import requests\n",
        "import ipywidgets\n",
        "from IPython.display import Image\n",
        "from ipywidgets import interact\n",
        "\n",
        "# Clustering\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "\n",
        "# Factor analysis\n",
        "from factor_analyzer import FactorAnalyzer\n",
        "\n",
        "# Machine learning 용도\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
        "from sklearn.metrics import (roc_curve, auc, accuracy_score, roc_auc_score)\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.datasets import make_blobs\n",
        "import scipy.cluster.hierarchy as shc\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import classification_report\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
        "from lightgbm import LGBMClassifier, LGBMRegressor\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Wordcloud\n",
        "import konlpy\n",
        "from konlpy.tag import Okt\n",
        "import collections\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud, STOPWORDS as stopwords\n",
        "from PIL import Image, ImageFilter\n",
        "from wordcloud import ImageColorGenerator\n",
        "import pickle\n",
        "\n",
        "# 한글 사용하기\n",
        "import matplotlib.font_manager as fm\n",
        "from matplotlib import rc\n",
        "font_name = fm.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
        "rc('font', family=font_name)\n",
        "\n",
        "\n",
        "# 크롤링\n",
        "from selenium import webdriver\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 기타\n",
        "from urllib.request import urlopen\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "from zeep import Client\n",
        "\n",
        "from collections import namedtuple\n",
        "import sqlite3\n",
        "\n",
        "# 한 번에 matplotlib 그림 띄우기\n",
        "%matplotlib inline    \n",
        "%config InlineBackend.figure_format = 'retina'  #%matplotlib 뒤에 써주면 그래프를 더 높은 해상도로 보여줌\n",
        "\n",
        "# 설정 관련\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2jrKBzK7PZ8",
        "colab_type": "text"
      },
      "source": [
        "# 0. Machine learning: Linear model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pc99ussyDFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjwDM4deM1V2",
        "colab_type": "text"
      },
      "source": [
        "## >> K-fold cross validation\n",
        "\n",
        "`from sklearn.model_selection import KFold`\n",
        "\n",
        "- **KFold ( n_splits = , shuffle = True)**: KFold\n",
        "  - n_splits: 데이터를 몇 번 나눌꺼냐\n",
        "  - shuffle: 데이터를 나누기 전에 섞을건지"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i7AH_8bNYTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Kfold 예시1\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=10)\n",
        "lasso_regressor = Lasso()\n",
        "ridge_regressor = Ridge()\n",
        "\n",
        "lasso_mse = []\n",
        "ridge_mse = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    lasso_regressor.fit(X[train_index], y[train_index])\n",
        "    ridge_regressor.fit(X[train_index], y[train_index])\n",
        "    \n",
        "    lasso_mse.append(mean_squared_error(y[test_index], lasso_regressor.predict(X[test_index])))\n",
        "    ridge_mse.append(mean_squared_error(y[test_index], ridge_regressor.predict(X[test_index])))\n",
        "    \n",
        "sum(lasso_mse) / 10, sum(ridge_mse) / 10\n",
        "\n",
        "################################################################################################################\n",
        "\n",
        "# Kfold 예시2\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np \n",
        "\n",
        "lasso_regressor = Lasso(warm_start=False)\n",
        "ridge_regressor = Ridge()\n",
        "\n",
        "lasso_scores = cross_val_score(lasso_regressor, X, y, cv=10, \n",
        "                               scoring='neg_mean_squared_error')\n",
        "ridge_scores= cross_val_score(ridge_regressor, X, y, cv=10, \n",
        "                              scoring='neg_mean_squared_error')\n",
        "# cv: 몇 번 돌릴 것이냐. cross-validation, scoring: 점수를 측정하는 기준\n",
        "np.mean(lasso_scores), np.mean(ridge_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toTWwIKsx8Ri",
        "colab_type": "text"
      },
      "source": [
        "## >> Linear regression\n",
        "## Linear regression이란...\n",
        "- 선형회귀!\n",
        "- 가장 basic!\n",
        "- train data로 모델을 만들고, test data로 성능을 평가\n",
        "\n",
        "## 빈용 메소드 모음\n",
        "- **linear_model .LinearRegression ( fit_intercept = True , normalisze = True , copy_X = True , n_jobs = )**: 모델 만들어주기 \n",
        "  - fit_intercept: 상수항을 넣을지 말지\n",
        "  - normalize: 앞에서 scaling 해줬으면 굳이 또 안해줘도 됨\n",
        "  - n_jobs: CPU를 몇 개 쓸건지 지정할 수 있다\n",
        " - **linear_model .LinearRegression . fit ( X_train , y_train )**: fit 시켜주기\n",
        "   \n",
        "   **.coef_**: 계수를 반환   \n",
        "\n",
        "   **.intercept_**: y 절편을 반환\n",
        "   \n",
        "   **.predict ( X_test )**: : 예측하기\n",
        "- **mean_squared_error ( y_true , y_pred )**: MSE 추출하기\n",
        "- statsmodels를 이용해서 regression을 할 수도 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_k1yCotTCPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# statsmodels를 이용한 regression\n",
        "import statsmodels.api as sm\n",
        "model = sm.OLS(y_train, X_train)\n",
        "results = model.fit()\n",
        "results.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0Z5AwrhE6Za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normal equation 예시1\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lr_ne = LinearRegression(fit_intercept = True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)\n",
        "\n",
        "lr_ne.fit(X_train, y_train)\n",
        "\n",
        "y_hat = lr_ne.predict(X_test)\n",
        "y_true = y_test\n",
        "\n",
        "mse = sklearn.metris.mean_squared_error(y_hat, y_true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPd69rTc0sJb",
        "colab_type": "text"
      },
      "source": [
        "## >> GD, SGD, Ridge, Lasso\n",
        "\n",
        "## Gradient descent란...\n",
        "- 한 점에서 내려가면서 기존 값에서 계속 업데이트 해주면서 새로운 값을 적용해 최소값을 찾아내는 것\n",
        "\n",
        "## Stodchastic gradient descent란...\n",
        "- Gradient descent는 한 점을 잡고 그 점에서 내려가서 최소값을 찾는 방법이다.\n",
        "- 반면 Stochastic gradient descent는 x의 값을 돌아가면서 gradient를 구해서 지역 최적화에 빠지는 것을 최소화 한다.\n",
        "\n",
        "\n",
        "## **정규화를 쓰는 이유는 overfitting을 방지하기 위함이다.**\n",
        "## Ridge\n",
        "- regularization에서 L2 방법을 쓰는 것\n",
        "- Parameter를 제곱함으로써 정규화시킨다.\n",
        "\n",
        "## Lasso\n",
        "- regularization에서 L1 방법을 쓰는 것\n",
        "- Parameter에 절대값을 취함으로써 정규화시킨다.\n",
        "- Lasso를 쓰면 feature selection이 가능하다.\n",
        "\n",
        "## 빈용 메소드 모음\n",
        "- **linear_model .SGDRegressor ( n_iter = , loss = ’squared_loss ’, penalty = ’l2 ’,  alpha = 0.0001 , l1_ratio = 0.15 , fit_intercept = True , max_iter = 1000 , tol = 0.001 , shuffle = True , verbose = 0 , epsilon = 0.1 , random_state = None , learning_rate = ’optimal ’ , eta0 = 0.01 , power_t = 0.25 , early_stopping = False , validation_fraction = 0.1 , n_iter_no_change = 5 , warm_start = False , average = False )**: Stochastic gradient descent\n",
        "  - loss function: squared loss를 기본적으로 사용하면 된다.\n",
        "  - penalty: regularization 방법. L1, L2, elastic net\n",
        "  - alpha: L2 앞에 람다 값을 얼마로 설정해줄까. 이 값이 크면 클수록 regularization이 많이 되기 때문에 학습 데이터 값이 줄어든다.\n",
        "  - max_iter: number of epoch. epoch을 몇 번 돌껀가\n",
        "  - tol: 멈추는 기준\n",
        "  - shutffle: SGD이기 때문에 섞는다. False로 하면 Batch gradient descent가 되는 것\n",
        "  - learning_rate: 돌아갈 때마다 일정량 줄어들게 되는 것. 줄어드는 전략은 3개의 전략! constant, optimal, invscaling\n",
        "  - eta0: learning rate을 지정. 학습속도를 빠르게 하려면 eta를 올려주면 됨. \n",
        "  - warm_start: 잘 안 쓰기는 하는데 weight의 초기값을 지정해줄 수 있다. 초기값을 기반으로 예측!\n",
        "\n",
        "- **linear_model .LinearRegressionGD ( eta0 = , epochs = , batch-size = , shuffle = )**: gradient descent 만들기\n",
        "  - eta0: learning rate\n",
        "- 예시)\n",
        "\n",
        "  **linear_model .LinearRegressionGD ( eta0 = 0.001 , epochs = 10000 , batch-size = 1 , shuffle = False)**: Gradient descent\n",
        "  \n",
        "  **linear_model .LinearRegressionGD ( eta0 = 0.001 , epochs = 10000 , batch-size = len(X) , shuffle = False)**: Batch gradient descent\n",
        "  \n",
        "  **linear_model .LinearRegressionGD ( eta0 = 0.001 , epochs = 10000 , batch-size = 1 , shuffle = True)**: Stochasic gradient descent\n",
        "  \n",
        "  **linear_model .LinearRegressionGD ( eta0 = 0.001 , epochs = 10000 , batch-size = 100 , shuffle = True)**: Mini-batch stochasic gradient descent\n",
        "  \n",
        "- **linear_model .Lasso ( alpha = 1.0, fit_intercept = True , normalize = False , precompute = False , copy_X = True , max_iter = 1000 , tol = 0.0001 , warm_start = False , positive = False , random_state = None , selection = ’cyclic ’)**: Lasso\n",
        "\n",
        "- **linear_model.Ridge ( alpha = 1.0 , fit_intercept = True , normalize = False , copy_X = True , max_iter = None , tol = 0.001 , solver = ’auto ’, random_state = None )**: Ridge\n",
        "  - solver: auto로 하면 데이터를 보고서 fitting을 할 때 어떤 알고리즘을(normal equation, SGD) 알아서 찾아준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLaZOHneYIit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lasso 예시1\n",
        "ridge_reg = Ridge(alpha=1, solver=\"sag\", random_state=42)\n",
        "ridge_reg.fit(X, y)\n",
        "ridge_reg.predict([[1.5]])\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
        "elastic_net.fit(X, y)\n",
        "elastic_net.predict([[1.5]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSPI9HdpXsat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ridge 예시1\n",
        "ridge_reg = Ridge(alpha=1, solver=\"cholesky\", random_state=42)\n",
        "ridge_reg.fit(X, y)\n",
        "ridge_reg.predict([[1.5]])\n",
        "\n",
        "ridge_reg = Ridge(alpha=1, solver=\"sag\", random_state=42)\n",
        "ridge_reg.fit(X, y)\n",
        "ridge_reg.predict([[1.5]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBvFAocp0sRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 기본 Code\n",
        "for epoch in range(epoches):\n",
        "  X_copy = np.copy(X)\n",
        "  if is_SGD:\n",
        "    np.random.shuffle(X_copy)\n",
        "  batch = len(X_copy) // BATCH_SIZE\n",
        "  for batch_count in range(batch):\n",
        "    X_batch = np.copy(\n",
        "    X_copy[batch_count*BATCH_SIZE : (batch_count+1)*BATCH_SIZE])\n",
        "    # Do weight Update\n",
        "  print(\"Number of epoch : {}\".format(epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-6-RgkQKOxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stochastic gradient descent 예시1\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "lr_SGD = SGDRegressor()\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "std_scaler = StandardScaler()\n",
        "std_scaler.fit(X)\n",
        "X_scaled = std_scaler.transform(X)\n",
        "\n",
        "from sklearn.mode_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)\n",
        "\n",
        "lr_SGD.fit(X_train, y_train)\n",
        "\n",
        "y_hat = lr_SGD.predict(X_test)\n",
        "y_true = y_test\n",
        "\n",
        "mse = sklearn.metrics.mean_squared_error(y_hat, y_true)\n",
        "rmse = np.sqrt((((y_hat - y_true)**2).sum() / len(y_true)))\n",
        "# rmse값이 엄청나게 커졌다는 것은 학습이 잘 안 되었다는 뜻! learning rate이 너무 크다거나 충분히 돌지 못했을 때 발생\n",
        "\n",
        "# scaled된 data로 돌리면\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.33, random_state=42)\n",
        "\n",
        "lr_SGD.fit(X_train, y_train)\n",
        "\n",
        "y_hat = lr_SGD.predict(X_test)\n",
        "y_true = y_test\n",
        "\n",
        "mse = sklearn.metrics.mean_squared_error(y_hat, y_true)\n",
        "rmse = np.sqrt((((y_hat - y_true)**2).sum() / len(y_true)))\n",
        "# rmse값이 안정적으로 나오게 된다. 즉 SGD regression을 할 때는 반드시 scaling을 해야 한다!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpKSYEZYFMgd",
        "colab_type": "text"
      },
      "source": [
        "## >> Polynomial regression\n",
        "\n",
        "## Polynomial regression이란.....??\n",
        "- 1차식이 아닌 다항식! 비선형 관계 예측에 용이!\n",
        "\n",
        "## 빈용 메소드 모음\n",
        "- **PolynomialFeatures ( degree = )**: polynomial feature 만들어주기. degree가 2이면 제곱항까지 만들어줄 것을 의미\n",
        "- **PolynomialFeatures .fit_transform ( 데이터 )**: polynomial feature로 바꿔주기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bkc3rbdFYQm",
        "colab_type": "code",
        "outputId": "8eb78638-1f21-48d8-ae3c-3edf036f9bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# 예시1 \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def f(size):\n",
        "    x = np.linspace(0, 5, size)\n",
        "    y = x * np.sin(x ** 2) + 1\n",
        "    return (x,y)\n",
        "\n",
        "def sample(size):\n",
        "    x = np.linspace(0, 5, size)\n",
        "    y = x * np.sin(x ** 2) + 1 + np.random.randn(x.size)*0.5\n",
        "    return (x,y)\n",
        "  \n",
        "  \n",
        "\n",
        "f_x, f_y = f(1000)\n",
        "plt.plot(f_x, f_y)\n",
        "X, y = sample(1000)\n",
        "plt.scatter(X, y, s=3, c=\"black\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0tgjIirzD4wTPeHi/8qhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOD2wfd_FYZg",
        "colab_type": "code",
        "outputId": "d1e68ea9-7fb1-47c6-8a5e-d3771e2fd6d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# 예시1 \n",
        "X = X.reshape(-1,1)\n",
        "y = y.reshape(-1,1)\n",
        "X.shape, y.shape\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X,y)\n",
        "\n",
        "f_x, f_y = f(1000)\n",
        "plt.plot(f_x, f_y)\n",
        "plt.scatter(X.flatten(), y.flatten(), s=3, c=\"black\")\n",
        "plt.plot(X.flatten(), lr.predict(X).flatten())\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXd4U9Ubx7+3SUfa0iZllNKbhKEM\nAUVlOKEoTnCAilZaRfwFqIo4oAGBIEFGcaGChYShVCwKgmBEHGAdqGhFVGQIMstqobt0Ju/vj3BD\nmiZpxs0q9/M894Em957z3nNv3vOe97znPQwRQUBAQECg5RAWaAEEBAQEBPhFUOwCAgICLQxBsQsI\nCAi0MATFLiAgINDCEBS7gICAQAtDUOwCAgICLQxBsQsICAi0MATFLiAgINDCEBS7gICAQAtDHIhK\n27RpQx07dgxE1QICAgIhy++//36WiNo2d15AFHvHjh2Rn58fiKoFBAQEQhaGYY66cp7gihEQEBBo\nYQiKXUBAQKCFISh2AQEBgRaGoNgFBAQEWhiCYhcQEBBoYQiKXUBAQKCFISh2AQEBgRYGL4qdYRgp\nwzDrGIbZxzDMXoZhruejXAEBAQEB9+HLYn8LwBYi6g7gKgB7eSpXQEBAgBf0ej3kcjn0en2gRfE5\nXit2hmHiAQwEsBwAiKiOiEq9LVdAQECAT7RaLQoKCpCRkYH09PQWreT5sNg7ASgCsJJhmD8YhlnG\nMEyM7UkMw4xlGCafYZj8oqIiHqoVEBAQcB2NRgORSASj0Yjc3FwUFBRAq9UGWiyfwIdiFwO4BkA2\nEV0NoArAFNuTiEhHRH2JqG/bts3msBEQEBDgFZVKhezsbLAsi9TUVLAsC41GE2ixfAIfir0AQAER\n7bjw9zqYFb2AgEALJJR91SqVCsePH8fAgQMDLYpP8VqxE9FpAMcZhul24aNbAezxtlwBAYHgxNpX\nHWrKneuU1Gq1xRUTyh2VIxgi8r4QhukDYBmACACHADxBRCWOzu/bty8JaXsFBEITvV6PjIwMGI1G\nsCyL48ePB1okl5HL5SgoKIBUKkVsbCw0Go2lowqFe2EY5nci6tvcebyEOxLRrgv+8yuJ6H5nSl1A\nQCC0sfZVh5qPWqPRgGVZDBs2zPJZSkoKRCIRUlJSAicYz/BisbuLYLELCAgECtsRBwDBYhcQEBAI\nNaz96FqtFkaj0WKlV1ZWQiaThdzowxmCxS4gINDi4XzrLMtiwK3D8N25GPTpEIN9m1eEjLUOCBa7\ngICAgAXOtz5thga/Sa5FTM/BOCDrj1GT5oTkXEFzCIpdQECgxcPFryf1vxtMfBJMP+ghFTfgUOTl\nOH78OFQqVaBF5BVBsQsICFwyfLLzBBQJ0TjywwaMv60Xfj1SjKPnqgItFu8Iil1AQMBjQmlxT029\nET8dKMSR7Z9h+fJlKP/nOwDAnJWfBlgy/hEUu4CAgMdwi3uCeQUnJ9esd1ejgRgU7f4eGRkZmD99\nEupLTuLLXUcDLSLvCIpdQEDAY7hJSesVnMGWMZGTa/XW3yECoeHEHhiNRtTU1KDuxF5EJHWDThec\nnZKnCIpdQEDAY7hJSZVK1UjJBxOcXB2vGYTechnefectsCyLqKgo1Jz8F/WiKMx+/Z2g7JQ8RVDs\nAgICHmHrerFW8sGESqXC0aPHUEIx6J0cb5EzKysLUlMZAGDk+MlB2Sl5iqDYBQQEPCJYXS/2OFZ8\nHhW1DeiVHGf5TKVS4cBveRCHMThVGx5A6fhHUOwCAgIeEayuF3v8fcJsmffsEN/o86hwES5rF4vt\n/xwJmU7KFQTFLiAg4BHB6nqxRa/X4+lpcxEGQtfEVpbPZDIZEhISwFQUIkHZI2Q6KVcQFLuAgIDH\nWPvZgzXcUavVojo8DrXFJ/H+yuWWz0pLS1FSUoIdX29ESX0YECYOsKT8ISh2AQEfEKxKzlNsFThn\n7U7RzMaJwnPQarVBu7OSRqNBREIy6s9ddLVoNBpIpVIwDIPas8cBJgxnzptajCtGyO4oIOADrLMJ\nhkLWwOawvh/AnL88/sZHEX/jI0BDHa4oz8cv65agrKwMRBRU9200EbpO+xznd21G7Y41yMrKsriP\n9Ho9tIveg+iul2D8fik0T9wT1K4lIbujgEAACaWJRVfg7ofLXy7pej2kNz2KhkO/oU+nROyJ749K\nigSAoMttfrK0GkZicP70YZSUlDS1ysvPAACYuMQASOcbBMUuIOADQmVi0VW4+8nLy0NpWTlaDx4D\nKinA4Kgj2Pl2BkSiMMTfmArOAxBM933orDnJV+1Z8wjCegs8rVaLgiP/wVhZjPOimKBzI3mKoNgF\nBARcQq/Xo7KyEm163QSRNAmLn74H3+V9i4IDu1H2xxbE9BiIsKhYBMK964xDRZUAAFPZaQBAXl6e\n5TtuJCINN0Ecnwij0dgi/OyCYhcQ4JmWNnHKwUWSSHreAml0OG67ItHicqn480sw4ggkXzcMCxYs\nCLCkjTl8tgqtIsVY9Nq8Ju4xbiQyuP+VaN/5ihbjPhMUu4AAz4RCxkNP0Gg0YJWdIVJcjeI/vsKq\nlSugUqmQlpaGhqIjMJadQdfBDwaVGwYwK/aObWIwdqxj91iyTIJKUziOHD0WdPJ7gqDYBQR4JhQy\nHnqCSqXCys0/gRgRiv74xnJPOTk5SE5ORtWBX3CgPAzn6xoCLGljTpRWg5VJnHayrEyCBhOhsKIm\nABLyj6DYBQR4glMcAII+46GnTH83F6a6aoSdO9zonjQaDWLKDoMRR2DH4eIAStgYIsLJ0mokSyVO\nO9lkqQQAcKKk2t8i+gRBsQsI8ISt4khPT0dGRgZSUlJaxPAeAAoaWqHmyC7UVlc1jgXXajHlfw9D\nHMZAv2Fb0LifiqvqUFNvQrJM4rSTZWVmxV4gKHYBAQFruNWMVVVV0Ov1yM3NhdFoRG5ubqBF44Uz\n5TUQS9uj7sQepKamWj7nOrT5r8xCz+R4bP/3dNC4n06UmhV1slTiNAQ1WRrd6PxQR1DsAgI8oVKp\nEBsba1kEk5qaCpFI1EgJhiKciylr+VoAwHfrViAnJ8fyvbUlHFVeALTuCFmbdtBoNAGfPOZcKx0u\nuFocIYkQoXVMBL75eWfQjDa8goh4OQCIAPwBwNDcuddeey0JCLREdDodsSxLOp3Opc9DAZZlCQDJ\n73uBuk//guoajI7PvX4YKdUGYq+6qdG1LMv6S1wLOp2O5EMeJ6XaQCVVtc2ef+87P5AiPStg8roC\ngHxyQR/zabFPBLCXx/IEBIIeVy3SUI6O4SzyDlfdhD5yKcJFZrVhnQyMu/9n04YDAIamjW90bSAm\nj7VaLSopAqa6anz8wfsOz+OeYcGB3TBJpEGXEsEjXNH+zR0AWABbAdwCwWIXuISwtUgdWaihbLET\nEVXV1lPnqZ/Ta1/us3zG3av1/ZpMJuo2dRPJR2QG/F51Oh21HT6NksYsJqlU6vA87j4SbhtP7MQ1\nQWutE/nfYl8IIBOAydEJDMOMZRgmn2GY/KKiIp6qFRAILNbJseRyOVJSUuxaqNzEHYCQ8uFa/OtL\nP4DRRLiSlVq+4yaLrS1chmFQffIA6mPaB3x0olKpEJmQhIbyQjAM4/A87hn27iKHKCoWU6fP9KOU\nPsIV7e/sADAMwLsX/p8CwWIXuMTQ6XQkEokaWa5paWkkEokoLS2t0bmB9Dl7glQqJQDU6pqhpFQb\n6ETJect3jkYhD81dQ4oX19OSpYEfnXSZ9Am1vuPpJs/BHuvyj5NSbaAjZyv9IJlnwI8W+40A7mUY\n5giANQBuYRjmAx7KFRAICbRaLYxGIxiGuRjq+PE6QBLfJNTRNiQy2OEs3fB2nUE1lUiKj7J85yh1\nwiN33AhGHIGUex8JlNgAgPN1DWgQRaK+9EyjxF+O+P3HrQCAZavX+Vgy3+O1YieiqUTEElFHAI8A\n2EZEaV5LJiAQIqSkpEAkEkEikaCkvALqD38C+2wu2KdXoctzH2Lr3jOWc21DIoOdrKwsSKVSRHfo\nChkqoVAokJ6e3sTtZK3k9/70NQDgWU1WUIQ6xosbXJoMzdEtBgAsXPpeSHS6zhDi2AUEvCQvLw9G\noxERURK0GzEdcQMehOnYTtzephQ15cV48r3f0K7fUEv0SCilGVCpVJiXtQBhCSxO/rMDBQUFWL16\nNQoKCpCXl9ckdUJKSgpmvpABMhnx2/7jAY0EOl1uzvuyLme5Syt/MyeMBQAwMdKQ6HSdwatiJ6I8\nIhrGZ5kCAsEOZ7H3SH0Jks59YfrlA8wYIsfaOc/g+MrnUHP8b0QNfBKVojio1eqQ24RjzqIVYETh\nqDqxHwAQFRXlMP1tXl4ejPW1aCg9jU59rg9oB1ZUUQsAeODuIS5Z4M+MexJixgRpe2VIdLrOECx2\nAQEvycvLgzipO07GdsPoGzriWF4uVCoVGIYBNdSiaGMWqL4GCbc/BSIK+GpMdxk++mkAQH3hYYhE\nIrz11lsOOybOcr+CTQAT197fojaCU+wn/tvrkgXOMAySE2Jxf+rjIdPpOkJQ7AICXjJ9hgaJdz2N\nOHED1Hd2t3yelZUFkUgE0/ky1P62FlHynhijeTvkFiuxV/RFGAiJ0Qyys7OdKj3Ocr+1Xy8U1TAo\nOHEyYPdZVFGLcMaE5MQ2Llvgia2icKY89FP3CopdQMBL2va9C0yCAnMe6gdJhMjyuUqlQnZ2NliW\nxewn7kbH1tH4V9wJM2aEjo8dAA4UVqJzu1Y4fuyoy5Zsl7YxYERisN37BM4VU1mLDgmxlsldV0ZI\n7eIicaCgMKRGVPYQFLuAgBeYTITsvP/QvX0rDLsyqcn3nAU7bqwK4wd1wd8nynDlkBEhtVjpYGEl\nxFVFbsl6WbtYAMCKdZsD5tYoqqhF29hIt0ZIiXFROFdtDKkRlT0ExR7ChJqvtiWydV8hDhRWIiOl\niyXm2/q5WP//vj7JaBUpxse/mZV6KLhkahuMOHquCnt+2eaWrF0uKPaDhZW+FM8p/x47jd9+2Opw\nNbA92rWKBCOOBNuxS8iMqOwhKPYQxp5iEJQ9vzhrT71ej/9lrUKcuAFDe1+01q2fi/X/JREi3NOn\nAzbvPoV3lixDZWVl0CecOny2CiYCRtzqXoRLXFQ42sRG4vDZwCn2ospaVBSdbBSW2RytYyMBAD/m\n/xnSE6iCYg9h7MVDO7ICBYXvGc7a86lMDZikK1D4y0asXLHc0r7Wz8V6pWl6ejp06tGoqTfhlVWb\nUVpaipiYmKBWIAfOmBXzJysXQ6PRuCWrsnU0jp477yvRnFLbYAQTGYtYsdGtjrNNbAQA4Gxlra9E\n8w+u5B3g+xByxfgOR/k7Qi1HSbBgrz253DDxN6eRYvJGim0nd9q+3HcMwxAA6jBWRx0enRsS2R5f\n/2o/KSZvIojC3X53hs3+mBTPrArIPZ4oOU9KtYFydxx167q/C0pJqTbQlt2nfCSZdyAA+dgFggBH\ni19CabVjMGGvPdVqNYwmQmzvIag+vBPiugqn7ct9JxaLAQDn//0ZEWwvINz5rj7BwMHCCiREmsAm\nJbr17uj1evywZQMQLYV66jQfSuig/pyPAAA7f8pz67o2F1wxoW6xC4r9EiHUVjsGMzU1NYiU94S4\nVRtEnvwDCxYscJqWl/suNtY8oSg++TeICUNJNBvUE6eAefLz2suS3X53tFotGkpPg2HCwLRq40MJ\n7bNs9ccAgNyVS926LiHG7Io5V1nHu0z+RFDsLRRvfOqCP945kZGRiOk+EFRfg3+/XQ+VSmVpM7Va\n7TB6JCsrCyzLYs6LYxErMqL1lYODegRVbzTh8NkqXJ4Y6/a1Go0GUQ1m//z/Jk7hW7RmueehUQCA\n58aPceu6CHEY4iXhgsUuEJw0N4nKZeizp7xDIQwvkMzPWoDYHjehp4wsC5K4NiMihy4ZLlnW7Nla\ndI6uhbTbAJgoeGPZC0qqUW8kdG4T49H1EqNZsffodzOfYrlE9z79AQATVE+4dZ1er0fp6eP47a99\nvhDLbwiKPURpzqp25PPlFFBubq5D5S344xtj29ZHqyPARLVCj5hqyzlcmy1YsMCp24Jr/11ffIiy\n6nq88u6qoO1Ej5yrAgB09ECxa7VaFBzcC6qvwdFi/0fGFFXUQhJmRJdOSrc6Ta1Wi9qyIuw5dNyH\n0vkBV2ZY+T6EqBjvcRaF4SgyRqfTkVQqJZlMRmlpaZZzuM8lEgnJZLKgj9TwN7ZtLR+hJvnza4lV\ndnJ7L1Pu/IXZy6jjFAM9lvVhUEbH6HQ6kt+SRkq1gc6UV3t0Pcuy1OOFD6jDw1q/vlc6nY4UqVpi\nVUvcjgTT6XSkeGQWXTN9gw8l9By4GBUjKPYQxZlCcaT0m/scNhsTC5jh2jotLY2kMhnJn/2QOjww\nzfI5ABKJRG4pLp1OR4r/LaabZn7iQ8k9h2VZkt3yP1K8sI5MJpPb13Nt0/5BDSU9udiv7xXLspQ4\nagElj5rvUac549O/6cqXv/SRdN7hqmIXXDEhirMoF9sNlrmhKJc3PCUlpcn53HJ4hmEEFwwau1+s\nc42flyQiTBIH0el/LD5zkUgEo9Focac05ybT6/XIyMhA+b87cOy8GJW1Df68NZfQaDSQtFPAVF6I\nZcuWuX0953KqLT4BcXx7MEyY394rjUaD8FatYaouc3tRFQAc2fc3yqrrsUQXfPMeLuOK9uf7ECx2\n32Ftydta6J64by5V7LWVTqejxNtUpJi8kR5Of+KiFX/BvcW1naN25tpYJpMRAIrudA0p1QbK21/o\n13tzFcV4PbW9/yWPLG3uXm8Z9zIp1QZ66LH/+e39WrpUR/IX1pF08BiPZJenpJJSbSD28l4+kM47\nILhiLh0cKXNrF4L1v+76g929riXgqKO7483vaOSSnxq5YBy1N3etrUKXSqXEsiwtWqKnzlM/p0fn\n5wZd+xqNJuqYuZFkg8dQdHS0x7J9s+e0WUledbPf3DFsx8tIqTZQ/IAHPJL7hTdWkVJtoFnvrORf\nOC8RFPslhD1lbv1Ce5pOwJ7yupR58PGxpFQbKGX8bLtKvLk5DE6hWz+b6zTrqf2j84Kufbkl+bF9\n7vJKtr2nykipNtBzb6zyW+c1b9FyUqoNNOH1HI+uzz9yjpRqA3277wzPknmPq4pd8LGHEI58t9bh\nifZWQFonouKuTU9Ph1gsRnp6usP6uHJTU1Pt+uxbOrbpd7f8VQAA+HndRb97Tk5Okw2dbX3JzkIh\nj+RvQ3j7rmDE4UEzt6HX6zHgVvPWxZH15V5loOwgNadN6H7NDX5b+Tz4rvsAACPvudOj67d+/ikA\n4BPDV7zJ5Hdc0f58H5eKxc6337o5y9u6PqlUarES7V3LWeEMwzTyETtzv1xqPnrr+2VZlto9+DJ1\nUOloVFoab3W0uXoIKdUGatXpqqBpP5ZlKfbK20mpNlCCoqvXMnWduonaD33WbyGPn/15wuz+6dnf\no/rYjl1IqTaQ/LYnfCCdd0BwxQQeT10gzuLQrWPPbf241i4Tzp8rk8nslpmWlkYikYiio6MbhTna\nZiLkOgZHctn6j4PJneAt1ve7eImOFJM20INz1/BaxxvvLiOl2kBxAx5w6K7xNzqdjmQpo0kxaQOB\nCfP6mSrGLqG2I2b47f1Y8eMhUqoNFCaJ86i+pUt1pHhxPY3k+VnzgaDY/YwzpedufLMrPm1HES9c\nPLUrddtbmMQp/IiIiEYdQ3NyBINC8iXf7S/k1e9qvViMHaentiOmk0gkCpoO8k7tWmLH6Xmxsm+d\ntY7YJxf7zWLP+mIvdVJ/Riwr97i+6+Z+Qy9+vItnybxHUOx+xlPr3BprpW674MVaEVivFrV1oTjr\nWOobjHS4qJK2Hyiib/acJvb6YRSp6E2RbRW0ZGnjUD2GYZr9IdrK0JKZ8/keuvylzXS+toGX8qwX\nhSUNn0KKCR+43CH7Gp1OR+yYRZScOocXOaZv+Jt6z9zCg2SuMenjXTRgzjdeldF/xnpSjJobdO+1\noNj9DB8/SGdK1VoR2Frp1ufrdDqSSCTEMAxFx7aiqI59KGHwGLpOs54ue+lzUqoNdg/5C5/QwJmf\nkGrBagpv1dqlTsq2MwsGpeQr7lz4PT2y9GfL397eq/Vz6jXiGVKqDfTau8t4KdtbWJYl+XMfkWzI\nOF5GDtl5B0mpNlB5dR0P0jXP4yt20LC3f/CqDMVjC6h9+msBHznZIij2IKS5H6ytv9rarSKVSkks\nFpsXtlyIK7a28Dl3iEgkooikrpRwWwaxE1aTUm0gxaQNlJS2gOTDnqGnX8uh7QeLiL3yRgpv15ki\nFb0pptctJLtVRYpxS0mpNlDHzI3U5u7n6NpBd9qNx3b0Nx+jlmCksLyGlGoDLdp2gNc5Ba69JGwP\n82TfdcMafR6odlyYbfb7J978CC+dy8Zd5snMfafKeZCuee5+63t6YuWvHl+v0+koacRLJB+/POiM\nFL8pdgByAN8C2APgHwATm7sm1BW7OxaVs5Wgzq7hFDanrDlFzylxzkq3rHxMaEOyq4ZQ+7TXLBb4\ntRMWU9s+txIjjmxk7Vv71rmDs/gPnKkg+fBJJH9hHSle3EDSm9OJVXQkIuf+9Jbslvn0jwJSqg30\n5/ESXucUuHfi0bTHSDF5I6XOyw2Kdvz9aDEp1Qb6+p/TvJSXf8Rc3uQ33/fLSKTfK19T5to/Pb6e\nZVmS3TqW5BPXBN277E/FngTgmgv/bwXgXwBXOLuGb8Xu76GrOxZVc4uHHGEbtSISiSxKnItYAUCs\nXE4f/3aMbpi3lZRqA3VQ6ajVNcPonSV6i5LgzudGALZhfLb3otPpiL28J/WbsIiUagP1m7GBDpwp\ndziicLdNQo0XP95F3aduIlYu99kq3AGa9aR4/LWgmDzdsNPckR04w4+Ffaq02mxsDH7U5/fWYDRR\n56mf06tb9nlchk6nI+mNF9IKyBU8Suc9AXPFANgI4DZn5/Ct2P2tVDy12N0p23r5ua0FxynsNr0H\nUr8ZG0ipNtC97/xAk998n0QicROlbWtdOgubtCXzzfdJ/uyHJH9+HbW9MqWJC6il+9dNJhMNmPMN\nyR+Z5dN3TD58Msmf+4ikUllA21Gn01HiLaNJkbmJ3l3CjwxGo4kue+lzemSe71MnFFWY3WbvbT/s\nVTnjXv2AlGoDvXFh3iNYCIhiB9ARwDEAcc7O41uxc9ZtWlpaSCoYe+4aa2XMKXmGYUin09HfBaX0\nqP5nUqoNdHPWNvrszxOW1Kr2lLZt7vXmYuSt/5bJZCSKTaD2j71Jiskbqe119ztcwNQSmbtoBSnV\nBup9/3gSiUQ0YMAAn9z306/lkFJtoLmLVvBarrvIZDJqPfQFSs5YwWsndlPWVprw4U7eynPEnpPm\nFAaf/3XSq3IMf54kpdpAe0+V8SQZP/hdsQOIBfA7gBEOvh8LIB9AvkLB7/CmOdeCL+EzGsba/21t\noXOrSMXxiSQfqTFPiE7MJdWrqyl7qfNEXbbWtW28uz0ZrP/mRgzRcTLqkDrHnD/kqjtapMvFGu65\nJt78MCnVBhLFtfNp3pz9p8tJqTbQuvzjvJbrLlKplBJHLaDEVH5D/R5e+hONeHc7b+U5gltv8Ovh\nc16Vs/1gkdkVc+0tQWW8+FWxAwgH8CWAF1w535c+dnfcDHzgSUfiyDrmlLOtn3Vhtp7a3/kUKSZt\noC5TNpF86NPEREQTy7IWpW8bCsmVaxsXb8+Nwp3rLC5ep9ORNKENtR+pJUXmJrpdNa1ROwd6wo9v\nuOfafuQs6qDSNZrn8MU71WA0UffpX9DLm3bzWq676HQ6Ujz7Id37yke8lvv8R3/QdXO9iy13hXX5\nx0mpNtDhokqvytl3ytzRRne7MaiMGH9OnjIAVgFY6Oo1/oqK8dR696UP3Zlctm6YxUt0lJ13kHrN\n3EKdphgoc+2fdKq0ulFHYD2R6sgKt7fYyZ7MztrLEkcvCqfktCxSTNpAkWxPi6z2OpZQRqfTEatQ\nkuKFdZRwW4bbOyR5Up9izNt0c4B3VKqoqSel2kCLvz3Aa7mPzsslxeSNNCot3afGFhczX1lT71U5\nZ8ovTvgGk7HiT8V+04Uf9V8Adl047nZ2jb8Uu7Xv3RX4jFF2pR5ba5ezBpcs1dHa/OPUe9qnpFQb\n6NZZ6ywxwNbnW/ve7VnLjupx9KI6ay+uE4mOjiZZYjJ1+F82sRNWU4KiW4uz2Ll2m/7We5b4cl/f\nF8uylHD7UyR/7iNaujRwbTj7HfOcwvNvrOK13HY3PEBKtYHELi5+8xTtZ//QFTO+8LqcugYjKdUG\neuubf3mQij+EBUrkWh6T5iYuHcGXm8fW2s3bX0h3vPmd2Y/+v0UUKe/dSD5OmbsbS21djyML3rZD\ns9c23N8Jim6kmLiG+k7fwNsy+2DB8h7cnEaKyZvo7Wy9T+vjOsbYPneaO5LufXxanzPY6+8xy9D7\net7K1Ol0JLmsPynVBopI6uozA0Cn05H8YQ31mf4pL+X1mrmFZm4MrGvMlktCsTenXG3juJ25GFyJ\nM3ek6LyRn1so1KZbXxo48xOzQn9qJT33xioaZWVB205muvvjcNYWjjo0R3Vy9z9l4fukVBtoyid/\nNXIP2ZMvlKKVuHmI9umvUfu015pNhOYtXDu3vty8Vd4LPFvL7vBE1oekVBt47cxYlqXwdp3MPuuu\nN/jMrcWyLCU+MocUT7zJS3l9pn9K8oc1QfXOXhKK3RXl6sjPzOGOwnFHubpSrkwmo/A2Cmo7fBop\n1Qa64qWNFNf3HoJI3GjFKacwnbmVXL0Pe+c5m3yWSCRN/OfW7T538x6zhXfDvU1Wx9obaYSKD/7t\nbD0pJm+k+JvTGqUu9gVcGy1eogv4VnlTPvmLrtZ+xWtHrNPpiO3SzbxdXd/7fPYe6HQ6UozX0x3a\ntbyUpxjzNrUbqQ2qd7blKvbCfbRu8cvUWx5PifESSpBJfe4ycRS14szyaK7Tmb9oObW++3lSTN5I\n8uc+ptYDRxETHmUpl1txysWuOyrPE8XprE1s67FW1LZRPDqdjuoajHTvoh+p69RNxF7es4nF7o57\nK5jYsvuUucO6JsXhKMQX3PZGHinS5gasE0zV/Uz3L/6RlxGpNSaTiS6ftpkenrfGZ++BTqcjxXMf\n0QNz+MmjfuusdaRQvRtU72yBn/mOAAAgAElEQVTLVeyr7ieaGWc5jJo4onlyojd7Eb17I9GKu4k+\nTCVaP55os5po21yinxYT7fyAaM9nRIe+Jzq5i6j4MNH5YiLjRf9wc9EizYUMWuOorL2nyuiZD3eS\nYvImUry4nqSDx5AoOr5RyCLnNrFW7M3J5om/3VHOF+vPHI0UrM+bv2g5KV5cT7dp1zZZKOUsvj6Y\nFL2tPDM+/Zt6zPiCauuNfov60el0JB85gy6f9HHAJqNvmLeVJubu9MnzuTlrm08XKbGKjuZIljtU\nXpel0+lI/uBL1HsaP/56vmi5ir3gd/rqrQn09A3x9NLgeMp/7QGizZlE68cRffgI0Yq7iN69geiN\nnkRz2UadgMNjLkv0Rk/65xkp5T0eTV+OTiD6ZCzR55OJtr5CHzx9PT3RJ5yGdxfTyH7tiU78Qbnv\nzqNenZNJvzS7kXj2FKHJZKKf/ztLT773q9nlMuMLan/HeAqLuejzlkgkja5zpfPgznP3B8iHe8Ta\nomNZluL6P9BoxV9zFh/fFqG32Hbeg1/7lkav2EFE/ktwxrIsteo33DxS6NLd7+1TU99AnaYY6PWv\n9vuk/IeW/EQPZf/kk7KJiF5dbN7Eut119/MS1CBNeYIUL663GCvBQMtV7HZwptz0S5fQFZ2T6bnR\nI+iaDuE0SCmiJ29MNFvwPy02W/Sb1UTrx9PheTfQdpWMDk9h6egL8VTzciLRzPjmO4Y5HYhe70G0\n+Dr64YkY2vSIhFYNl9CKke0o54Xb6JXnUynzpRdp/KTJNH/ODKo4uIPWvDuXOrePp1YxF7Mr2lq3\nvrZqPSmf67isl9brdDpi5QoaoFlP187+ioora92aiA4G0tLSLFa5LLkzKdUGenLBar/KoNPpiL32\nVvOE9EL/ZEK0Zt4is2Kc8HqOT8p/Nncn3ZS11SdlExHtvJCVUtK5r9cdok6no3aDRpnTNS/xbVSU\nO7RYxW5PIXDWlnUqW9voFXs7E7ni3pCzyaR67GHqlCCmKxPD6MG+7Yn2fk70x4dEP2cTfTuf6Iup\ntC/rVtr8eAJtH5tAO59uTYfVHah4RhI1aJrvGCqmtqLjz8fS7owY+vGJaPpmTALRuieJDC8QfTOL\n6MeFRPkriXavJzrwDdHxfKKiA0QVhUT1tR63pSftbd2Ott//c6KMOk/9nKau/8vp8wpGrN+TdgPu\nNVvNvfr7VQadTkdsZ/Mko/z2MX5vM7b/hXDLPgN9Uv7czeZdqIxG31jAX16YF4nq0NXltSvOkA8c\naW6PblfyIB0/uKrYGfO5/qVv376Un5/v0bVyuRwFBQVgWRbHjx8HAKSnp+ODDz6wnCMSiWA0GsGy\nLDQaDbRaLVJSUpCXlweNRgMA0Gq1qKqqQklJCViWRUpKCnJzc9G3b1/s378fDMMAgOV7rhyNRgOV\nStVIJiKC4srrUBHfBbE9b4FYlgRTfQ1qDuxA7Z6vYTq+C9IoptEhi2Iw5KZ+OHPsAHp2YXHq8D7E\nRwIySRiu7KpE29hwoKbMfJDReaOIJUBUvNURZ/O37SE1/xt54bzwKEtRer2+0X1at7dGo8HEiRNR\nU1ODUaNGIScnp8nz0H62Byu2H4Jx81xoJjwBrVbb5HkFI9b3/ekZKXYX1WNazyqMHatq/mKe4Noy\nOWMlagv+QdQfa/zaZreM1+KQ9FoMOLUBH72/jPfy39t+GC9/tgf504egTWwk7+Wv3nEU0zbsRsHi\nx5EklXjddpMXrsLa060xhi2C5pnR/AjpJQzD/E5EfZs7T+wPYfjEWsFy5OXlAQAYhoFUKsXQoUMt\nSlylUjVRxNwPSCqVWhRWRkYGjEYjduzYAQCQyWTIyspqUhdHTb0Rvx8twcK1W/FrQTVEQzWIJxOk\ntUU49e1SNBzJR9Yrs4B7Lse4ceNQWUcoKG/ciX7w989YunQp7lapoNfr8fyFum61lpcIqKsCassv\nKvpGR6nN3+XA+WKg+PDF700NzhtVFGlR+tfuPQT9oFrU/TAFaP8PDBOvwRff1uKmIUOw5oMZGJRc\nj4i4ROS8MR2oOI1ZM6Zi5uy5ljaaOORyLN/6J+p734+MjAykpqY26lCDFe49ISIsnfMNhl/fBmMf\nudqvMnDvdtvwWpxL7obp9/ivzdLT07HrVDRie/fAT9u+9Ekd7eMlAIDTZTU+UexFFbUAAOP5UiT3\nvMzr8h4Zfg/WZv+Egbfd7XVZ/ibkFDunpLVareWzyspKiyK2VeK26PV6nDt3DgzDYNiwYcjJyYFe\nr0dERARqamogFotRX1+PkpISqNVqS5nyLt1wVtQasz/9A1+bfsauY6WoM5pADRGoPrMHUf98ifxN\nK9EuLgrAmCb1ZmZmorKyEg0NF5UsEUGr1VqUil3ZGQaIjDUfcR3cbzAioL66aYdQW26nUyhDu0oG\nzPGD6NRBBuz7HFfVlOKqfnVA2XrcNBgAogGcBxb3By7c6ZixEUDJfODtbMRHxWNL6/P4r1U8ClMV\nqCzZhF5XRaJH5XbgLwcjiPBo830GCGtr/eZ7HsbZyjrceFkbv8vBvQNvfLUfi749iPTRd/qt7tzc\nXCTcPw0NpaehSE72SR1J8eaR4amyGvRKjue9/KKKWhjPlwEms4Gm1+ub1QfOSIiJAACUnK/jS0S/\nEXKuGKCxOwZAk6G+Xq9HZmYmGIZB165dkZ+fj9TU1EauAwCWa6zLy5w2E5NmZUEsbY/wBBYxbDd0\numYgCkqqzZWTCVR8DNd3bgPV/SnY9/1nmP/KLLsuGkdYy9dcZ2TrGgkI9TXORwoXRhMH/9mJI3t3\nIT4SaN0uEbFMNVqZyiFpznwIEzdW9JG2riSpnQ7B6pyIWK86Buvnf/nQsTgkvQb9T2/Cx+8t9bhM\nb9iy+xTGf7ATG5++EVfJpX6pMz09HduibkTd2WMo+WxBIwOELwrLa9B/7lbMvr8X0q9T8l7+2FX5\n+PHP/dj7RhoAeO3+Kztfj6u0X2HGsCvw5E2d+BLTK1x1xYSkYueU3YwZGpgAzJkzF1NfmgYCMH9+\nFgrPnkVDgxEICwMjikBYRBREUTH4Ju8HzMl6Dd//vAPhMVJESdtC0bUXCs6WI0wSj1btlThvEjWq\nq6HkJO4bdC16dYhHzw5xGHXnDSg4fBAikQjZ2dmNlK0vlLBMJkNpaSmkUilKSkp8Vo+nWMvC+dMB\nILrjVWj78Bzc2roM3y3OxMtTXkDag/c6cB/ZG01Y/V1/3rkQjMj+vEKks3mGi4d+VS60s1+BRqPB\n9K9PQhyfiDMrn/GJcnOFo+eqMOjVPMwf0RuP9Ff4pU6jiXDZ1M9Q/tunuDu5Hjk5OT6po+v0LzB+\nUGdMvqM77+UPf3c7YiLEGER/8fL7MJkIl0//AhmDumDSHd14lNRzWqxiH73yV+TtL4Q5W7B3kMkI\nY1UpTOdLEW6swaP33wVl62gc2PkTFs2fifqSU0BDLUaNGmXxE3///feWiVqpVIrY2FjLxKz1ZKxG\no3HZKndGQkICSkpKIJPJUFxcDMD+BHKgsJYlJSUFq1evBvdOtXtoFqI6dMOk7hWYMP5/nlfSUGel\n7LlOwdGcg51Ooq6ymQoYICoOFBmPPcVAcWUNik+fQverB6Dblf0djCJsRhhhYZ7fnw0mE6H7NANq\n9n2PGXd39UvnfaK0GjfO34a5w3vj0QG+60xumLcV13VpjTdG9uG97JuytqFfxwS8+TB/Zfd95Rvc\n3jMRc4f35q1Mb2ixk6dDeydh27r3UF5WBpAJca1aQa3OhCiMwUdrcvF7fr7Zr0wm9OvXF+OeHIPo\nSBFiIsSIjhDhq82boHt3EZJax+O3H/MA0EXre8SFhzeoC7rH1pgnVImQm5sLo9GIzMxMVFRUADBP\n1JaVlaG0tNSizCQSSaMImtLSUgCw+NE5rK1c7ntH1oW9CVx7E8iBQK/XW+Y3OJmICFKpFBUVFSj5\n7j10eOIdzNmwDZqpky2dHGD/nh2ORMQRgLgNEOOh39tYD9RWNDNSKMfZs4U4WXwUktp96CQFYgt/\nB3buB+oqmqmAsVL8zUUkOXA3hV0cKYaFMagtPIy66LYYN25co7keX3H0bBUAoGPraJ/VAQDt46Nw\nuqyG93KJCEUVtWjbit9J2YSYcBRXCj52l/DGYuf807W15hnwqKioixOcVv5zawvXnk+bO5dT6kBT\nZcMpGs4iLy4uxvnz5y3RNyUlJRCJRIiIiEB1dbWl3qysLHz//fdYvXo1JBIJRowY0SgyhIvAcTRH\nECrYjhxsO6zMzExE3/IUxJ2uxYmlKhgri+3eM3ed9YgnEG3xxlf78c62AyhdORZMfc1FZWpsuDhi\ncBidZBOZ1GjUUNZ85RGtGin6345X4XitBCd2fY/SGgIi4zBjzmsO3E1xgCjc4/vW6/WYvXobwq5L\nw4/qwWBlvlPuT6/eib2nyrFtUgqv5ZbX1OPKl7/CtLt7QDWwM2/lDnx5PY4ePYrpN8QG3O0JtGBX\njKOJU871UVtb20jZW18DwKESsla2jpQK5+9mGKaRe8b6eq4Oa9ns/d9Zh+KMYPSvW68RsJXp2Lnz\nSHl1G6r3fIuyb7IRFRXVJByVez5ch+lr69RRGw5/dzsAYMNTN/Jbocl4YcTQzFyC1VF8rghVZefQ\nqv4s4iIIYc15HsNjmhkl2BtJmCelO1/RByWdhiCu3/04lHUfRM1W5jmzDXvw4Y5j2KO9w7JWhA/+\nK6rEra9/B9P2FZjx2J28vT/KR2ejPro1RF/OCwrDy1XFHtIrT61zeNjLe+JqjnBXsjVy51vnb3Ek\ni219jtLiekIw5VhxNefMA3PWkGLyRkpQdHW40YevNom2h702LKmqbZInJZCrZme+vZKUagO9+OYq\nIqORqLqMqOQY0am/iQ7/2HT185aXiD59imjNKKL3hhEtuZlo4ZVE85VEL0ubXf1cNSOBCjUKonf6\nEemHEOU8QLR2DNFnzxN9/TLRD28S/baC6O9PiA58TXT8N6Kif4kqzhDV17h8X/rv/yOl2kClVXW8\nttfP/501rzpVXsXrOzR8zkekmPhh0KycRktNKcDBKVIuiZZtpkJ7ysL2h+pJZkTrMrgMjLb5un2p\nfINpib699rPt4FiWpYTkzqR4cT21G/Z8s7s4+eO+7HXIbfveRUq1gWa+vbJJOopAdKKssjMpMjeR\n/K5x3reNyURUU05Uepzo9D9ER34i2vcF0a41RL8sJcpbQOvmPk7fvfow0Zo0ovfuIVo6iOitPkRZ\nnYhmJTSfL2l2O6JXLyd6py+R/laiVcOJPh5NtGki0Vcaou9fJ/p1Gf1u0NFjU+fQ4V3fEhXuIyo/\nRVR33iyjF2zadcK8/L9nP17fode+3Eedp37uszQI7tLiFbt1KlUATXJD2GbrI6ImitheJkZ7PyJH\nPyzOUrXdYSeYlK8vcZa3h2t7XMjh037os6SY/CmJ4xM92trPV3Dytr77eZI/m0sicbjLO2r5Aq6j\nkUgkxI7T0+3atT7vYEwmE/WY8QXN2vSPoxOIaiuJyk4QndlDdPRnov1biP78iGiHjui7V4m+nE60\ncQLRR48RvX8f0dIUoreuJsrqTDSrdfMdg7YN0YIuRG9fQ6QbbE7P/fHjRJueNZf93avmuv78mGj/\nl0RHfyE6s5eo7CRRbRX9L+sDUqoNtJDnbQyX/3CIlGoDlVT5NieTq7iq2EPOx86Rnp7eKLTO1jdu\nz49qGzpoL2ywuc9sI1Ka8zFfalhPVA8dOtQSUcRe3gsRD8xD/YHtGCQpaBIeGij/pVleNVqlL4Lx\n5D84+clcu2sU/IX1fJD8kVnoePXNSJcd9Om8SmFFDfrP2QrtfT3x2PUdeS8fRECDeZHb4FsGQzZk\nLGL3G7BqVoZNpJKTtBlG55Ep9cSgHLEoL69Cpx5XOc6R5ChsNSLG7iK3iW98gI2FMoyXn8GUp5uu\nKHcHPubHWqyPncNbN4qjv2198baf2bOeHFlUl4rl7gzrNnhgrtnXnrV4eZPvAslfx0st6WoDLY/1\n+/bYhf1Hy6v59Ufb8uvhc6RUGyhvf6FP69HpdCRNaE2KzE2UNj/XvYvrqonKTxMV7jf79w98TfT3\nOqLflhP98AatnfUwrVLfTQfmDyTKGWF2B73Tj+jVrkSzE5sfMbwsI5rfkWjhVeb5ifeGEa0ZRR88\npiTdtEdo7ohORL8sIdqVS7RvM9GR7eb5jpJj5vkPF1xJfIy80NItdk97P2fL+e1Z67ZWvr0YdEcW\nu3WysdjY2Eveopd37YWwe2eDjvyKY+vmBUQGe+/NO1sP4PWv//VZ1kFPyVy4Ch+fbo2StTMgKjni\ns2ihZ17/AIYiGZ5SnEHmU95Zpc7gfg+KZ1fjkZt7IevBK3kr+/EVv6LkfB02PXOT/RMaam1GBE1T\nYtg7Th45AGm0GNFMrXMBmDDni9ii4vHTH3swc+U3GDlhlmCxu4qrGztwfnG4aGE7miAlatoDW0fh\nWP8bahs5+wLLJOUdT5Fi8qcWq93f2LOaRry7ne5554egGUFwcBt+xF491Kfvj3zoU6SY9CmxcoVP\nyufg2vc6zXpKX76D17LvWvg9jVn5K69lEl18BknX3UNUeZbo7EGigt+JDm4j2r2BKP89oh/fIvpG\nS2R4kegTFdHqkUTL7yBafJ15A545HS6ODH71bg4ALX3y1BZnwxzrCBmpVOrWNmfOfuyOomyai8a5\nFOHaJjyuLSleXE/yB6YQkf/bpknoaeeu1FH9GY2an+vXkEtXkMlkxD6bSwl3POPTbfnumr2W2PHL\n/LbH6m3ataQYt5S3unQ6HSmeXU33vfIRL+VZs3iJnpRqAyWmpHslr25JNvW65lrKXrzIK3kuOcXu\nTEHYi5DxBfa2jRMwwz2fAQMGUMKQcaTM3ERHz1Y5HRH5GpZlKbrHoAu7Bt3sl3fEHXQ6HSkef52u\n16z3aT3D3v6BFOnz/dapye9/keTPfcRbXaxcTorJG0l+dwYv5dmiePETkg4e45W8bJcLO2Pdmu6V\nLK4qdv4yFwUYlUqF48ePN0oHIJfLodfrodFowLKszyMd8vLyYDQaceLEiUayCFx8PidOnEDZL2tB\nJiMWf3vQsvqQz1WIrqLRaNDmqlsQIzJiRka6X94Rd1CpVBjQLRknqoClOr1P6iAiHDlXhX7dO1qi\nvnxNnNiEsMgYFJWUQ6/3/r5emDoTTJgIdw3mecXwBaRRIrRqk+Rx2+j1epxvML/fw+++nU/RHOOK\n9uf78IXFbourM9B8ugIEl0vzcG304Nw11GXq55S1eHnA2qy6roEum7KJ5CMyg/aZyQc+ZB5R9PDR\nKLdLd1KqDbT8h0O8l++I2J6DSak2kLg1y4vVvvuEOaqJvf4enzzHYW//QKNXeD4nwLIsRXQwW+zb\n9p3xShb402JnGOZOhmH2MwxzkGGYKXyU6S2cld5cL8vlEM/IyPDaerAdNQg0hWujRU/fh7AwBufa\n9W20XoB7BtYjLl+g1+sh7zsE9RSGoj++abQjVzCheuguAMCDqom8l63ValF4Yf+Yjm18m9XRmsED\nzGl1Y9rwM0LgtsQrOnbQJ89RFhOB4vP1Hl+v0WjQjjVv1CGVeJ6szR28VuwMw4gALAZwF4ArAKQy\nDHOFt+V6i6tKVqPRWDa/DtYfd0skMS4Kj/ZX4JOdBTh27rylg+Wege3ffGDdWWi1Wpg69Iaptgo1\nR/9CSkoKb/XwSeb4xyAOY9Dhin68l63RaJDYpScAQNk6hvfyHXHztb0AAKNUT/NiBBVeUOxtW0X6\nxJXUOiYCxVXNhDs6QaVS4a1ss4EijY7gSyyn8GGx9wdwkIgOEVEdgDUA7uOhXL+gUqmQnZ3t0Lr3\nteXYknHUdnq9HjKZDK89eTvq62rx0MvLGuV1B1wfcbmDdWcxfYYGMV2vQ/V/+YCpwbIherARKRah\nS9tY7D3VXE5491GpVHhuxlyEMYDch6l6bXk7y9xZf7b1R17K27zNXM7U557yyWhZFh2BkirPLXYA\nKL1g8cuiQ8RiB5AMwHo9eMGFz0IGR9a9Xq9HRkYG75bjpYIjq5vbhKTq7ElU7NqC01FKVFIkYmJi\nLM/AF24t686ioCYCYZJ4NBzJb9ShBCM9klph76lyn5S9dcefMJYX4f2Vy31Svj0006eBqstw9Y23\n8FLetp9/h6mmEvNe8c1vNCEmHJW1DahtMHpcRml1PRgGaBUVOordJRiGGcswTD7DMPlFRUX+qtYh\nttakPetSq9XCaDRCJBIF9Q8/WHFkdWs0Gkil5k2ay3esA8iEpCFPWM5LT0+HWCxGeno6r/JYdxbv\nf7sbpvpalO3/pVGHEmzo9XqsX/EOTpXVoKSK/518dh85g5qzx3mZY3IVlUqFDlIJdu0/wkudV1xz\nHZjaCp/9RhNizKuRvbHay87XIS4q3Ke57hvhygyrswPA9QC+tPp7KoCpzq7xR1SMPayjVmyjZuxF\n0QhRLvxjL0c+FyFz9GwVEZFloZBIJOK1TsuiJLmCukxaR0kPTvfbohxPYVmWojpeTUq1gbYfKOK9\n/O5TN1HrO572+8IsRepsSnpyMS91jnh3Oz2y9GcepLLPF3+fJKXaQP+cKPO4jGdzd9LABdu8lgX+\nWqAE876phwB0AhAB4E8APZ1dEyjFbq28m0sIJuAb7K3OPV1WTZdP20yZa/8kIvvplPmok2XN4XVR\nnfuSUm2gr/45zUv5vkSn05EsSUFKtYGeXLCa13K5RTP/W7Da7+/+A3PXkOL5tbzUeVPWVno2dycP\nUtnnlwubeLB9h3gsb/ryHXTvOz94LYvfFLu5LtwN4F8A/wGY1tz5wWCxCwQG23w63LOYuXF3I6ud\n77qsN/+Qj9RQt6mbqLbeyFtdvoRlWUp+ehXJH5zGa5mRyVeQUm2gb72MrfaEJXkHeclcaTKZqOu0\nzfSKwUEueR44cKaclGoDRfcY2GTvBVfQ6XSkeHIRDX55ndeyuKrYefGxE9FmIupKRF2IaA4fZfoC\nX0zICVEz7sE9g5ycHEtue71ej4yULggLYzBhiQFyuRzXXXedxc/uaRtzk7d5eXmIjY1FSUkJ8n74\nCWLlNTj7x1d48onHfXSX/KLRaCAqP4WkHs0n9XOnzHaXmbMrdmkby1u5rtI+PgoAcLqsxqtyymsa\nUNtgQrtWUXyIZRfZhRBFkSSOM2TdQqvVokEUgYN7/uJbNIe0mJQCgcIX8daXCtZtlxgXhT4x5dhV\nFoUzNWHYsWMHjEYjcnNzPW5jbvI2JSXFEk5534RZMIWJUbn7W+Tm5oZEx6xSqTA+9R6UGCNRbzTx\nVqa8Z19QfS2mThzHS5nu0EEqAQCc9FKxF1WYr28X57t0y+bYc4I0kcWCBQvcvl6j0UAcHY/+V/lv\neY+g2L3EF/HWlwq2bffz8pmgumpIB42GWCyGSCRCamqqx23MjQ7y8vJQWlqKmJgYnJB0gqS+DA2n\n9iE1NTVkOuYrkuJQZzThv6JKXsrT6/U4UFiB+uITWJOby0uZ7pB0wWI/VVrtVTmF5RcXJ/kKURgD\nWXQEHh/r2YKqMU/+D2FRMbih39U+kM4+gmL3EiGNgOfYtp1G/SJqd32G6Mv6I/O1ZWhoaMDAgQO9\n3k6M6xjGqbX441gpJg2/Hg0NDRZ3UCh0zD2S4gCAt3h2rVaL8AQW9eeOo29f/lw8rpIYFwWGAU55\nabF/tGkLAODeIYN8OuoypxXwLNy0vLoeRP5LJwAIil0gCODcIQBw9Ov3kSyVYBfTGSYT2bWo3XGf\nWO+YVMv2Q4Q4DA9ck9yozlDomL/duAZkrMdHW7bzUt5L0zUQSxNRX1yAEydO8FKmO4SLwhATZsSb\nS9/zSiFv2LINAFB88ojPRl16vR7//fMndv97xKPrS6svrDqN8Z9i93kmR3tHoKJiBIIT2zUEn/5R\nQEq1gdblH7cbyeTOmgPLuZ27UffpX9CLH+9qUkYoREtJpVJq/9ib1GHUPF7K23OyzJwf/Mb7Anbf\niicXUbuRWq9i2UfOXUOKFz7x6XoElmWp7fBppBi7xKPrdx4tNodL9r/TaxlxqeVjFwhemrOwuZWo\nVVVV0Ov1uOfKDrhKLsW8L/Zi5KjRTbI/2rpPnKV+SElJgUgkQqc7RqO63oiEwp2Qy+VISUmxlBEK\nfnaGYVBfdBii1kqPIjNs4Xz1114uR0ZGBu+rfF2hTYwI4ri2XiVgS+zYFcpE837Evhp1aTQaRIUZ\nEdsmyaPrOYu9sOCw/94xV7Q/34dgsV9aNLdtIcuyJJFIGu2ktPtEKXWe+jlNXf9XozIAUFpamt1V\nxNa7H3F7rDIMQ4w4khQT19CT7/0asiuMdTodyW9NJ6XaQGfKqr0ub+HX/1LHKQYSR0p4XeXrDvL7\nXiD5cx97ZbEPnPkJJT/2uk8tdp1OR/Jhz1An9WdkMpncvv7Z13NIqTZQ6449/GaxC4pdwOe4sm0h\nwzAEgCQSiWVRkfyeiaRUGyj/yDlKS0uzKHaRSNRImdsudrIuFwDFX2ferELz9sqQUOKO+PnCCkg+\nFhRN+HAn3Th/K++rfN0hZfxsUqoN9Ej6Ex6XoRi/jNrcN8WnKRFYlqVW/e4npdpAb2e7vxk11yGz\nXbp5LYug2AVCAtuVqDKZzKKwmfAoSs5YQVdP/5TYjl0sihoADRgwwOnm05zFnpCkJMXza6nt8Gkh\nvbm4TqcjabsOpFQbaHTWh16Xd+fC7+mx5Z7vCsQH8hvvMyu8nv08LqPr1E3U/u4JPrfYW/UeYpa1\n+9VuX582P5eUagPJEhIEH7vApYHtSlQigkQiQUREBNBQi7OGN3CuLgx1ve+HTCaz7I2an5/vMI++\nXq9HZmYmGIbBoGcWICwiCpH7tiAlJQVyuRxqtTrofeq2aLValBaeRENZIbbu3OdVWfVGEw4WVqB7\nUiuepPOM0SOHAwBGqZ7x6PrqOiNqTWGYPulZn/rYVSoVMsaY5yCefOpZt6/v0qM3qO48SoqL/fbO\nCYpdIGjg8rTX1dWhuifmyA8AABi0SURBVLoa8fHxaDi5F2U/fwzJFYMR2+sWjBo1yrJwyTYOPj09\nHWFhYRg7dixKS0txPjYZO8tjMPrGTji+Jx95eXkoKCgAEYVE7Lo13ASz8dwxUFwH6PV6j1fNHiqq\nQr2RcMWF2PhAMe6xkQCADzd84VHI45nyC6tOfbg4iePRB+4FANw85C63ry2uqkNCdIRf3zlBsQsE\nDVy0S2pqKljWvHw7OzsbzO7NaDi5B+E3jMbTsxZaFi7ZKrXc3FxLxEhYVCxa3/0cjGVnMPmObo3K\nX7BgQUjErlujUqlQUlIClBYgTJoE9UvTPY7m2XfavMipe/vAKvZ2rSJBZEK5McwjS3bZh+sAAH9s\n3+bz1BAJMeZ8Mec8yIlfcr4OyqQ2/n3nXPHX8H0IPnYBdymtqqNbXvuWes3cQr8dPmc3uiUtLY0Y\nhqHwKAklPTqPFJM2kObtlYET2ge0udrs641I6koSiYQkEolb/mVzhMcE6qT+jOoaAp/dsudLG0n+\n4FSPfM/ymx8w+717XOM08ooPKmrqzXH/tz3htqx3Lfyexqz8lRc5IPjYBVoKer0evbp1xl2SQ2gT\nG4m05Tvw4Atzmwxtc3JyUHa+FkkjZyFC3hu04wPMmjC6UTnBnvDLGXq9HsYzBwEAkcndUV1djbq6\nOpSUlNi1eB3tClYraQ1jcQHCRYH7+XOyxYuNuOn2e922ZPV6PepE5n1ap07M8HlqiJgIEchYj4o6\ncnt0cbywBF9//ql/3ztXtD/fh2CxC7gDZ41JpVKStVdQ8ug3Sak20JiVv9IP/xZReXUdFVXU0Ee/\nHaMBc76hjurPSD7wIcerUP24UxCfcPLLn3rPsvuTvVBP2/NtRzXsU+9Tvwnv+FP0Jlju5WEN3ZS1\n1aPrE27LIMVza3wgnX16eTC6MJlMpHhxPUlTnuDlvYNgsQu0FFJSUsAwDEpLS1Fy+hhOvP8ianZ8\nhN+PlSBt+Q70fvkr9H3lG2Su+wuymAisf+pGHPvu4yZWYKgk/HIEJ3+vpBh0unYwiouLkZOT49B3\na+9+837+DaJWrbF/x7dISEgI2OiFk+2mPj1wsrQGDW6mI9ZoNIhtxyI2rN5vozC2nQy3Dxvu1uji\nfJ0RjDgCrSIY/753rmh/vg/BYhdwB+vFRtwhlUqpqraetu49Te9+e5CW/XCI8o8U06gALrjxF8t+\nOERKtYFef3eZ2/H4Ly18j5RqA0V1vDooRi8Zr31ASrWBXl283O1r71r4PSnS5vrtPkbpf6H7F//o\n1jXHzlWRUm2gj347xosMECx2gVCH88OmpKRAKpVCJpMhLS3NEtkSHSHGLd0TkZHSBU/e1AnXKmVY\nk5tr2aDDuoxQ9avb4xqFFADwZs5Gt6Ji9Ho9cjZ/DwCQ1BRBJpMFfPTy2Zr3AABvLV/t9rWny2tw\nTY8ufhuFyWIiUOJmVMyK1R8DAH778VtfiOQYV7Q/34dgsQu4QnM+cW51qXVUiO0SeWv/fKitNnVE\nbb2RLp+2mUbOXePWPbEsS23un0qKp1b6VkA3mL94OSnVBnr6tRy3rquuayCl2kDvbP3XR5I1RfPp\n39Rr5ha3rmH732GO3LnqZl5kgGCxC4Q6zfnEuQVN1lEhOTk5lk009Hq9ZUu8uro6FBQUQK1W+/MW\nfML7K5fjfME+bN9/0q0NSDQaDaLZHuiZFONjCV3n+bGjARA2bd3u1qiK2yu1fbzEN4LZoXVsJCpq\nGlDbYHT5muEPpwEAnhk72kdS2UdQ7AJBS3O7U3GrMWUyGVJSUiCTyRpNCHKKPyYmxpyiAOYRaqij\nVqtRdWw3RG06ImPCRJdXod73cDqYmASMGHStH6V1ToQ4DKaKczjPSJCZmenydXpucdKPW30lWhO4\n7ffOVbrujrmy3w0AgPFP+DctsqDYBUIWbjVmcXExDAaDxXrPzMxsknN9wYIFFt98KKPX61FaWora\no3+BEUcgvH1XaLVal1ah/llQBgDoI5f6S1yXMFWehViaiLKyMpd3xXpnWQ4AYNXSt30tnoU2sWbF\nPmDQba7v3pX1BsJAiIsS+1q8RgiKXSBocWSFcjlhYmJiLNZqWVmZ5XvO7ZKXl2ex+FvK3rRarRZE\nhPqT+wCTEZKOfZCSkuJSKOcfx0ogCmPwhuYFiMXigGyuYY8O8ZEQxyeCyLXFP1qtFkxMAgCgquiE\n3ybGLRZ7VZ3LclYZw2CsLrckr/Mbrjji+T6EyVMBV3A0ecql6+W+sw2HbEkTpbZYpzluP2oBtU9/\no9n75SaZkx9/k3o9/16jvPbBgPyu8aTI3EQIE7sUpqrT6aj9sOeIffZDv4ZsHi82hy7KBz3s0rul\n0+lI8egr1G/GBt5kgDB5KhDqOLJCU1NTwTAMwsPDce7cOZw7d65JKGRLsM5tsd6YOy8vD9VHdyGi\nfRcwkTFO3TBarRZlVTUQte2Egt+3WT5PTU31l+hOuffWG8EwYRDHtUVeXl6z56tUKkTI2qOhrBAA\nvNpazx04V0ymZrZL75ZKpUL/mwejC9ve16I1QVDsAkGLI/dJTk4OTCYTEhMTUV1djerqahCR01WY\nLSGe3dqPrtFo0KrqJJgwEcZMmWfpAO3dZ0pKCqLYK8CIxKg59jcYhoFOp0NOTk4A7+Yi0nBzlImU\n7eJyPHp0WwUaSk8DgEudAR9EhYsQFyVGUUWty9ccOlGI7d9+6f/3zhWznu9DcMUI8IFOp7O4FaKj\no52eG+p5Yoia7vxUW2+knpotpF73p+Uce/fJsixJBz1OikkbiAmPJJlM5nfZncF2u/KCi+MRl843\nGk2kmLSBpINGN9rn1tfodDpSjF9Gd2rXunyNYuIaSrhtPG/vHfzhimEY5lWGYfYxDPMXwzAbGIYJ\nrul2gZDHmaWtUqkglZpfOS6c0RGhnicGaDqCiRCHYXD3dvh6zxkYTeYwTuv7tF65G9d1AOIbSpGc\n2BZZWVmBvI1G6PV6VBYWgIwNuPHO+1waWZ2pqAEjCkersFpkZ2f7zeWm1WpRW1aEPYcLXDrfaCIw\nUTGIEcP/750r2t/RAeB2AOIL/88CkOXKdYLFLuAqrqw+tTdxGIr7mnrC53+dJKXaQD//d7bR5zqd\n7uKesF17k1JtoOy8gwGS0jHc81WM19PYVb+5NLKa/pY5382Uhe/7UVLzqua2902h7i+6tufs2Yoa\nUqoNtPLHQ7zJAH9Y7ET0FRE1XPjzFwCsN+UJCNjSnKXtyA/v6e5Cocagrm0RKQ7Dlt2nLZ/p9Xpk\nZGTAaDRCJBLhLtUUAMDtVyQGSkyHcM+3W5IUv/9bYFkpbP28ba3499cZAAAfLFnoV1nz8vLQUFmM\n86Zwl0YWZy8sZGrjh637bOFz8nQMgC8cfckwzFiGYfIZhskvKirisVqBloyn8ectwfViiz1lEhMp\nxq092uGjX/6DXNnJEjnDKfXs7Gyci+mIy9vFonPb2KCbROae7+C+PVFUA5SWlVvi2a1XEFt30h17\n9QWZjBjYt7dfZdVoNIgVm8BESKCdM69Zw4GbZG3XKspfIl6kOZMewDcAdts57rM6ZxqADQAYV4YJ\ngitGQMB9HG2cEd35GlKqDRTdY5DF/cT9e+BMeaMt3YJ1Ejl3x1FzsqzufUgmkzWS0datJh85nZLH\nrwjIPTz1Wg4p1QZ68PFxzbr6Pvn9uGXrPr5cguDLFUNEQ4iol51jIwAwDDMawDAAoy5ULCAg4APs\njUJyc3Nx/tAfqC8+iYQbHsKMGY1HKKt+PgoyGXFi+wZLmGQwjmQ6t401/6dVOwwdOrSRjLajNkWP\nqyGqLgnIPWz62Jxe+Jdde5odSXIW+4n/9vrdJehtVMydADIB3EtE5/kRSUDAPYLNveAr7LmlzIuM\nCGU/5ULUpiOSBgy96Lr4f3v3Hxx1fSZw/P1kIQnJBrMhIJCN4IkKvWI9Qbzansb2tNiz1TrTORl+\nOdNZr9FWb7wZcva8nRNse0Hrj7aOd9niXYE23s2p4zV3Zw/UQLmhQiioKP4ITvgthCT8COYH2X3u\nj+yuiRCiJLuf3e8+r5kdwmbJPp9l83w/+3w/3+fzk6dYu7mF3nc2cEGBJDtBZuLFWxeX93ecPB4r\nGNQK4my6fCXcccufOxlDaPFfAjD76muHfc+1nuxhrMSomDQh7QehkdbYfw6UAOtEZIeI/NMoxGTM\nZ5IrJ0rPZs2aNSxatIjudzfh723n71/cyb0PPETwoulcsiBMtO80rY2/pLi4OOOS+UDl/nwK8mKU\nXnT5OZNgx6le2k71MmOSP43RfeyuxXcAsLN577DvuSMne5ha5ndyIB3pqpgZqlqpqlfGb98drcCM\n+bQytbyQLo2NjUT7TnP8pSeIxpQ1Ryq4+J5naOkqoOt3/8L4MbGMf21EhFkVZVw7//ZzJsHdrZ0A\nzhL7BH8+InD9/G8O+Z5LfILcsGU7LbvecPJJ0loKmKyXqeWFdEn0pW9r2cWhX95PQftu9uzcyke/\nfYLWLb/J+Nl6wqwpJew6dDKxIOOsJbZEYr9kopvEPtaXR7m/gIoZnxvyPZf4BHn0ZA8fdRz+TH3m\nR4sldmOyXCgUwu/309XVRVvL2zT97B72rqnhdEsT48aN48CBAxnTovdcZk0Zz/Gu0xyK7440sMSW\nSPLPr99M/pg8KgLp2zlpoEgkwpGWd9my8/0hH5P4BOnzlxHtbE9/y14ssRvjCeFweFAC8fl8rFy5\nkt7eXlSVtWvXZvzJ5VlTxgPwheu/TllZ2aCNUhJJftMbzfS07uWZVb9wEuOyZcvoajvE+weGvhYn\nFArxgwfD5BX6yY91O2nhYIndGA8IhUIsXLgQEaGoqCjZQ2Vga95MP7k8c3IJAL1FE+no6KChoSH5\nveQseMJFnDr4vrOxiAh9J1rJi2/0MZS/e7g/mcdOHXNSBrPEbowHRCIR6uvrUVXKysqSyWTNmjXU\n1dVlxcnlksKxlI7pozh4OYFAABFJlmJCoRDbdzWT5y+jqLvN2Vhqa2vx+/qQgmI6e/qGfJyvOND/\nRdfxIR+TSpbYjfGAgW0EPrmxdygUoqqqiurq6oyvtc+7rIKZ13yV9vZ2amtrBx2QHl31bwAs/kaV\ns5PBoVCIb33tBoDkvqtns+Sv7gXge6GlaYnrkyyxG+MBiVLF008/TWNjY3Jj70TJor6+nmg0Sn19\nveNIz+0LlaV8cPQUHad6z/jer/97IwCrn/xRusMa5FeRnwPw2NPPDPmY2fO+DMDdd7rZpcoSuzEe\nMHDJZ2L548AuiQsWLMDn82XMdnhDmTutv4RxxVdvo6amZtBFQBNnzqXv2IdUXTvPZYjoRx0A5PnP\nrLNHIhECgQAPPPwIPlEmFJ97n4BUscRujMeEQiE6Ojpob28fVGvv6+vLmO3whrJt3fNo9DSdhRei\nqslSTCymtHIB3ft2Djqp6sL86/4UgMuv+uIZ31u2bBnHjh2jL7+E7raDLFmyJN3hAZbYjTEZ5McP\nL6fnw2YKL5o9aFPy946cJG/ceLr3vuFkXfhAGxtfIdrZQcvhY2d8LxGbb/xE+k4cdVb6ssRujMkY\nVVVV9LRsp2DKZdx6x8cnejfvbgMgcPqo8639wuEweT3HmXHF1WdcHZs44VtUXkGs86iz0pe46LQ7\nd+5cbWpqSvvzGmMyW2VlJYe7fUz9zlP88FufZ+E104hEIjy0oR3xTyA8RzOiPcLNK/6DnQePc+Cf\nQ8mS0b59+wA4HY1x2YP/w/e/cin333jZqD6viGxT1bnDPc5m7MaYjBEOh7mwMEpgbB8vbj8IwPJH\nfopv6ixOvtVITU2N4wj7vfVaI3n+chTB5/MNWld/+EQ3qjD1Agc7J8VZYjfGOJcoaQDs27ePe26a\nzZaWdn7/QRvX3PkgAKfeXE+m7OVzyw1fRHxjKKuckbzKN2F/RxcAU0vd9LMBS+zGmAzwyZ76PW+/\ngp5sZVFkM00n/Mwp7WZyyVhWrlzpONJ+i277GgAvrv+/ZFJPHJxWv/AS8PHmIS5YYjfGOPfJnvr/\n+PBDHHz2Qbp2byX2XiM3lh9P1rAzYbesaRP6k/ae9lPJ+xIHp4bG18j35dmM3RgzOrJ1m8DEhVWJ\nFr3hcJjJRULX+p+x74VH+f7d/e0QqqurM2K3rMnjC8n35bG37eMdQRMHp5nzruOiCUX48twty7RV\nMcZ4SGVlJfv37x+0SiNbnC32SCRCdXV1sg9ONBoFYNGiRc4vtrrp8Q1UBopYdefVg+6/8bENTC8v\nJrJk2MUrn5mtijEmByVmjVVVVVk3cz/bFocbN24kFotRVFSUbIsA/dsBujZz8ni2Nh8c9DpHY8qe\n9o/4I4f1dQBUNe23OXPmqDEmdYLBoAIaDAZdh3Je6urqNBgMqogooD6fb9D9dXV1jiNUXVr7a51W\n06CSX5R8nVc+tUqn1TRo9aNrU/KcQJN+ihxrM3ZjPCjbN/hOnIgsLCwc1Lwsk/a3ffm51QAUXnhx\n8nX+6ZoXAPjXx3/o9NOSJXZjPCiTEuD5SByYnnzyyYxtXnbf0m8DsOTeB5Kv8/W3LURjUboPf+D0\nBO8YZ89sjDFDCIVCGX9QGj8minZ3crCnvzVvJBLhdzuPUjxpGhWTJzr9tGSJ3RhjzsOKFcvpuXop\nr5++BIDlK1Ygtz9C554dzlckWSnGGGPOQzgcRo7uRkom8e07v0tXQTl5hX5uv/aPXYdmid0YY85H\nKBQiv/UdANa920Y0eCUaizJ9XI/jyEYpsYvI34iIikj5aPw8Y4zJBuH770aPNFP+ZwsoufJmupq3\n8JMf/YPrsEae2EWkErgJ2DvycIwxJnuEQiF+s3wpefnjKCgspKD55YxYYjoaJ08fB5YBL47CzzLG\nmKxyRbCUTTU34BNhwo+/4TocYIQzdhG5FTigqq+PUjzGGJNVIpEIcz53Kc/Xr3YdStKwiV1E1ovI\nzrPcbgV+AHyqzx0icpeINIlIU2tr60jjNsZ4WCQSIRAIUFZWlvH9bhJXyVZXV2dMrOfd3VFEZgMv\nA4m+lUHgIDBPVT8817+17o7GmHNJdHoEMr5T5eLFi1m7di2Q+lhT3t1RVd9U1UmqOl1VpwP7gauG\nS+rGGDOccDhMaWkpgUAgI05GnktDQwMAIpIxsY5aP3YRaQHmqurR4R5rM3ZjjFeUlZXR0dFBIBCg\nvb09pc+V9n7s8Zn7sEndGGO8pLa2lmAwSG1tretQkqxXjDHGjECiWVmim2MmNC+zrfGMMWaE0rUl\noW2NZ4wxaZJpG5vYjN0YY7KEzdiNMSZHWWI3xhiPscRujDHnIRKJUFlZmTFtBAayGrsxxpyHdK2E\nGchq7MYYk0KZthJmIJuxG2NMlrAZuzHGpEmm1dttxm6MMSNkV54aY4zHZFq93WbsxhiTJWzGbowx\nOcoSuzHGeIwldmOM8RhL7MYY4zGW2I0xxmMssRtjjMdYYjfGGI+xxG6MMR7j5AIlEWkF9ozgR5QD\nR0cpnGyRa2POtfFC7o0518YLIx/zNFWdONyDnCT2kRKRpk9z9ZWX5NqYc228kHtjzrXxQvrGbKUY\nY4zxGEvsxhjjMdma2OtcB+BAro0518YLuTfmXBsvpGnMWVljN8YYM7RsnbEbY4wZQtYldhGZLyLv\nikiziPyt63hSSUSeEZEjIrLTdSzpIiKVIvKqiLwtIm+JyH2uY0olESkUkS0i8np8vA+5jikdRMQn\nIttFpMF1LOkgIi0i8qaI7BCRlG9GkVWlGBHxAe8BNwL7ga3AAlV922lgKSIi1wGdwGpV/bzreNJB\nRKYAU1T1DyJSAmwDbvPw/7EAxaraKSJjgU3Afar6e8ehpZSI3A/MBcar6i2u40k1EWkB5qpqWtbt\nZ9uMfR7QrKofqGov8Cxwq+OYUkZVNwLtruNIJ1U9pKp/iH99EtgFVLiNKnW0X2f8r2Pjt+yZbZ0H\nEQkCfwH8wnUsXpVtib0CGLhT7H48/Euf60RkOvAnwGtuI0mteFliB3AEWKeqnh4v8ASwDIi5DiSN\nFPhfEdkmInel+smyLbGbHCEifuA54K9V9YTreFJJVaOqeiUQBOaJiGfLbiJyC3BEVbe5jiXNvqyq\nVwE3A/fEy6wpk22J/QBQOeDvwfh9xkPitebngF+p6vOu40kXVT0GvArMdx1LCn0J+Ga85vws8BUR\nWes2pNRT1QPxP48AL9BfVk6ZbEvsW4FLReRiEckH7gD+03FMZhTFTyauAnap6mOu40k1EZkoIqXx\nr8fRvzDgHbdRpY6qPqCqQVWdTv/v7yuqushxWCklIsXxhQCISDFwE5DSlW5ZldhVtQ/4HvBb+k+q\n/buqvuU2qtQRkXpgM3C5iOwXke+4jikNvgQspn8mtyN++7rroFJoCvCqiLxB/8RlnarmxBLAHHIh\nsElEXge2AP+lqi+l8gmzarmjMcaY4WXVjN0YY8zwLLEbY4zHWGI3xhiPscRujDEeY4ndGGM8xhK7\nMcZ4jCV2Y4zxGEvsxhjjMf8PNy4+jI0KsL0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY7hL5dVFYgL",
        "colab_type": "code",
        "outputId": "b7adbcce-ca9e-4284-94f0-2988b80a1f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# 예시1 \n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly_features = PolynomialFeatures(degree=2)\n",
        "X_poly = poly_features.fit_transform(X)\n",
        "X_poly[:10]\n",
        "\n",
        "lr = LinearRegression(fit_intercept=False)\n",
        "lr.fit(X_poly,y)\n",
        "\n",
        "f_x, f_y = f(1000)\n",
        "plt.plot(f_x, f_y)\n",
        "plt.scatter(X.flatten(), y.flatten(), s=3, c=\"black\")\n",
        "plt.plot(X.flatten(), lr.predict(X_poly).flatten())\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxC4ikmGU2EVEMowSu4hIhlFiFxHJMP8P36vFo8vq184AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVliZegCFYmB",
        "colab_type": "code",
        "outputId": "d9223c59-434a-40a0-b13a-c5da10bff174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# 예시1 \n",
        "poly_features = PolynomialFeatures(degree=16)\n",
        "X_poly = poly_features.fit_transform(X)\n",
        "X_poly[:3]\n",
        "\n",
        "lr = LinearRegression(fit_intercept=False)\n",
        "lr.fit(X_poly,y)\n",
        "f_x, f_y = f(1000)\n",
        "plt.plot(f_x, f_y)\n",
        "plt.scatter(X.flatten(), y.flatten(), s=3, c=\"black\")\n",
        "plt.plot(X.flatten(), lr.predict(X_poly).flatten())\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXd8U+X3xz83SXebJh10JW3Ze5ch\nyzoQBURRVJD2i4MCRcRJC0JTiKyigjIEEoZSsQ4E1CqiAkUFRPaeQqEDaKF7N8n5/XGbmHTRNjej\n/d3369UXJLn3POc+NznPuec5z3kYIgIPDw8PT8tBYGsFeHh4eHi4hTfsPDw8PC0M3rDz8PDwtDB4\nw87Dw8PTwuANOw8PD08LgzfsPDw8PC0M3rDz8PDwtDB4w87Dw8PTwuANOw8PD08LQ2SLRn18fCg0\nNNQWTfPw8PA0W44dO3aXiHzvd5xNDHtoaCiOHj1qi6Z5eHh4mi0Mw9xoyHF8KIaHh4enhcEbdh4e\nHp4WBm/YeXh4eFoYvGHn4eHhaWHwhp2Hh4enhcEbdh4eHp4WBm/YeXh4eFoYnBh2hmEkDMNsYxjm\nIsMwFxiGeYALuTw8PDw8jYcrj/0TAL8QUScAPQFc4EguDw8PDyeo1WrI5XKo1Wpbq2JxzDbsDMN4\nAhgGYCMAEFEFEeWZK5eHh4eHS5RKJdLT0xEdHY3IyMgWbeS58NhbA8gGsJlhmBMMw2xgGMat+kEM\nw0xhGOYowzBHs7OzOWiWh4eHp+EoFAoIhUJotVokJSUhPT0dSqXS1mpZBC4MuwhAHwBriag3gGIA\ns6sfREQqIgojojBf3/vWsOHh4eHhlKioKKxduxYymQwTJkyATCaDQqGwtVoWgQvDng4gnYgOV73e\nBtbQ8/DwtECac6w6KioKaWlpGDZsmK1VsShmG3Yiug0gjWGYjlVvPQLgvLlyeXh47BPjWHVzM+76\nQSk2NtYQimnOA1VdMERkvhCG6QVgAwBHANcAvExEuXUdHxYWRnzZXh6e5olarUZ0dDS0Wi1kMhnS\n0tJsrVKDkcvlSE9Ph0Qigbu7OxQKhWGgag7XwjDMMSIKu99xnKQ7EtHJqvh5DyJ6uj6jzsPD07wx\njlU3txi1QqGATCbD6NGjDe+Fh4dDKBQiPDzcdopxDCcee2PhPXYeHh5bUf2JAwDvsfPw8PA0N4zj\n6EqlElqtFj39RVg4JgSCikJIpdJm9/RRH7zHzsPD0+LRx9ZlMhkGPDIalwqAv7ttg5ugAruvajB5\nv5fde+sA77Hz8PDwGNDH1ufGKXDEpS9mdcmGiCEcdhyMEe1EWBMbaWsVOYU37Dw8PC0eff56QP+R\ncPL0wRjahz0UhlXSWYDIBWNaV9haRU7hDTsPD8//G747noGRnjcgcdCA6fk8/rpRghL5MODSLsAG\nYWlLwRt2Hh6eJtOcFveUVWpx8EoWQlN3QAcGl26VAQB2ZkiAgnQg3/5j7A2FN+w8PDxNRr+4x55X\ncOr1WvDpVmiIQV/BRRzP1ECpmIfK3Exs/deZPTD9iG0V5RDesPPw8DQZ/aSk8QpOe6uYqNdr655j\ncEEF+nmXYP8NDcrKylCRcQHXvAZDwzhAPX+a3Q1KTYU37Dw8PE1GPykZFRVlYuTtCb1eoX0exEj/\nfDiLGFwpkcDZ2RllmZdRKnTH+bsMgp1L7G5Qaiq8Yefh4WkS1UMvxkbenoiKisKNGzeRS24Y7HEH\nALBux19ISEiARJcPAKjw74nu/g52Nyg1Fd6w8/DwNAl7Db3Uxs2cEhSWa9BNeBNwcAW8WiMqKgpX\njqRAJGBwlYIQ6E5w0JXZWlVO4A07Dw9Pk7DX0EttnMlgPfPA8n+BVl0AgRAA4OwgRLtW7tiTxr7e\ntm6JzXTkEt6w8/DwNAl7Db1UR61W47W5iyGADm55FwG/rlCr1ZBKpfDy8gJTmIVs3/4AgHcnjb6P\ntOYBb9h5eHiajHGc3V7THZVKJUodxHDLuwKmNBfw7QSlUom8vDzk5ubi8G/f40ylPyp1gKemZezH\nzBt2Hh4LYK9GrqlUN+B6b3e24n1kZN2DUqm0252VFAoFHL2CEFxctbGbd1soFApIJBIwDIPyu2nQ\nMg5IKxQg9eQftlWWI/jqjjw8FsC4mmBzqBp4P4yvB2Drl3sOfhGeg8cDmgp0KTiKv7etQ35+PojI\nrq5bqyN0mPsTRqWvxsq2h/C1XyxeiH4PADtgKVd/BuET7+HLkmi08ZfC/71TNta4bvjqjjw8NqQ5\nTSw2BP31hIeHo6ioCC4dHoBkyIvQXDuCXq39cN6zP4rICQDsrrZ5Zl4ptMRArkmDRkeYveRT0wMK\n2BTIdI0U7pqWsfkbb9h5eCxAc5lYbCj660lJSUFefgG8H3oFlJuOh5xTcXxlNIRCATwHT4A+AmBP\n133tbjEAINThHq7n6jDkwYcMnymVSqSn/gttUQ5SKyVw1eZho2qtrVTlDN6w8/DwNAi1Wo2ioiL4\ndBsCoSQAa157EvtT9iH9ylnkn/gFbp2HQeDsDluEd+vjWnYRAKCdWymu5OiQkpJi+Ez/JCJx0CFD\nGAgBw2DzxwttpCl38Iadh4djWtrEqR59JolL14chcXXA8C5+hpBL4andYESOCBo4GsuWLbOxpqZc\nv1sMDychuvk74laFm0mYSP8k8lD/Hij27QkAmBM90VaqcgZv2Hl4OKY5VDxsCgqFArKQNhAG90bO\niV+xZfMmREVFISIiAprsVGjz76DDQ+PsKgwDsIa9t1cFHKgCr767qFb9gqQuuKr1BwCMGtzd2ipy\nDm/YeXg4pjlUPGwKUVFR2PzzQRAjRPaJ3w3XlJiYiKCgIBRf+RtXCgQoqdDYWFNTMvJK0d2VnRSN\nfCO+1kFWJnVBpk7Cvii8bU31LAJv2Hl4OELvnQOw+4qHTWXep0nQVZRCcO+6yTUpFAq45V8HI3LE\n4es5NtTQFCJCZl4p2jmyOh39N6vWQTZI4oIKOKDSSQoU3rK2mpzDG3YeHo6o7p1HRkYiOjoa4eHh\ndheeaCrpGg+UpZ5EeWmx4ZrUajWUSiVmT34BIgED9Y69dhN+yimuQFmlDnIha9i17gG1DrIyqQsA\noMTJl/fYeXh4/kO/mrG4uBhqtRpJSUnQarVISkqytWqccKegDCKJPyoyzmPChAmG9/UD2tKFC9A1\nyBMHLt+2m/BTRl4pAMBPlwW4eOHy9fTaY+wSVwBAntAbKOINOw8PTxVRUVFwd3dHbm4ulEolJkyY\nAKFQaGIEmyP6EFPCxm8BAPu3bUJiYqLhc+Nwk3NBOuAdCqlPKygUCptPHmfksoZdUnkHkMjrPM7F\nUQhvN0dczRcg89Jxu3jaMAsi4uQPgBDACQDJ9zu2b9++xMPTElGpVCSTyUilUjXo/eaATCYjACR/\n6m3qNG8XVWi0dR/7wGgKiU0mWc8hJufKZDJrqWtApVKR/NFJFBKbTJpV/YmSXqz3+DGr/qRVMx+n\nyjgPksuCrKRl4wBwlBpgj7n02N8AcIFDeTw8dk9DPdLmnB2j98gDew5BL7kEDkLWbBgXA9Nf/8yI\nsQCAURHTTM61xeSxUqlEETlCV1EC7b3rgGftHrv+HqZfOYvbglYQCRgsnvu2lbXlmIZY//v9AZAB\n2APgYfAeO8//I6p7pHV5qM3ZYyciKi6vpDZzfqIPd180vKe/VuPr1el01HHODyR/Jsbm16pSqch3\n7FzqPPkDongx0YFVtR6nvw6v4dNo8rux7LGZJ62sbcOAlT32jwHEANDVdQDDMFMYhjnKMMzR7OyW\nUfOYh8e4OJZcLkd4eHitHqp+hSMAu8kYaQiG+Pr6L6DVEXrIJIbP9JPFxkW/GIZBaeYVVLr52/zp\nJCoqCk5eAfAvu8a+UUeMXX8Pu7eV466IXaSEwjtW0tIymG3YGYYZDSCLiI7VdxwRqYgojIjCfH19\nzW2Wh8cu0Oeqf5WUhILsdKSk7ENaWhr++OMPiEQiREZGmhzf3EIyMTExSE9Px4rPtgEAugaK2Q9y\nb2DE3Y24PIXwT2wPRE181nDOgI5BcGwVinlxts/dd5IGIEiTwb6oIxSjH3Rfn/w/ZMOTfbO4eTuf\nXHjsgwGMYRgmFcBXAB5mGOYLDuTy8Ng/REj9dh6uz3RB/mwx/hhXiF9XvoGkb7YBLp41Uh2rp0Ta\nOwzDAAAcWrUBlRUhwNMZKMkBNo+EZ8EF/Ha1AvKiE8heMRRtQ2RQq9UYP2IwGJEjwseMt6nuJRUa\naIROCNBVLTiqw7DrOfbXHuRQ1cD1/92wE9EcIpIRUSiA8QD2ElGE2Zrx8DQHfpmDRYPKcDWHELdf\ni9wSHR7L+Qwxb0+B7LUtaPvml9hz4b/H+uopkfZOQkICJBIJXAM7QIoiBAcH42DcEFTmpeOj7KGI\n/ccbf/hOgm9lOp4PzoZSqcSFg78BAGYqEuwi1bGtawk0EAFuPvUen6hagxI4oUTD4NTfe62hosXg\n89h5eJrK8S3A4bXYeM4RD39ejNWnnfF03pvYq+2FBY5bEC09hrKCHLz62RG06jfKkD3SnMoMREVF\nYUnCMgi8ZMg8dxittJkY5JGBJX+WY/PuU0hLS8PwmStx3bkb4oY5Y/TDgxD/djRIp8WRS2k2DTvd\nLigDADw3rBtE3qFA1dNHXcS8PgUAg7uVjrh84qDlFbQgnBp2IkohopaxzTcPT30UZAK75wKhQ7Hf\neQQEQiE6T3gPgtYD8fpBX5SJPDEm/SPc/vxNlKWdgfOwV1EkFCM2NrbZbcKxaPUmMEIHFGdcwtyh\nTsgtI3x1w8dkYGr9sgquDoD87j5oK8uhybuN1r0esOkAll1YDgC4dmwvMoruf/yMqa9CxOiQq/PA\nwG5tLKydZeE9dh6eppCyFNCUAWNWYl/KfogCOiHTvSNeGhSKc3u2weP5dejsDUzuqUP29wmgyjJ4\nPTYdRGTz1ZiNZexLrwEAvIv+xVMdRbjh8wjOX6u2NN+vK9B6GF4f6AK5LAhdZF5gxP420phFb9h9\nRGX4+9yN+x7PMAyCvNwhatUWci8XS6tnUXjDzsPTWHKuAye3An1fArzaYF6cAn5PvAaxSIPYxzux\nx3QYgduOoYgZ7ARBWT7Kj3wLZ3lXvKJY2ewyY2RdwiAAYUq3SggFDHq99EHtB/aOhIc2DzcPbMMj\n/bohu4xBekamza4zu7AcDowWAR4M2vUa3KBz/Dycka3zAIrvWlg7y8Ibdh6exnLgE0AgAoawqxN9\nw54A4xWMRc/1g4ujkD2GYeA/7gOEeArw+oOt8P7LIxHq7YrLotaIi2s+MXYAuJJVhDa+7pg3KhSQ\nDwB82tV+YMcnAJEzcHY72vq6gRGKIOvUy3ahmKJydJISnITA9t8PNegJqZXYCTeLHVCWkw61SmUF\nLS0Db9h5eBpDWT5w+mug+zhAHACdjrA25V908vfA6B4Bpse2Hw74dsby8V0wdUoUpj3YFmcy8tHj\n0Wea1WKlq1lFaFt8Esi+iL8Kguo+0MkDaPcocDEZ7XzdAACbtv1ss7mE7MJytHdmg+sX0hqWheQn\ndkZ6pQecRcBHS5vHE1Vt8Ia9GdPcYrUtglNfAZUlQL/JAIA9F7NwJasI0eFtDTnfhvuyYQMOVnQA\nMo/ju08X4KleQfBwEuGbI6xRbw4hmXKNFjfuFaPNze0AgDfX/Vr/Ce0fAwoy0F6YCYAdFGzF5Zu3\nkX16DwBA4+LToCeHVh5OyBFIAQDzZ82wqH6WhDfszZjaDANv7LmlRn8e+xwI6gsE9oZarcbkhC0Q\nizQY1f0/b934vkxdswflGkLevtVwcRTiyV6B+PnsLaxatwFFRUUmy/Htket3i6Ej4PmQApzOFmDq\nu/PrP6HtQwAA97Q/4OPuhOt3bWfYs4vKIS5lV51u//Vgg54cvN2dcLdqkdL40Y9YVD9Lwhv2Zkxt\n+dB1eYG8wW8aJv2ZdQHIOgf0GA+1Wo3pMQowAV2Q9ff32Lxpo6F/je/LzNj52HWdwejQCvwvMgKq\n2JdQVqnDwi0/Iy8vD25ubnad9njlThG8kY8QzXVUtnn0/rpKggHv9sC/exHi7Yob90qso2g1yjVa\nME7uCHYuZt/waFiGjo+743+rT0ua7wQqb9ibMbXlQ9e1+KU5PPbbIyb9eWYbwAjwxYkiREdHw637\noyCdFsVnfjfpX+P7EhUVhV/TXODnBqT++TXuXTmOytxMiFr3axYTqFeyijCYOQMBAyi+ONCwk9o9\nAqT+Bd3dVPx99qpNnIl7RRUAgLFDugLOnoBDw9IXfdydcK8FlBXgDXsLo67FL81ptaM9YejPyZOB\ns98BrYdh5nsLodUR3Ls/itLrxyGqKKy3f/tPnIsyDTCuiyMAoOTyITjKujXY2NiSq1mFeNDhPPLK\ngbHR8Q07KXQIoClF4aFEwFWC2DlzLatkLagTvwYAlGeeBzwC7nP0f/i4O+Ee9Iad99h57JzmttrR\n7sg8AeReB7qNQ1lZGZzkXSHy8IFT5gksW7as3rK8L019Hc5dR+KZziIAgCjzDIgRINdVZvdPUFez\nijDE8QokPUZi8pSpDTtJ1h8AEOZ0EwwjAONRf40WS7Bh6zcAgIo7VxochgEALzdHlMEJlQJnoOSe\npdSzOLxhb6GYE1Pn4/G1cGkXwAiATqPg5OQEt07DQJVluLxvO6Kiogx9FhsbW3vIq/MYyDyAUb0C\nsOidKXAXauHd4yG7foKq1OpQevcm/DQZrBfeUDz8UCD0xiCvPADA5DdmW0jDunnyuYkAgPY+zo3y\n2B1FAni6OKBEKAZKcy2lnsXhDXsL5X6TqJGRkXUabz4eXwtXdrOLc1y9sDRhGdw7D0FXKRkWJOn7\njIhqD8l0GAGAwfyIwXj/fSXauJZD0nEAdGS/uezpuaXoQ+fZF6FDG3XuHccQDPApAUDo3K9x53JB\np179wUAHDxQB7n4NPk+tViPvdhruVTryhp3H+tzPq77fJGpSUlKdxpuPx5uydd2HwK1T+CePzW++\nUeoIxtkDnd1KDcfo+2zZsmW1h7xcvYDA3qCre5Ceno6Tu75EfmklFn66xW4H0dR7xXhAcB4aR0/A\nr1ujzt38+3n4uegg06TjRo71M2OyC8sRIMgHo6vEwbPXG3yeUqlEeX42bpeJeMPOY33q86rVajWU\nSiUUCoWJgVGr1Ybc6QkTJhiMt35TYldXV3h5eQEAH4834uS3bG2UuZ/tBwB88ccF6CpK8c0n8YYB\nFmhAn7V7BH39CF3aBOGdiNFgGODhF6fb5SCqVqsxafo76Ce4BK18ICBonKkIe5rdzLq/8BJUW7eb\nbHhtadRqNbZ8swNueVcBAJ9vv8+iKiMUCgWcqAIlTj68YeexPvV51XUZfaVSacidTkxMNBgi/ful\npaXNZgMIa/La8LZIL2Lg3/NhSL28AFlPaG+ehGLuHENfR0dH399wtX0EAuhw7sc1cBXqoLt7A9dK\nnOxyEFUqlRCJGLQV3IJj6MBGn5/r4I8KLdC66DTI3duq3yulUolygTP8NOzq15EvvNrgc6OiojBp\n/DPIYzzZnaKaKbxhb6bUl+VSfYNlvcEJDw+HUChEeHh4jeP1y+EZhrE779EW6D3xjaq1CNWmQhb+\nClJS9qPExQ8CFzGEt88Z9jsVCoXQarUGw1VnmEwWBjiJcTF5DaKjo1Fw+TBulohQVK6xwRXWj0Kh\nwAMyNovnp1ON39h5/vuLcTZLi26iNIg8/cEwAqt9rxQKBRw8vNFKlwUAeGpi4wbN1ItnkK1xhbb4\nHkBkCRUtTvMz7GlHgNS/bK2F3WIchklJSTHx3FNSUqDVapGSkmJyTlRUFNavXw+ZTIb169fbnfdo\nC/Se+C9qJVBZDLR7FAqFAtKuQ0E6LQa1kUIul+OPP/6Ah4eHSWmAOieuN32GXy6VwPnWYWi1WlSk\nnQUjEOLYDft75I+KikJfaSG0xODd5Vsbfb5CocDlAmf09iyAwMER4yJfgVKptEo4hghgXD3hpWEN\nO9wbVxc+5ZcfkUvuEEILVBRbQEPL0/wMe8pi4LcGLpT4f4Kxh2hsVKp77uHh4XWGb2p7AmhIBk1L\nRd93c8YPYtMcQwcjKioKvUZGYGBbXxzY95thElof3gJQaz8bp0L+crEIoZ5Av46BWBYbDaGAgWrH\nHrvrX52O0MflNi4Wi5F2J7fRukVFRWH8W0sgEZQiADk4dOqS1SaJ31+yDAIHZ/gx+ShjXAEH50ad\n/9yYJ5AHd/ZFc42zE5HV//r27UtN5utIolX9mn5+C0QmkxEAkslkpFKpDP/W9nlT5AqFwiad3yLY\n8BiR6iEiIho3aQqFxCZT+LT3Df0cERFh0u+19ZP+fYlEQiN6BhDFi4lOfkVERAMV28n/xSV2178Z\nOcWUqwigzZPaN123G38TxYvp1TkL6M3lW2p8Ly3FktUbKSQ2mU6+P5RozcBGn3809R5NmRPP3qfM\nU9wraAYAjlIDbGzz89idPIDyQltrYRPqit0aT6TWtgJSoVBAIpGguLjYcG5kZCREIhEiIyPrbE8v\nV59BUz1m39LZvH41Km/8jZP5nlCr1fjldDoA4NA2taGfjSeh65rQNk6F/OV4GuDkCdxg666kHt0L\nB/8OYEQOdjO3oVarMf6p4ZAwxThxV9T0CpT+3UBg0E1wHZ36DLLaJPFDTzwFAGjjiUblsOvZ89NO\n5JHeY2+mE6gNsf5c/5nlse+aTbQoqOnnW5HavGdzuJ/nbdyeRCIxeIm1nav3whmGIYlEQlKplFQq\nVa2eaEPa5/pa7YGIAf5E8WKa0N+fZDIZtRo3nwKjVDQxIsI8wVufJ1rZh4iIfHo/SiGxyeTRuqfd\n9J9MJqPJo3oTxYtpUI/W5um0Koz2xD1I/qNmGr5jlubHUxkUEptMGbO86FLCw40+XxbalobPXst6\n7Ge3W0DDpoMGeuzNz7DvXcR2uFbbdBlWoqkhkLqMpPH71Y9RqVQmIROpVEoASCqV1iozIiKChEIh\nubq6EgDDeXqdGYYxGRjq0kv/nr49ewonmMvJD8ZQ+TwxbVy3mtasU1Hwuzto3OKvzBf81yfsd7jg\nFi3/dAOFxCaTeMCzhv62tYFXqVSkmtyLChWtSCAQmHdPv3mJbs4NId9n4qz2/dj01zUKjf2BKuaJ\nadVTPo0+f/16FYW9u5G9R0c2WkDDptNyDfuBlWyHl+Y3XYYFqM/oNeZHWt1A10X1QcM4Hl6b4a+r\nLYlEQi4uLgZvSm/wHR0dTQaG++lhDwaJc9YNI9r0BBER7b+URSGxybTv4h3z5aYdJYoX08v9PEkq\nlZJsqpp8n5lHQqHQbgbIs/F96O85vcz3slMSiOLF1GHycqt57Am7LlBY7BdE8WL6a/n/miRj2KKf\nWTvzx4cca2ceLdewH93MdnheetNlWICmeufGGBt1vYE2/qx6yKS2EEp9A0ulRkvXs4vowJVs+v38\nbZI9MJqcgruTk28wrVuvMrkOhmFIKpXSt2uU7FPSF8+xE4lbXyD6czlRwe0aOrQoSnKI4j2J9i4m\nIqJFP52n9u/9TCXlGvNlayqpcI6YVo90JgAUMHY2Bb/+RYMHZEujWr+OCuN8aOPMh8zX49z3RPFi\nGh+/mhvlGsC735ykiPfVrJ04t7NJMvrHbafiOG869cGTHGtnHg017CKrBPK5xMmD/bfCdltu1YZC\noTCkGDYVpVIJrVYLhmEgFotrfJaXl2f4f1pamiG1cerUqZBIJEhISAAAuLq6oqysDC5u7tD5tMXs\npL+xKd0HdzVOqNT+t+BCOGwa9Bm+iy6V48v52/HEzAR89v5M9PTIxfKRwNCsD4FsAeDbGXDzAXKu\nAZd3AfsWo/AIUFSQB/9AmaHCYW2lDJolNw8DIENVwz+v3EXfEKmh6JdZ1yoUId+jPQYHXwbDlMOb\nKUKhqwQFmjK8E82uktSnBdqiH7d8rETU8xU4cVeInVUbhzSZVp0BAIEVN1FYVgkPZweOtKyb7KJy\ntHUpBArRqMqOxty+cRW5chdcOH4QPbhVzyo0v6wYxyrDbmeZMQ2pd36/wl0L5s3GuDB/TH9AjFHy\nIny28DVsVK011HgRidhxOCcnx5DtIhQKQUTIzc1FTEwMoqOjoZXIIX10GrxeXge/FxbCve+TuHHt\nKspP78Jo31x8GTUA2l1LkLl5Jm4nzcHdn5aj6NQvSL19F/vvuUA9MxxHotzR1ZfBwsNO+MIvDph+\nEOqKJyFPuIWv/WYDXZ7C230qsOcVKZTzYgG0sKqQaYcBgQgI6ovswnJcuFWAIe197l+et4EE9X8K\n3XwZuIgI//7Dbrj88ZadAGzfj7OnPAsAuJTHQaaOtDW0Age0F6QjM6+MA+3uT3ZhOUIcq+xDI2qx\n61Gr1agsykM+uWNAjw4ca2cdzPbYGYaRA9gCwA/sJJyKiD4xV26d6D328gKLNXE/GuOtGR9bffs0\nAyU5wP4EvHJvK14Zpa+Ex+6uk3dtNrZdqEQrYTkKiV32X1JSYvDSJ0yYgOTkZDACESDvBd/uj8Mp\nqBN0leVoVXkbN3dvwt2zf4E05QCA70/uRE9xKYpunoOovBwoBHTZV4GME/joGTme1GyEU85FbKgY\njuUVz+JW8S64L1mFiGlvG/Sf9t4yvOvujsR3XkA4sw3DHJKxSSVoFpszN5i0fwD/HoCjKw6eZzdE\nHtreB6P+x/aBRCIxr3iXvD9EAuCJnv5w6tQPf+m0GPrURJNCbbbqxz4hHtDkCjB76To83D3YPGFC\nEco926LD3XRs/GoHkj6aa/EnuuzCcgRJ2afbpqQ7KpVKlHUciTy4Q6qzzZ6t5sKFx64B8A4RdQEw\nEMBrDMN04UBu7TjV9NitvTFEYzyq2laCmvxgr/8JrO4H/KMCOo0CXvwWmHkSs24+jHHfluGnqzq8\n2E2E89PdkPJGR3QM9ATDMAYvPWX/fqh+O43Os76G+PE3IXARI+e3dYjpkIOp3R1QmXoM0LL7PwqF\nQsMAk5eXB29vb3h7e6O0tBTT+jpgXM5qOJXfwy7vyViw7SLcK3LgOegFBExagatZ/23/xjAM0tPT\n8ei7m7BHMh64eQji/YpmsTlzg9BWAhnHADm7E9CfV+7CRaDDqEE9DKtK6yzP21CCwgAA21bEYmvi\n5whw0eLAxQzExsbavB+Z22fAn8/wAAAgAElEQVRxlYIQ7CflRl6rzuggSMdXP+y2+JOIVke4V1yB\nVkwu4OIFiJwaLUOhUIDKCpEnkKDgzg0LaGkFGhKIb8wfgO8BDK/vGLMmT3NS2UmR44mGt7iYuGwM\njZngqvfYczuJ5kuJVoUR3Tpjcrw+O0IikVC7AE/6ZLQnaeKlRIuC6MDySPKWepJP92HUL24HhcQm\n05hVf9KsFZ+TUCiqkbpYPWPFWKfP166gXZO82D5NfIao0DTrI2bF5ySf+SXJ39pGvj3CDRN8Jpk7\n+5YQxYtpZnirljGJmn6M7Y8z20in09GARb+TfPwC7r9jn/QiSnqRiIjkY2eR/M2vSSKR2nTyVKVS\nUfpsP/pu7hP06TpudNCmLCOKF9OkxZstfm3ZhWUUEptMN1Y/RbTmgSbLmfrBF7R17lNUtMC+1szA\nFlkxAEIB3AQgru84swx78T32R3foU8Nb+hS9iIgIu8gqaBCXfyVa4E20YThtXvdJjWXpxsZYb+Tb\newvo5uJ+RPFiur6wNz09ewUNTdhLP57KIJ1OR0S157obLzYy6Z8rvxN92JFogTcdXB5BcllQDeMv\nlUpJ6O5F/v9bQcGzviffgU/XXMCk1RBtHEG0WEaUn2HLXuWGv9dVZV6l0eLVmygkNpm6Pz2NhEIh\nDRgwgLvv13dRRB+0J9Lp6LUPEykkNpkWr95kvlwzaBsgIYoXk/LtCO4GsfM/EsWL6YONW7mRV19T\nmfkUEptMuR8PJtoytslykk9l0qdzJ5J2gQ9R1W/LHrC6YQfgDuAYgGfq+HwKgKMAjgYHBzf9yjQV\n7I8uJcHwlrHHbs/eu4G7V9nVs2uHEJXk1qj1Uj2FUL+KVOTpR/Ln42janDjKjAsmihfTuYTh1K1t\nYK0rRfX6GXvXMpmM3B1Bq0a6sP24uj9R5sk68+IlEglJJBJyFUspcMIiColNJveeI2r2771rREpf\n1lg1d759mQqVcpLJZOQ39AUKiU0mobgV93VzDqvYe5B7gy7dLqCQ2GTadjTNfLlmMKa7J1G8mMa9\nOoU75+juVaJ4Ma36KJ4befWgX29QntCBaMf0Jss5cDWbFr83lSheTJvWreJQQ/NoqGHnJCuGYRgH\nAN8B2EpE2+sI+aiIKIyIwnx9fZvemNABELmYTJ4ax66N/2+N2HujMxgqS3Fv7SjkFBThS3oScJGY\nVGFUKpVgGMZkY4L5Sz6A/+PTERi1Do5t+uGn0znouOIu1p9xRIeiw9j3TAGCrn+D/CxTPdRqNZsl\no9VCKBRiftx72PrOCFye4Y4Z/Ryw4awjMCUFCOhZo56McX2T3NxcfPxhAkp2r0D59ePwGvEaujwx\nydC3arUa0rZ98OGhCuD01+zEY3Mm7R/su1KM9PR0MAFdUJmTCW1BFoRCocnOU2Yj68f+m34EbX3d\n4eIgxNnMfPPlmsGcl0YDAJxD+3MX45eGopJxhFfxv9zIq4fswnIIoINDaTbg0fiJUz3ebk4ogCsA\n4NPlS7hSz3o0xPrX9weAAZsV83FDzzErFENEtKwd0Q8z73sY10v6zT2WiIh2zyOKF9OItsJ6qwDK\nZDJas05Fa1OuUrf4X6j17GSK+fYU3corNQmxdPcT0q6JrkTxYsqf7UGXl4az9S2yL1PPdoEU4snQ\nE+0d6dQHo9nH/ngx3V7YnUb39q+hc339pf8MQgcKikig4Hd3kJOsq0FXAOTmALr1rifRhuF29fja\nKPLSieLFdGB5JMmCQyj47W3kNTy6xoIxTtBUEL3vR7RrNqlUKgp+ZSUNjf+O2zYaScW3kylTEUpr\n9l3hVG7q/C7027xhNDEi0qKh0rUpV6lv7Fb2Sehw09u4U1BK0+ewv9Vv1yg51NA8YEWPfTCASAAP\nMwxzsupvJAdy68bJAyi//wKlunYMqoum5Cg3JH/dQOYJ4NBqXHAdgHPlASb7jXp5eRkyLpYmLMOK\nnYewLq0Vlu66CD9BEXa9MQwJ43rgx28SERMTg+LiYvz00084c0eLkV+W4uGvBLglHYD2dA349iVg\ndRhOTixC6pse+PlFZ3QtOoBfTt/BuJ0C/OA7Az8ev1VD5/r6Kzw8HAzDwNXJASW/rYQm7zZ8x74H\ngdjP4O07uktxNfBpNgf8+h8N6nO7I5192li85Xe89M4CMA7OcC1Mw9q1a7nPUhE6AIG9gfQjUCqV\nKEq/iNR8DVQq21XPzLnwJ87rQnD1xCFO5Z66XYE2zG18/f3PFs2MYXPYq556mpDDrkfq6oh8sDX2\nx40ezoVq1qUh1p/rP7M99vUPshkc96EhdUyMPe7G1D1ptKeuqSRaO5jogw5EJbk1dESVp5xyKYtG\nrNhPIbHJFDx5NTnJu5vop59IrVPPynKijONEJ75kPZajnxFd208dQoMM59VWrqC2Ql619Y3+tVdw\nRwp+4ysKm7fDdJl9RSk7IbtpZMP6xd7YNZtK5opJJABJhkZQ8KwfaOVateXa2z2PNPFSauXtSe69\nHqeQ2GSSdeplufbqo6KUKuI8adXcSJJ1b3pGSXVUKhUtfbY1VSok5BrY3mIlKFQqFclfUNCMefNZ\njz3tiFnyXohfzcq5uIsjDc0HLbZWDBFr1Nc/eF/jqp+I1FcqrC/EYGzA6pNXm6FrEMcTq1Lo/nvU\nNi7C5dMxjIbFf8ca9Omb6c3lW2iiUbZP9cnMxv446uuLuga0utrUX//sjz+nkNhkmv3daZPwUMyD\n7ATczlXv1dp3do3qIcpc1JOEQiH5R35I/hEf3rcQmlmc3UEUL6a+AQLybt+HQmKT6e3lWyzXXn1k\nnCCKF1P0nHmcDmYymYxeHhJIFC+mnn37WiasVdWO3/hFFDNjYtWk9E2z5I2Zx2ZH7f14Kkcamk/L\nNuzfTSFa0a1BxtW46uGO1XOJ/lGbjOSNMTiNMa4mcitKiT7qQrQ+3CT2LJVKycEnmHzHzqWQ2GTq\n8t73JA57kiAUkUQiMcnAME7pvG979XC/YmHV/+/i4mLyRGHcDzKZjBb/fJ71MgeNMfSzmwMoN9aD\ndkZ4Na+yvhUlbArqrwpauVZNwbO+J8+hESalizmnal3GnEdb0Zp1Kmoz5yd6cWmSbQbBKudjzILP\nOR2IVSoVPTmgNVG8mF4YOdhi3wOVSkXB09T0+fxI1rBXlpslr9dkdn3G3OGtONLQfFq0YT+9bDQV\nzBGblJutC5VKRXJZEJ1bNoK92fq/HdMbfOOr54PrjVR9nofJoHNwDdvmv/sMny9dvZG8R75FwbO+\nJ/mb35D3sInEODgb5OrrpDMMU+8TQlMMZ30/2urt6AcXALUucKrQaGnM6r+ow5wfSNa+K0VEsIZw\nzRhP0sZLqG+HwOZT1jf1IHufLvxEv5y9xQ5YfcIN12SREIJOR5TQmmgnm5o3fHkKBUcsts0g+HMM\nlc5vRWNX/8F52rCuav1J4vuvWOx7oFKpKPjNr2n3gtFECW3Mljdi/ldE8WI68uHzHGjHDS3asC8d\n5UsULyYnYQO/ePqNDX55jyj3BtHvC9jX300x8aDrMnjGXn+tKy9rQS9r87qV7A/3M7b854Vb+TTj\ny+MUPOsHCn5nO0keeoWErp4G46k3oPrcdb1hv59ujTGc9Z1TvZ26nhSMj1u6eiMFv7Odhiu/NSyU\n+urTxaRViGn762F15tfbk6FXqVS08An2e0VF2RS38wx1jttF5ZXaGvMgnJP4DNGng1gn5Pk4av/u\nN7Yph7zpCTo9vx+9kXTcIvcnN15Gfy1/kTN51ZEFh1JIbDL9+nonok8HmyVLpVKRfNx7VKLwYe2G\nndCiDfv+Fa8QxYupq1xy/y/evWvs4/VXEaRav/6/L+u+peyP+Ohmw6F1eSkRERE1fth1ffFrGMKq\n5fanD++hVz/7hw25xO0i/xHTSOD2X8zbxcXF5LyGDB716VEfXIRHjPtKJpORuP+zFBKbTD+dzjR8\nnjzBhe7M8qz1yYhrj9BcZDIZ7XjBhS7NcCeVSkUPfbiPXtp0mIhq1sLnnD3vE82XUruQIPLoN5Z9\nUmjbybr9o9ORbrGMEuc9Qx/9eskiTVxYOJDOLTTP4NbHB2vYTaxPvBnErtA2A5lMRpLwlykzLoR0\nO1/jSEPzadGGnc7/YLKDeH3G7fLScCqZK6YZk8aZGkqtlmjzKHYZfNWmHdVDLtUnEQHUGePWY7yX\naI8OoVQc500/xQxmJ0Xf/Ioil35JecUVJhOn+pBS9XYt7dU2Rb5+4DJeWq9SqUgmD6YBiu3U9/1f\nKaeonFQqFU16wK8qtJHMSduWJCJiIt151502P+VM0qA2FBKbTK8us/wSeCIiuvCTYbJZ1vcRdkL6\n48+t2z9Vsf7Z771Fr3+UeP/jm8Ch5S/Q3fgQi8gmIjp+I6dqr1MpJY33NkuWSqWiVg9OpItxXejK\nkiEcaWg+Ldawq1QqeqYvu8kwXd1LRDV3/dEbyK2fLiNNnJiWDXeqdWeipE+XUMlcMV1Z+qBJG9VD\nFXpj1pDQS0hoKDkFdSKvx6aTKvYZ0ig8aejkeeTeYzgxIidycXGpkVljHMe2Jy+WqKYBNu7H6p+f\ny8inNnN+ojnbT7MnayqoeEEQ7ZrkZTcGvC6GdGazNqaGOVGrAWNYr7lbf+s0np/536KoNh0pJDaZ\n5I+9Yt0+q6rnMmb2xyTrNcwiTezdMJsoXkzakjyLyN999ha1jv2BNHFi2vF6mNny5MOep3/iwujP\nac1v8rTZbbShVCpx/kYW+6LkHgAYFtQQsaVsk5KSkJ6ejqxflkEgYLA9zduwFHzt2rUAALlcjulz\nl+Gjg+VoV3oCislPQiQSYeDAgYZ62PrytCkpKVi7dm2dS8mJCMqVG1AYMhSax+bCP+JDtO/eE/9z\n3Isv/3XHnxsWouj0byBNOUpLSw27HukXJE2YMAFCIbszj760rq2oXobBuGSCWq2Go6MjGIbBhAkT\nanzeJVCMSQ+E4svDNyDvMQjqTZ8h8VQ5HpFXYvWy+Ta7poagnPokAODRl99D2OgIUGk+4l6fbJ3G\nxQGAuz9uHfsZ6dcuQVOQjVInL+tutHH7DLTE4BLJMahHe4s0QV7tAAAFGRctIj+7qBzeyIdQAPxz\n4abZ8l4YOwoF5IY2gT4caGddmp1hVygUcPCsWlFWZdhTUlIAAAzDQCqVYsKECQiVByGqrzOY9sNx\n6EIGEhMTDStE9caIiLA11QelAjc8ot0HrVaLw4cPG7agS0hIqNOYl1VqceDqXTy35GuEzvgcwlEK\neA6eAG8XAUr2rceMtDkQCRgIB88EwzA1zicibN26FQqFAomJiYaBwyIrHBtB9do3xrV3lEolSktL\nERQUhMTExBqfA8Abj7YHlRWisvvTiI6ORqpkEByEDNZNf9hm19QQHmrrAjiJ8ey0ubgDCcY+0BlT\npljxPgT1wcOdpJDJZGjlUA7XoI5WHeCP/fwZ/i31QEm5Fgf37rZIGw5+HQEAhRkXLCI/u7Acfkwu\nAEDjYr4xHj/2SRTAFVKXmr9fu6chbj3Xf+bG2NXr15FWIaajHz5b98TW5d/YcM35H03O1edmMwxj\niJf/tXwSUbyYHm8nIgcHB0NIxFimrE0Hcg7pSfKR0fTcuoPU/r2f2bj5O9vJ91kFyR8cT3fyS9lG\nsi4SzZcQ7ZpjaFMikZBIJDIJucDOwi5E9ce+GxoXn/7hFxQSm0yunYeRRCKhk9MllL2wk6VUNhuV\nSkXnZkgobXEYXbjFln395oh5i1saTUoCu3l2aT59tPsitZ6dTKUVHGyc3UCuveFO370RRgEvraQB\nAwZYpI1T12+TRuFJV7+eYxH5720/TS+9HUsUL6Z+gQKzQ1nXsovos7nPUvlCOUcamg9aaigGABa8\nvxA5pTqc/yfFsBuQ8Y4zarUaie89i4JyYOgrSohEIkRGRgKAweskIoOnH/nx77iWq8MHj7vjo09W\nw9G/HVw7DYGu8wjM/z0DQxL2QvjccviNXwRBtydw+Ohx9HEvwMZJYYhpfw9OhzchbuLDaCV2ZhXc\nuxBwcAWGvg2ArSeTm5uLyspKEBFUKhUkEkmDtj+z9u5Q9dW+uV9dHH3dm6RFM+FecQ8+j0wGI3LE\n5mMl8KnMBO5esbT6TWL5kgXo5KXF14duYPp8dlfHb1cvtK4SgX0AEHDrFLoEiqEj4NJtK+3rW5qH\n1hIBLjBtUZl3C0ePHrVIM/5enkgnXwhzLFPlMbuwHCEO7NN2RiGZHcrycnVEAdwgqiwEiLhQ0Wo0\nS8OuUCiQVSrCsF7tMTdOAVlwKObMi8ea9Rsgb90eb707C6PaEHZeAQ6dS4VAEoht+47iwNW76P74\nRLh1DYek/9PQdHkCA15fifJB07BC+zy6eetwOe0GAiZ9DN+nZkMyNAKMJAg95RLEPt4JW17pD+23\nb+PmhhnYFjcR1/76Aa9NnWwwdmq1Gk/2DgQu/AA8MANwq/1xUG/oc3Jy7ht2iYmJQXp6OmJiYgzv\nWdvY14exLvpBNjc3B9d3LAfj5oWxMStwINcHBAY4t8PW6tbKR29NgIBh0Hn4JJzL0aHyXhq2f7HR\nukoE9mL/zTyBzgFiAMCFW1ba1/fOWQDAZedu0OXfNsyfcI23uxNSEQCXwusWkZ9dVI6evgLowMBB\nEmh2KMvDWYRCuEEAHVBx/6KD9kSzM+wvbf4Hi/4NQKakJ4pLi7H0WiCEE1Zj2fUAfHA9AMIXPsa4\n12bBy4XBvg6zIJu+GYGT18Iv4kNM3HAY572Hwmf0u/B8aDIce45Ghk4Cchbjx4IOuOXcFgs9v8dz\nrbJxa/PruLl8HDLVU1GwawUWR4bj0v6dCB88EACg1WoRExMDuVyOyMjIqqqQMXi3Zz6ySxl8dtnd\nULXRHAOsj88bx+ltvYu9Mca66CtAAkBJ6imUXjuG3zOE+N9bC8AEPwCcrbVUv80Z2d0bAINHX5kL\n15AeKE09BaFQaN2B080H8AwGMo9DLnWFI6NDzJJV1tHh9hkAwHlqjVVL5hvmT7hGKGBwx0EGSclN\ni3jA2YXlCBDkQeDuh9Sb6WbPVQkEDLSO7CCL0jwONLQezc6wj+oeAN2Zn5GamQN/TSZ0J7/HrBEd\nMfuJTmidfwI5e9R49M4W5FUKkZlTgWXP9sDqF3tj80v98PWUgXhVlgXtDwq0OvARbn7wNDI+nYSs\nxLcxd6gXAsYuhmdpGj4YpsPqhXMg0LGhE32WTUxMDJKSkgCwhjY/Px/p6enYunUr0tPT8XBQBR4M\nFeGS/1jELVxW5b3m1jDAxl7u/bxv/QRuQkKC4b1aN8W2AWq12pBBpFAokJKSAiKCRCKBUChE7v7P\nwDi7Y9GOI4j5/BCQfQHbPn2/zmu22ZNI2mHArytO3NGChI4ou3ESFRUV1h84g3oDmScgEDAoz7qO\nCldfTJ061Wzn4L7cPoMKZx9kQ4JQb1fLtQMgzyUETlQKFN7mVC4RIbuwHL64Z1a53hpynT3Z/5TZ\ndgOURtOQQDzXf+bmsUskEpoX7kYUL6Yg3/9Wn8pkMhIJQPdiPOjL5z1rnGMyGVpLmQCZLIhuLerB\nltYtL66xYMm4fotxvRgXFxcSMqCz0W50eaaY1OvXUkREBDEMQ66urjX2HK2+VR3scBK1IVTXvXoB\nMYlEQoHPvEfB73xHga2kpInzoOVP+tR5nk0KhWm17CK1H9+kj3ZfpNDYH0nSKsD6y/mJiP5czk74\nF9+jsYu+JvmbX1tlkj17YWfa9zq7KCstp9hi7RARfaKq2g7w2h+cys0vraCQ2GS6+0Ffoq0vcCb3\njfj3ieLF9MOqWM5kmgNa6gIlvVGY8SC7qrGTj8BgTCQSCY3sxO4mtPuTmTXOqc8I6Y2tYfHTn8tr\ntG1cv6W6sX5joBNRvJjGdhLVMNi1/d90QGn4CkN7WrFZ10pdY27cLabWsT+S/5Nv076X3OnS62KK\niJhY68pe/YBp6Wsz6cPb59j7fTKJnl7zFz295i+Ltl0v/+5jdbnyO33xdyqFxCaTVG65+uVERFRZ\nTmXzxLTi5b4U/O4O0mgtu/PVJ9t+J4oXk+4It5t2X80qZA37HG+24B9HjHxpOlG8mF4e5MeZTHNo\nsYZd/6PcsXouUbyYJvT2JKlUavD2tjzvTbQwgKiixMTw1JYSWd1TNKxK/WIc0RI5UfG9Gm0be9v6\n87euXUbl833pt0likkolNdqrPoiYY5jtycNvqKf97KKvKHjW9/TWcBlRvJh6BzjUuA+cbhJ9H0z6\n8MgmdlvBdDbF0LhOitUH0ZJc1rDv/4DiV26mkNhkemeFhWuz3zpDFC+mGVMmUJ95OyzbFhGp91+h\nMoU3lSXP5lTuoX/vUvtYtrb9B6N9OZM7beEqongx7ft4CmcyzaHFGnY9m9etZGtbDHEyLP8PlgdR\n8YIgoq//V6uxqP5DrbPK4a0zRPOlbPXHahjL0HvwP0eKid5vxRYcI8saX3vy2GvrP+Owl96T9wpq\nQ8HvbKcuT08jrcKD4h90qnMXJ2tcl3FblxIepqxZYvINY3cvil+5uUbJB6sOop/0Jkp6kWQhbSg4\n5geSPzHVsn1z4kuieDFN+egLemXzP9zLr8aPpzLoQlxXKth0/x3QGsMPJzNo8OzNRPFiSlkxmTO5\nq5MPs2UQDn7KmUxzaPGGXSaT0Y033WnL087/FefS19M+/W2NkAfRf6EU/cYJtZWk1f+Ijn74rKGA\nVV0/LKlUSjP6O7DHHVxdQ4Y9GF9LUtt1Goe9jAui+Y+aScGzdtKfkyV0Yqqb3dRo//dNCe18wYW8\nR75F8plJJBQ51Hgis6Z+V5Y+SOlvs3sNyKaq6THlt5YdYHbNId37ftQ17ida8MM57uVXQ7FyM/08\n7xG6s6A9p3InL9tKz8z+iP0tXv6NM7mb9l8mihdTya+LOJNpDg017M0uK0ZPeHg4zmfr0MOPrbGS\nkpICnPkWEDkD7R8zZI4YL9GvnjqYkpICrVZrWKgE/Je+99zKvwH/7sDOaCStjDepl6LP3Ni64GUs\nH+GCE8V+kD+/xJC50KgNrpsxtV2nfmNrfWkHoVAIIoLo8l6IhELsFQxEL38hHugUaKjFY7O0zaJs\ntPHU4fhdR7i2DYM24wy0mkpDvR5b3Met+84jyAMQC8rA5Gei1MnbsllQt09D49sZRRWEUB/LZsQA\nwKbVy5FK/pBosgCthjO5u/84hFZ0l33BYVbMyaOHUUguOHvc/M29rZr11RDrz/UfVx77vGGOpFWI\nqVvbQNq4bjWb3VBL+ERPdQ+sttcmsficVCpeEETpb4tpSHuJyeP55MF+RO/7Ea0dTJ1bB9W7u1FL\n99zrw7gPnl38FQ2JURmecGzeP1UVDa8e+Y1CYpPp9Y8SbX6/fljFVkB8obeE/pfwJYXEJlNBaYVl\nGtPpiJbI6c7WaRQSm0wpl7Is004VKpWKJF7e9O6cd9jvwL1/OZP95MJvaP67LxuyirjCp9sQSle0\npq2R5j8tcfHkhZbusSsUCpwp8oKAAc7sXIVX+roA5QVAn8g6z4mKioJCoUBMTAy8vLwAwMQjq1Ge\nQBqCEV8UA6TDnhd0iPI9ge/eGoJ9r0qhfrQUWYwPen10HX0HP1SrR6X3/vULmexhpai1MfZ6D29+\nHze1PrhQ5gVc/MkmHrGJ15T2NyB0xO5c1sNTTHnO5k9aT0bNBRgBvvpoFvwcKwEAsq4DLJPLnncT\nKMvHnhs6AMDh33/kVn41lEol8nLu4VpZ1aKfe9yVFpAGhKC7DwChE+Ai5UxuRWEuCsgVYifzC4FZ\nc/1JszXsUVFR2PlPGuApB/YtQsnPChy9I4T61/O1Hq//QcfGxta5cKi2jj+bDfRRFePL8wAu/Ij+\nBT8jvIs/8HAcBqnzcOpqJlJSUpCWlgYAJitR9WV5bR5ysAPUajWKsjNQevZ3/CocCt2Ng0DxXavr\nYbJq9+ZhILA39lwtQA+ZJ3YkbbH9AOzkDvh2AjKOY8OHCwAAOs/AWr+vZlO14jTpZB5Iq8GqpQu4\nlV8N/e+r1COEfePeVc5k61edwsMfqKWaalMRakpRADdInM2XaVVHpiFuPdd/XIRiDFTN6ufPEVMP\nP0GtjznGGTISiaRR25yZhAu0GqLyIsM+qXVl2dwvG+f/I/q+cRD70shZVQtxjidavW/07W1cv4Y0\n8VL6dFwAhcb+SBOXJlk15bJedk4nWhpKUqmEZDOTyGvEDMvksu9dRDRfQk8rvyDZtA1WW5Q1fME3\nlBfXis4ue5wTeSqVioJnbqXT8/sRbXiME5l61qxT06/zwun023Kz+mb9ehXJug2glWvVZumDlp4V\nY8Lts/TF2g/qNBC1ZchYgtq2jeNh0RvUAQMGkNejUygtrjUVfzauRqaS1ajKoHrukZ7sbkm9hlrl\nO9IgqnLrkz5dTMGTPqIHFNst087WF4hW9aPRK/+k4MilVhvU5E+/Qyfndqf9k6WcyJPJ5RQ863u6\nGhNE9M0kTmQa8+17j1NqrL9ZfSNrW7Uz1iORZunSUMPebEMxJvh1xcRp75o85hjHUmvLkLEE+iyb\njIwMm8dq7Q39Y2hGRgby/96GX7V94JCaAndH9vPaNiOxKGl/AwCu+D8ON6EWcdGRdrHRCQBAFgYA\nGD+4HQZ0DEJGMbBeZYHw0O0zoIAeSL1XjH6dQq0W/xWLdLjOBCHEXctJ2OvtOfFgBAIEuVQAHgEc\naGhKudAdEgdtk/tGrVajRMN+v8eOfIxL1eqkZRj2WjCOpdYX2+IyBcleinPZMwqFAgESV9x07Q4H\nqsDK2Ek1ipxZhZuHofNqhyL5YBRePACGgf0Mxr6d2Xr+Gcfw9y/fgRE5YuHH67ltoyQHKEjHos93\no7BMg5HD+lvt+m9cOInrugDIxcCyRebH9R97ahzcUQpnlOPw+RscaGiKwM0bHsIKRL36apPOVyqV\nKKpkq1k+PaoZGXaGYR5nGOYSwzBXGYaZzYVMc2mokdUPANHR0WYb9/8v+evmoO+j6NfeQS65I4TJ\nMJl41t8Di+b8EqHs6mQd0JsAACAASURBVH58dSIXlSRA9onf7WtiWygCAnoBGUcR9dwTAIBxUW9w\n28bt0wCAA7ccAMAqOex6HhrQC9cpAAIGWBIzxWx5xlviffH9XrPlVUfn5AkBiM26awIKhQKtZK0B\nABIXBy5VqxOzDTvDMEIAawA8AaALgAkMw3QxV665NNTIKhQKCIVCaLVa+/pxt3D8JO644T0UbfMO\n4GZWfo0a85aoOa8fLL5ZuxjOuhL8re0IXXkxym6cNmyIbjcE9QFunUZM1HiIBAwCu/TjVv4t1rBn\nirsBAEK83biVXw9D+3bDNWJTTMc91NtseVlGhn3Ec5PMllcdgYu+dG/TarJHRUXhk7WsgyJxdeRK\nrXrhwmPvD+AqEV0jogoAXwF4igO5ViEqKsqwkXRt3r097VbU3Kiv7rpUKsXSL/bBkylGwhKFSV13\nwDJhLf1g8c93KwEAZ7yHo/Tfo4BOY7L62C6QhQHacjjdvYC2vu64cIvjbfJunwHEQZg0+0MIGEAu\ntZ7HvjJBidQqw85FyuPPe/+CP3IAAKPHc/+0LHCRsP8pa/qOVnkl7JoEqWsz8dgBBAFIM3qdXvVe\ns6Eu716tViM6Ovr/fQ56U6nL69YvBPvhRBZKtEL0d01HETmZ7FtribCWfrCIGtENxYwbrjt1gCb1\naIP2nrU6QX3ZfzOOoXOAB/fb5N06Bfh3x57Dp6AtyMbnm623FaBi3lwUllYiF2JODPveQ8fgr73F\nvvDk3vQ4urMLniqKc5ssI6+0EgwDeDg3H8PeIBiGmcIwzFGGYY5mZ2dbq9k6qe5N1uZdKpVKaLVa\nQ+0QnsZRl9etrydTqgF+vabDY8JjCHj0JcNxkZGRJhuQc4V+sOjomIX9ub7QVVYg/9LfJgOK3eAp\nB9xa4fK+JGzftAq38suQW1zBjeyyAuDuZSCwD86m3kHZ3TRO5pgaSlRUFAIlLrhc6onb5w6YLa9L\nn4EIpCyUCtwABxcONDTFycMbAFCcf6/JMvJLKiB2doBQYJ3sLy4MewYAudFrWdV7JhCRiojCiCjM\n19eXg2YbT/WNl+8X07VWmmRLpTavW9/3o0ePhkQiwa/XgQBBLvp2DMKIZyYCAJKSkqDVag3bEJqL\n8X1PWpsA5N3EEZdB0Nw8AYmbs30O2gwDyMIguHUC2VdOAuBwc+tbJwEQENQXrq1CoM2/Y/U5pswr\n5/Cvzg/C/FSzZbn5BKKrVAMXv3bmK1abfDHrsZcUNN2w55VWQmKlMAzAjWE/AqA9wzCtGYZxBDAe\nwA8cyOUcY+Nd3Zuszbvks1y4R38PkpKSkJeXhz+z3ECMEI8Jj2LNPvaxXF8VcsKECZy2qVQqceTb\n5QCAA+iJzxfMQE5Ojv3e36A+aCfRwZ/YJ9xNO37lRm7GcQBAj6eno1QnwNhHBlk9Tbdf9/a4IQyB\nrwuZvZ9oVmEZ20diGUfameLm6QMA2LB2ZZOfanJLKq2WEQNwYNiJSANgBoDdAC4A+IaIzpkr1xIY\nG+/qRps34tZBfw8mTJgAmUyGmbHzwYQMwjjXk/jueDpu3itBYmIiNBoNEhMTzWpL76mHh4dDIpGg\nuLgYY3v54p7GBWlMAB7sYJsnxwYTxC5UGuSvgaYoB7/+U3sdpEaTcQw3ChhczmcNzcQxj1r9uz98\nUBhSBcHsCzOKgRERsgrKIdVmA56WMewSqRd0xMCByhEbG9vo8/9a8RJcT2xG4b07FtCudjiJsRPR\nz0TUgYjaEtEiLmRaAksYbz5rpnHo70FiYiIUCgWUSiUO5nrDtywVbQW38Pq6ZMjlcgwcONAQZ29q\nH+s99ZSUFLi7uyM3NxetBRk4jG7IPvE7Xn2Z+9Q4TgnqCzACvPPcIAgLbiGgcxg3cjNPQOPXE63a\n9QAAtPV150ZuI/D3dMY1qlolaoZhLyjTwFFTBGdtscUMu9TNGYVwgZcLu7dAoyjKwpD8HVjn/SWu\nnz9pEf1qo8WuPLUWlsi3/v+Cvu/eWv87AOB/Tn/hZL4z7pQJcPjwYUOcval9rH86CA8PR1FREXqG\nSCBz1+EQdUXR2X1ISkqy74HZWQz4d0cf73JMm/AkcrX/196dx0dZnQsc/52ZyTqTZCaQhJAFAiiL\ngAupCrhEUIttXdtauSDS3ju0caltvYV61VFjay9YtWpbvAzaarSo15aq1A2XXNSCEmTfZJUsQEIm\nk32bmXP/eGcGAglZyMw7Sc7388knyWRm8ryTyTNnnvec58TQ5vWd2X3WV0BNCaMv/R5Z5+Qi21q4\n9+4f9028PTDcGschmYpEnNHMmMq6ZtKFv/YdghkxoM09r5VmUhKjWbJkSc9ufHhz8MubJiX1cWSd\nU4n9DKk2Ar0XeOz+456HIP1cxh15C9nahPXy+ZhMpmCdvbePceDdQVFREW63mytHaYtDNrVm4Tm8\ni9mzZ0f+C3P2VCgt5py0WFq9PvZV1p/Z/fnr6299Wc6eijraXGW80kcnqXsiPSmWFqJpiBt+Rom9\noraF4cLf/jkp6/RX7iWjQdBgMHPOqIyev9s/4d3IpWNUYu83VG2+99o9duOuZUpKG0k7/pf4MRey\n8HfL8Xg8XHbZZcGT3b19jAMvDPOumsgxmcgN190UrOFH/Atz9lTwNHGeUeuBcsYzY8q/1Mo7jxcS\nlZxJW1UJubl9VOLpgbTEWISAqphMcPW+FPPqm+8yXGiLk/76z//rq/BO0WS0YGrrxSIx1/7gl6my\n97NqekoldkV3TqeTK+96EoAvC2aRYY1jkxiFzyc7HFH3pHwSmF7peOB+crz7+Vyew3enZAbvAyKo\n+VdHRkwDoPzDZUhvG6++e4bzvku+gNQJ/PxXD2KyptHmKqWs7JTZySEXZTRgNnj5eF8jrYd3Qk9r\n134r3/2I4eIYHp/k3kef6uMoNU6nk6N1XkSTq+c3du2jZeg5eKSBZJXYlcGkoKCAD7ce5kCNgag9\nb7Nw1li2l9eycmNZhyPqniT7wHVfX7aEBI+Luqw8rPHR7e4jouvsllRIHo1r4z9prTjIJ9sP9P6+\nvB4oXQ/ZF5N33Q8QwkAijbq9W6k7WsKethSiZTM09G7R4tQrvslwWUF5veD+Bx7s4wg1BQUFuJoh\nztuLEXtNKU3mTNxY+GL1G2F7jqnEroRcV4kzsBJ11V6Jd18R154dz7lZVn77zk5unjP/lO6PJyf7\n07V+yMvLw2g0clOe1uzqaFNsu20LAzNzIrrOPmIqFw8HT+V+jENG9HxmRsDRbdBaD9lTg7X6KWdl\nkZ+f3+erfLtjqNnIQdNI7Zte1tnTRp5NTkwt2ROnhuxdl8PhoMEXTZKhpec3bqqm0WSlRpqJ9dSE\n7TmmErsScqdLnIFSSUtLCy9trMeIF8Put3n0xolUN7ax+L1d7e5jwYIFrFmzJpiQA7c/ufVDoNHY\nyy+/jE+YmBxbzqHo0fzusceDUyADJZj+UGdPjoNzTYcwxCVSWdeLBANQ8rn//i5mX0UDQsCqFc/1\n6Srfnqj8eg9fR5+lfdPLKY+bdx8guaWM11evC+louLYVzKIZ6W3r/o2khEYXO0pc1GAmJU6G7Tmm\nErsScqdLnIGE3dzczBdlXg64JWv+dBf/vehO2ra9z18/P8SGr13t2uqeOAUyPz8/OPo+sfVDoNGY\nlJKMi75FrnEfXxty+ucK4+ypADjzrwBgR29PoB5aq80cScpkX2U9GdY4bvn+d/t0lW9PjE63cTg6\nE4/s/ZTHkqPHyDDVsOtoc8hGwwUFBRypbgRg+f/8qfs3bG0AXxuf7y7DLS0MifGF7TmmErsScqdL\nnIFEO2fOHDIzM/n7HgPT0z18+OYKSt/9Hzy1FdiXf0LRp2uDt/F6vWRkZAT76J84+j7xfq1WK8np\nI5g1bRxRwstTf/tXcIQeGO33C8mjqDNa2bpC223ohTc+7Pl9SAmH1kH2xQDsqahndIqlz1b59sa+\nrcV4MXKgLqrXiT3HZsQkJBWtoev543A4qGn0AvDin5d3/4b+k61pZ0+hgVjiDG2qxq4MDievRH19\nlzZv+JaJseBp4diqJ6hqNdA66QZsNltwb9Ti4uJO++g7nU4WLlyIEILL71zCzOjt1LYasIybQVZW\nFosWLYrsmvrJhOCtHQ1cNtyDrDnMh1/u6vl9VB+AusOQfTFtXh97K+oYl57Q97H2wPybbwSgbcjY\nXpVimlq9pKHNYX+68M2QjYbtdjvT8q4E4NZ/+373b9iktfm1ZE2g0WsizuhTNXZl8CkoKGDd/hq2\nHPXx3bGSpKQkPOU7qVn7GnETrsAycQZz5swJlg5Ofidw6623YjAYWLBgAW63m0ZLBptrY7k2dhOJ\nF9zEh0VrKC0tRUoZ2TX1DqRd/AOssYKJjeuRicNxOp09m82z72Ptc04e+ysbaPNKJqQnhjboLvx4\n3s0ArNlXj6dyD/h6tqr2aG0z2aJC+8Y2so+ja++SvKsAyD1vYvdv1KiN2I+2xSNNsVhiDKrGrgw+\ngbLMLtM5TM828adHf8XSpUsR297GU76DqGnzuePh3wcXLp2c1FasWBGcMWKItTDkWz/jgsZ1mD1u\nmHBd8P6XLFkS2TX1Dsy0PwIILjduxWBNZ9F/3d+z2Tz7PoKkbBgyml1HtBr9uGH6JvbUhBik9LGz\nwYIJD9SUdH2jEyz/6+tkiQq8GFj+2jshnbJqSdJ6sjfX9WCzDf+I/XBbHFFmG9b4aFVjVwafwAj8\n5kdeAwSzx2knm6pdVWx/9meMTLFgf7GY4oOuDpPa7NmzEUIQFRtH2k33YUoYwn8O3wKmOBhzZeSf\nJD2d+GQYfj6Xm79GGIw0RFmpqqoiLi6OhoaG0yc0rwcOfAKj83AuX85dDyzGgGRUSvj2Oe1IlNFA\ngklSGuvvo165u0e3f/H1t8gWFRyqM/LwI78OaXktwaa17n3jtZe6/+LhT+wlTbEYYszgbdX+FmGg\nErsSeazZMHoGbCwEnxen08nEsaO4Jm4/Qy0xzH3uc773i0dPKacUFhZS09hC+s0PE501CT4v5KKo\nfTBmJkSbI3shUjd8WZdMrq0eG7XEZIyjqamJ1tZWqqurO51KmpWVxRtLH4SWGhg9Q5taGjcEr6uU\nKKN+//6B2JJMXpKnaRusUNH9tsROp5NWYzxZogLjkI5nO/Wl+MRkAGJEa/dfPPwnT3ce87B11x7t\nsraGUIR3CpXYlcg05TaoLYO9HwRH57+57x42P34b9aW7WXk0masf+Tvj826krrmNY/UtvFZcwlVP\nrMGQPh7f2hf4481joK4cJtwA9P9OnPcVrsVogBmta7CMnIzNZgv2tT/dVNK97zsBATmXk5eXR3RK\nDmmx4Rk5diYQW8nuTeyqMULCcKjY2aPbt0VZyOYo2ZMvCfm7MRFtwSMNpCTGdP/Fo8mNjDJT1WKg\nulabLklrY0jiO5lK7EpkOvsaMKfAhhfIy8tDCIHb7ab6yCHKXriH5s9fZcOhauY+9zmTHnqf3F9/\nwMLXt2AzR/P326dz6P9e4zsZNRCTCOO+DfT/Tpw33f4QJXWCm5O2kzPlClwuF4WFhV1OJZ13UYrW\n2z0+maK16zEmDGH35x+TnJys27uXQGyXnDeecnczvtTxUNH9/XkcDgfpw1JINjTwmz+9HPrjEIIG\ng6VnHR4bXcg4K8IUjU+YtMvaVGJXBjNTNJw7G756l93rP2q/jF76aNn0Fv/61Qyen5/LolnjeOA7\nE/hb/jSGFC/jG6NSsM+bDTvegHNuhOh4oB8sROqCfcECsq66nVx24Ha7eGLpc6ctLdntdkq2fEpK\nWylMuA6AeXfdC0BrxYFOSzjhEPhbWKO8eH2SDeVeqPyq2zVou93OzHNHALB+f3iOo8lowdjag8Vh\nTdV4orX9Um++xV9ualWlGGWQW7HPgsfr5aFZqVitVmw2G3Pnzg3ObImPNjFjXBr5eaP590tymDLC\nxiv+jbDl9pXQ1sgbhxL6dV39FOOvxSjbmGHYyJOFb3RdWtr5lv921+F0Oil8ew0Acc2V2Gw23d+9\nvPXKXwBY8a+D4G3R5tt3U0K9dl23KSUsx9FiSiDG05PE7qLUrbV/2LHrK+0yNWJXBruFj/6BV7e1\ncVn8fqrLD5xSegj0gzmxpBDYCPv+q1Nh6NncufgFSktLWbhw4cBI8FkXIhOG833TJ0y7dk7XpaUd\n/4BhkyA5h4KCApri05B1lbgOl0TERt53/lBrZZA2/QfaBd08gdrc5iWt7RA+jBRtOhiW4/BEJRDr\n7cFGJ03VbC/RTqC+88572mVqxK4Mdg6Hgxf3WbFEA+tPXcod6AdzYkmhsLAQz56PGBlTwxrPZOrr\nG7DZbLS2tlJaWtqrzYgjisHIRiZwidjMgb07Tr8BScVOrU3vJG21pMPhID5zPOek6zvN8UQ/XzAf\nkDy35oC2TV43T6AeqWlmtCinwZylle3CwBeThNnXQIvH270bNLqwZY8H4NrrtRP4asSuDHp2u533\nNpfDWd+Ez54OruQLCPSDsdls5OXlBUfvJa/8J8QP5Ue/fw+3243ZbCY6Wvvn73XL2wjyw6c/AmB2\n2gHy77q781WoG14AYzScp9V3r//BrQhzMjddPkWPsDsUbTLgq6vCJRPY75Zaa+FucP71dUaLckpb\nw7cRt4izkigaqKpv7frKUkJTNZaMsQB873v+VgRtTSGM8DiV2JXId+VD0FoHax5rd7Hdbqe6uhqX\ny8WqVatwu92cb60lq2U3vymqY+qlVwRLFUuWLAnW5vszp9PJ1pIa3i8zMy/qI6yZYygoKDh1KmdL\nPWxeAeOvBbO2uGZzaQ0A52VZ9Qq/Q776Y5isaRSXtVH31addXt/pdPLH5S8yUhzh462lYYhQY4q3\nkUQDF11+VdclvZZakF7e+mQTBiQWi3+VryrFKINdcBT65mdw/q3w+bNQtiHYE8ZsNgdHqzU1NRgF\n/O6qWA7VSB55v7Jd18f+PiMmoKCgACklv/m4jiGijtunJpCXl3fqVM71Tmh2w0X5wdtuPFSN0SB4\nwvELTCaTLptrdGR4UgympDSKy70keKuh4fRbyBUUFDByaBwxwsOOsi5W3fahaIuNWNFGfVM3WgT7\nV50ebY3F21SLiEnQppzGhelFVUoZ9o8pU6ZIRelKZmamBGRmZqaUTW4pHx8v5TPfkNY4owSCPwtc\n7/7LoqV8MFHelpskMzMz5bJly/Q+hD63bNkymZmZKefOnSuLfnmurLo/TZ41/KTjrTsq5W+zpSz8\nbvA2VqtVZtz2pJz4878EHzuj0ajjkRyXdc1PZPbCN2Vejvb3k3tWn/b6y5Ytk3Pn3CTlg4lyaqZR\ne36EgevjP0r5YKI8/8obun5ulW6Q8sFE+SP7bfIbD6zssxiAYtmNHKtG7ErEajcKjU2CG58F1z4+\nuXMEcVGCqKgoqqqqqKqqYl6ulYfzYlm518T0BY8NiNH5yYIbczscFBUV8cvN2cQbPDxztYHDZf4y\njNcDb/5Uq+Ve/WtAG+HWNDRjTMmhdMNHwfvTY3ONjlw3czpCGNjSoC3bp3zjaa9vt9uZnKztZLS1\nwttuE5ZQMvsbgf3i7tu7fm75R+zpE6czOnNYqEM7hUrsSsQ6pXyScxlc9wcmxh+j8elp/FtuMmMS\nWnBM8/H8NT4MWRdy4/MdJ/T+3icG2rdEcDgcHK6s49eeuXxzhJd35iez/Jff5eBjl8FX7/CZ5RpI\nHQdo+77GZk5AGE00H9qKEIJly5bpsrlGR6xR2iwTQ+oY3KYUKDt9YgeYlFDH/pYk6luhqKgoxBFq\noi3aC09jrauLaxJM7Dsr2/js4/fC/rxTiV3pX86bDbNfhYZj/OXqJrbkW1g4PZpXdvhg3j+Cq0xP\n1t/7xED7dzB2u519X3zIP0zX8Gb63VyVY+Sbrj+T3rCdn7/XzC1PHB+ZFxUVEZM9Celto6VsB1ar\nNaLezbzwpycAiBuSiXV8Xpcjdp9PMtZYxpYaS7t9bkPtjfeKADi0txtz7f2J/UB9FA1VR8L+vDuj\nxC6EeEwIsUsIsUUIsVIIEVmn25V+r8OR9thZ8NNNcOtKfvS24Kxn6rnzQxNEdz4/u7/3iYFT38FE\nmwxcMS6VhysuxfuL3fDDd3k142FeL03F4XAEH7u8vDwSz76IJI+bjLQUFi9erPORHOd0OqmvKEV6\nPUyfdT1rD7VAXTkvPft4p7epqDpGjuEoXzWY2+1zG2q/f/bPALgrujETxz81tzYmBbOJsD/vznTE\nvhqYKKWcDHwF3HvmISnKcZ2OtKNiYfQMptofo9Wccco0xpNfEAbKrJiTXTNxGFUNraw/6oMRU5n3\nk59RUqJtWJGfn09paSlFX2xGJGdz+w2XRtxjUFBQgLvaBfWVJGaM4b9f+gCAT15+rNPbrHrxaQBS\nJ10R1mM5J3c6AEMt3VgQ1VSNLzoBD1EU3Lcw7I/5GSV2KeX7UspA1551QOaZh6Qox3U10u4sYQ+E\n0kt3XH52CjEmA+9uOxK8zOl0kp+fj9frxWg0co39VwBcPSFNrzA7Ffj7jk23suGrUv51sIn6Vvjp\ndecHr3Pyi/SxTe8A8EThe2GN9d0ibUP1WFq6PmfTVI0nRitgDE2ICVeIQX1ZY/8R8E5nPxRCLBBC\nFAshiisrK/vw1yoDWW9H2gOh9HKyjpKJOcbEzPGpvLpuH1kjcoIzZwJJfenSpVSZR3JWqoVRKZaI\nO4kc+PtekXsOlc1wrLqOdeUQVbouGOPJL9KXZkr2+tKZNPm8sMa66L4HafYZsJpaKfjNb08/cGhy\n0RqlLUpKTYgNY5R+Xc2HBD4AtnXwcf0J17kPWAmI7syxVPPYFaXn2s3r95s7d66MH3WBHLFolYwf\nf3lwPnvg856jtXLEolUy66ofBi8/+T4iwYrPv5YjFq2SmePOk46ZSdp88bOGSyllu+ORPp903Zcq\nVyy8SpdjqHkoQ7583w3ye7f9+PRrJZwz5ZE/zNKOafwFfbamgm7OYzd1I/FfebqfCyHmA98BZvp/\nsaIoIeBwOIJTHQNWrFiB1+ujzVVO8rTv88CF7eu/L679GunzUvbZSgp2ru7wPiLBqBR/z5eEVOTI\nDOATfneH1kM+sHIYgKPbsZmaKXan4XB8P+xxVtR5SIxrZN2mHcFzGR1qdFFnGg1A2b6dFBQUhLXO\nfqazYmYBC4HrpJThaVumKCeJtPJCqHRUltIWGUlq/rUC49CRpF/07eOli8f/yEtrD9K66/9IihHB\naZKRdgIVIGeoNqOpxhfDC+9vAnMqM9I76Kvy1bsAWKf/UJdjiLWmkkgDk74xrcsau1taiBI+MlKH\n9LtZMX8AEoDVQohNQohn+yAmRemRwXKitCOFhYXMnTuX5t2fYml18cAb2/jpvQ+TmT2S0bMdeD1t\nVBa9gNlsjrhkfqKhlmhiDD6s2WO5/4EHteZle1af0jTLs/MdtvhySMsYqUucKZmjSRQNbNt7qPPn\nnM8HzW6O+cwMT7bo8kJ6prNixkgps6SU5/k/ftJXgSlKdw3EE6U9UVRUhNfTRs27v8frkxRWZJBz\nx/McbIqh6ZM/k2jyRfxjI4RgfEYy02bdpCXBc27QepfvXHX8SjWlGMuL+dB7AWNSw9eu90RRZitJ\nNHD5rOs6fc694HwGpI8tpXUc3LlFl3eSauWp0u9FankhXAJ96asO7uTwC78gxrWPr7etp/G931P5\nxVsRP1oPGJ+ewM7DddqEjBGXUG1KZdvyn+Bctky7wpcvAvA336WMTtEnsRvibNgMjWSMmdDpc275\nU9qairKmKBqrj7Jw4cJwh6kSu6L0d3a7HYvFQlNTE1UHd1D8zB0cKlxE28Fi4uLiKCsri5gWvacz\nPj2RmqY2Dtc0g8HAox/XMnGIj40vOXjp2cepW72YYsNkKozDyLDF6RLjl7u/JkHWs37r7k6vc88d\nPwKgJjoNb70LIUS4wgtSiV1RBgCHw9EugRiNRpYsWUJraytSSl566aWIP7k8Pl2b933u5d8iOTmZ\niuFXsrHCwNMz2rhq/yMYkNyzL5eWykM8/9ypWyWGw/+u+hCjkFQc7nxGzA1XXwZAbdRQon3NurRw\nUIldUQYAu93OnDlzEEIQHx8f7KFyYmveSD+5PG5YAgCt8SlUV1fz5qq3mb86ngNxk/HYRnPbajMH\nE86noXyPbsfiatY+J1uiOr+SvwFYNQn4Gty6lMFUYleUAcDpdLJixQqklCQnJweTSWFhIcuWLesX\nJ5cTYqOwmjyYM8dis9kQQrBlbzkz/rCXjHs38OzHBzFYkolvrtLtWG74N63MMiTaQ32Lp+Mr+RuA\nuaUZmmrCFVo7KrErygBwYhuBEzf2djqd2O128vLyyM/Pj/ha+4VnZzDuopm4XC4WL17c7gXpd8+9\nCsCt1+bpdjL4mhu1jcGtop5nlnfSz94/Yq/Bwp3228IVWjsqsSvKABCY8rl06VKKiopwu91UV1cH\nSxbaClUvK1as0DnS0zs3y8r+Yw1UN7Se8rO/vr0GgBefejTcYR0XbwPARj1PLH2+4+s0uWgxJeDD\nwO3z9dmlSiV2RRkATpzyGZj+aLPZgqPd2bNnYzQaI2Y7vM7kjtAS5+SZN7Bo0aJ2i4BSxuXicR8h\nb9qF+gUYp+2iZBV1GPw7Kp3I6XTyvy8uo7xeYhSSIeZutPgNAZXYFWWAsdvtVFdX43K52tXaPR5P\nxGyH15kNq/+O9LZRH5uGlDJYivH5JJUk0VyyjVWrVnV9R6ESm4RXCmyinrEXTD3lxwsXLiTB5KHa\nG0dzVTnz5s3TIUiV2BVFiSC//XUBLUf2Eps9iSVLlgTfhXxVUYchLpHmQ1t0mRceJATVzZDUVsXB\no+4OfixIjhO4RSKe2mO6lb5UYlcUJWLk5eXRcnAjMelnc/0tx0/0rt1XBYCt7ZjuW/sZE1JIxs2Y\nyd84pQHd4sWLSUswUWdKxld/TLfSl0rsiqJEjKKiIhp2fQZCsHrHUUCrWz+w9DW87sM47rlT9/YI\ntvRRZMa1seeIgePXWgAACUpJREFUmx//+MftzgPY7XayUyy4DMnce/dPdCt9qcSuKErEcDgcpMV6\nsUV5eGNjOQAFjz2Ncfh46rYXsWjRIp0jBOKHEN14FINlKBKB0Wg8Pq/e24ZoqcMlExiepMPOSX4q\nsSuKortASQOgpKSEO66exBcHXazbX8VF8+8HoGHrB0TEXj7xNtLNEmE0kZw1JrjKFwguTqomgeFW\nffrZgErsiqJEgJN76rfs+AhZV8lc51qKay1MsTYzLCGKJUuW6BwpEJdMomgCJG988FkwqTudTq6c\nrm3CXS0TgpuH6EEldkVRdHdyT/3//vXDlL9yP0371uP7qoirhtYEt6LTfbes+GQMvlbiaOFr1/GN\nQAoKCvDUVgBQZ0hUI3ZFUfpGf90mMLCwqqCgAKfTicPhYFi8oOmDZyhZ+Tvuul1rh5Cfn6//blnx\nQwAYZqznUNXxHUEdDgdnZw0FICYpBaNBv2mZKrErygDSn7cJPDH2wEraxYsXYzQag+0QvF4voE2L\n1I0lDYBJ1hb2VtQHL7bb7Sx7Umt3YB2SpktoASqxK8oAEihp5OXl9buRe0dbHK5Zswafz0d8fHyw\nLQJo0yJ1Y04BYKK1lfV7y9s9zr4Gbb59Smq6buGBSuyKMqAERrpFRUX9buR+Yr+bQEnp5ZdfRkpJ\nS0sLhYWFLF26VP8WxJZUAKIqd1DrMVFW4Qo+zl+uW0O9jOXg7u36xYdK7IoyIPX3Db4DZZnY2Nh2\nzcsiYn9b/4i9apvWbTI2LSf4OB/cu4tqmcBfnvyNru+WVGJXlAEoIhLgGQi8MD311FOR17zMFAOx\nVmaeOwKAeT+9N/g4j8lKpVpaaD66X9d3SybdfrOiKEon7HZ7ZL8oWVJJqq9BNtdT3qK15nU6nVzc\nVEm1cSgZw1J0fbekEruiKEpPmVM5tm0tTRVb2dw2GoCCRx5hw3zJ9hpvcM69XlQpRlEUpacsqYzN\nsCGO7UMkpPL9+T+hJXYIQ0QdyWkj9Y5OJXZFUZQes6SSZGolunIXAKt3V5GcMw6jkJhi9GslENAn\niV0IcY8QQgohhvbF/SmKokS0hGHQUkvBz/4dWbGXoZfOZtTEKQCsWPm2zsH1QWIXQmQBVwOHzjwc\nRVGUfiBJ60T5wxuv5K2C2zBEx5ERq7UX+M7s/9AzMqBvRuxPAguBCOinqSiKEgZJmdrnmhImZ1r5\ndNEVPPntDACun7NAx8A0Z5TYhRDXA2VSys19FI+iKErk84/YqSnB6XQyZcJZ7Fr7nnaZRd8+MdCN\nxC6E+EAIsa2Dj+uB/wK6NVlTCLFACFEshCiurKw807gVRRnAnE4nNpuN5OTkyOx3kzAMDCZwlwRX\nyRYXraJZxGsLmHTWZWKXUl4ppZx48gewH8gBNgshDgKZwJdCiGGd3M8yKWWulDI3JSWlL49BUZQB\npqCgALfbTXV1dWT2uzEYIXE41JQEO01mWOBAVbO+cfn1uhQjpdwqpUyVUo6UUo4ESoELpJRH+iw6\nRVEGJYfDgdVqxWazRW6/m6RsqCll1apVAIxONhA3fILOQWnUylNFUSJOxLcUALBmwYE1CCEQwCib\nkdjz8/SOCujDBUr+kfuxvro/RVGUiDZkNNSW8cRvH2bK2cOJNQHJOXpHBaiVp4qiKL2TqpVd5n97\nKg/eNReAt9ft0jOiIJXYFUVReiNlnPa5YicbVv0ZgPufWaFjQMepxK4oitIbtpEQnQBlG5hzxQTK\n6wX5v3xI76gAdfJUURSldwxGyLkU9n3EmFgBud/GfktknPBVI3ZFUZTeGjMT3F9D9UEYc6Xe0QSp\nxK4oitJbk3+g1dpTz4HJN+sdTZBK7IqiKL3gdDrJGjMBZ9SPIP8ziNa/D3uAkDL8TRlzc3NlcXFx\n2H+voihKX8nKyqK0tJTMzMywbYUnhNggpczt6npqxK4oitILDoeDzMzMiGx5oEbsiqIo/YQasSuK\nooSJ0+kkKysrYloMqxG7oijKGQpXvV2N2BVFUcIk0urtasSuKIrST6gRu6IoyiClEruiKMoAoxK7\noijKAKMSu6IoygCjEruiKMoAoxK7oijKAKMSu6IoygCjEruiKMoAo8sCJSFEJfD1GdzFUOBYH4XT\nXwy2Yx5sxwuD75gH2/HCmR/zCCllSldX0iWxnykhRHF3Vl8NJIPtmAfb8cLgO+bBdrwQvmNWpRhF\nUZQBRiV2RVGUAaa/JvZlegegg8F2zIPteGHwHfNgO14I0zH3yxq7oiiK0rn+OmJXFEVROtHvErsQ\nYpYQYrcQYq8Q4ld6xxNKQojnhRAVQohtescSLkKILCHEx0KIHUKI7UKIu/WOKZSEELFCiC+EEJv9\nx/uw3jGFgxDCKITYKIRYpXcs4SCEOCiE2CqE2CSECPlmFP2qFCOEMAJfAVcBpcB6YLaUcoeugYWI\nEOIyoB54UUo5Ue94wkEIkQ6kSym/FEIkABuAGwbw31gAZillvRAiCvgUuFtKuU7n0EJKCPELIBdI\nlFJ+R+94Qk0IcRDIlVKGZd5+fxuxXwjslVLul1K2Aq8A1+scU8hIKdcALr3jCCcp5WEp5Zf+r+uA\nnUCGvlGFjtTU+7+N8n/0n9FWLwghMoFvA8v1jmWg6m+JPQM4cafYUgbwP/1gJ4QYCZwPfK5vJKHl\nL0tsAiqA1VLKAX28wO+BhYBP70DCSALvCyE2CCEWhPqX9bfErgwSQggL8DfgZ1LKWr3jCSUppVdK\neR6QCVwohBiwZTchxHeACinlBr1jCbNLpJQXANcAd/jLrCHT3xJ7GZB1wveZ/suUAcRfa/4b8LKU\n8u96xxMuUko38DEwS+9YQmg6cJ2/5vwKMEMI8ZK+IYWelLLM/7kCWIlWVg6Z/pbY1wNnCSFyhBDR\nwC3AmzrHpPQh/8nE54CdUson9I4n1IQQKUIIq//rOLSJAbv0jSp0pJT3SikzpZQj0f5/P5JSztU5\nrJASQpj9EwEQQpiBq4GQznTrV4ldSukB7gTeQzup9pqUcru+UYWOEGIFsBYYK4QoFUL8u94xhcF0\n4Fa0kdwm/8e39A4qhNKBj4UQW9AGLqullINiCuAgkgZ8KoTYDHwB/FNK+W4of2G/mu6oKIqidK1f\njdgVRVGUrqnEriiKMsCoxK4oijLAqMSuKIoywKjEriiKMsCoxK4oijLAqMSuKIoywKjEriiKMsD8\nP3LZBcDohhvdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXcLfARPJQnn",
        "colab_type": "code",
        "outputId": "76d0eb29-b83b-44a2-881b-66ca7e475eca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 가장 적합한 모델 찾기\n",
        "# Linear regression, Ridge, Lasso 3개 중에서 10~49까지.\n",
        "\n",
        "def rmse(predictions, targets):\n",
        "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
        "\n",
        "poly_range = list(range(10, 50))\n",
        "rmse_lr_list = []\n",
        "rmse_lasso_list = []\n",
        "rmse_ridge_list = []\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "for poly_value in poly_range:\n",
        "    poly_features = PolynomialFeatures(degree=poly_value)\n",
        "    X_poly = poly_features.fit_transform(X)\n",
        "\n",
        "    lr = LinearRegression(fit_intercept=False)\n",
        "    lr.fit(X_poly,y)\n",
        "    rmse_lr_list.append(rmse(lr.predict(X_poly), y))\n",
        "\n",
        "    lasso = Lasso(fit_intercept=False)\n",
        "    lasso.fit(X_poly,y)\n",
        "    rmse_lasso_list.append(rmse(lasso.predict(X_poly), y))\n",
        "    \n",
        "    ridge = Ridge(fit_intercept=False)\n",
        "    ridge.fit(X_poly,y)\n",
        "    rmse_ridge_list.append(rmse(ridge.predict(X_poly), y))\n",
        "    \n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "data = {\"poly_range\":poly_range, \"lr_rmse\":rmse_lr_list, \n",
        "        \"lasso_rmse\":rmse_lasso_list,\"ridge_rmse\":rmse_ridge_list}\n",
        "df = DataFrame(data).set_index(\"poly_range\")\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2400.2274159729322, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2408.860136931154, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=4.85543e-18): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2406.814493176081, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.07148e-19): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2402.938722675943, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=9.22947e-21): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2398.762715313102, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.15421e-22): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2394.9091820664216, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2391.718473870374, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2389.3381059770322, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2387.690911341347, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2386.671628524939, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2386.1385935420058, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2385.9342262104087, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2385.9188675623195, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2385.9570286883027, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2385.904513131973, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2385.604616190699, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2384.8907861095504, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2383.6141005523655, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2381.651282356998, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2378.9120656118166, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2375.345655953905, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2370.9425900038946, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2365.7665099254496, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2359.8533302814426, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2353.2842508210947, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2346.1669905713147, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2338.614675041863, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2330.7488860849107, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2322.689494365073, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2314.5505459803635, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2306.42694074406, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2298.3891664050902, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2290.5045562635332, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2282.8371368945986, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2275.440887931608, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2268.3514187100423, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2261.5967797637654, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2255.1985930437354, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2249.17202808088, tolerance: 0.5460943105172318\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2243.5177693269416, tolerance: 0.5460943105172318\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lr_rmse</th>\n",
              "      <th>lasso_rmse</th>\n",
              "      <th>ridge_rmse</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>poly_range</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.908540</td>\n",
              "      <td>2.294458</td>\n",
              "      <td>1.936648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.899772</td>\n",
              "      <td>2.295308</td>\n",
              "      <td>1.917277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.637873</td>\n",
              "      <td>2.295093</td>\n",
              "      <td>1.916812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.365971</td>\n",
              "      <td>2.294353</td>\n",
              "      <td>1.890192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.348537</td>\n",
              "      <td>2.293067</td>\n",
              "      <td>1.624377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.927390</td>\n",
              "      <td>2.291625</td>\n",
              "      <td>1.493108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.705838</td>\n",
              "      <td>2.290287</td>\n",
              "      <td>1.503377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.663773</td>\n",
              "      <td>2.289180</td>\n",
              "      <td>1.295161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.689606</td>\n",
              "      <td>2.288365</td>\n",
              "      <td>0.873456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.715536</td>\n",
              "      <td>2.287834</td>\n",
              "      <td>0.743838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.638875</td>\n",
              "      <td>2.287560</td>\n",
              "      <td>0.736622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.620338</td>\n",
              "      <td>2.287534</td>\n",
              "      <td>0.602170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.551585</td>\n",
              "      <td>2.287723</td>\n",
              "      <td>0.506790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.580720</td>\n",
              "      <td>2.288106</td>\n",
              "      <td>0.518933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.958716</td>\n",
              "      <td>2.288659</td>\n",
              "      <td>0.507277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1.129944</td>\n",
              "      <td>2.289355</td>\n",
              "      <td>1.328121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1.214223</td>\n",
              "      <td>2.290179</td>\n",
              "      <td>1.922024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1.261996</td>\n",
              "      <td>2.291117</td>\n",
              "      <td>1.904141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1.312890</td>\n",
              "      <td>2.292159</td>\n",
              "      <td>1.803441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1.329480</td>\n",
              "      <td>2.293303</td>\n",
              "      <td>1.684829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1.308079</td>\n",
              "      <td>2.294554</td>\n",
              "      <td>1.472639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1.269078</td>\n",
              "      <td>2.295922</td>\n",
              "      <td>1.439374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1.580647</td>\n",
              "      <td>2.297414</td>\n",
              "      <td>1.893259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1.642675</td>\n",
              "      <td>2.299051</td>\n",
              "      <td>1.356047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1.676980</td>\n",
              "      <td>2.300848</td>\n",
              "      <td>1.595102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1.686152</td>\n",
              "      <td>2.302812</td>\n",
              "      <td>2.042633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1.677191</td>\n",
              "      <td>2.304957</td>\n",
              "      <td>2.022744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1.659493</td>\n",
              "      <td>2.307280</td>\n",
              "      <td>1.935177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>1.640727</td>\n",
              "      <td>2.309775</td>\n",
              "      <td>1.858802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>1.627850</td>\n",
              "      <td>2.312426</td>\n",
              "      <td>2.048710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1.622207</td>\n",
              "      <td>2.315216</td>\n",
              "      <td>1.804566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>1.626158</td>\n",
              "      <td>2.318121</td>\n",
              "      <td>1.747126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>1.718984</td>\n",
              "      <td>2.321111</td>\n",
              "      <td>1.826398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>1.707336</td>\n",
              "      <td>2.324146</td>\n",
              "      <td>1.834131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>1.695689</td>\n",
              "      <td>2.327190</td>\n",
              "      <td>1.754053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1.686405</td>\n",
              "      <td>2.330204</td>\n",
              "      <td>1.903494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>1.681409</td>\n",
              "      <td>2.333157</td>\n",
              "      <td>1.893880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>1.681971</td>\n",
              "      <td>2.336016</td>\n",
              "      <td>1.843600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>1.688615</td>\n",
              "      <td>2.338753</td>\n",
              "      <td>1.813920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>1.701080</td>\n",
              "      <td>2.341338</td>\n",
              "      <td>1.781467</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             lr_rmse  lasso_rmse  ridge_rmse\n",
              "poly_range                                  \n",
              "10          1.908540    2.294458    1.936648\n",
              "11          1.899772    2.295308    1.917277\n",
              "12          1.637873    2.295093    1.916812\n",
              "13          1.365971    2.294353    1.890192\n",
              "14          1.348537    2.293067    1.624377\n",
              "15          0.927390    2.291625    1.493108\n",
              "16          0.705838    2.290287    1.503377\n",
              "17          0.663773    2.289180    1.295161\n",
              "18          0.689606    2.288365    0.873456\n",
              "19          0.715536    2.287834    0.743838\n",
              "20          0.638875    2.287560    0.736622\n",
              "21          0.620338    2.287534    0.602170\n",
              "22          0.551585    2.287723    0.506790\n",
              "23          0.580720    2.288106    0.518933\n",
              "24          0.958716    2.288659    0.507277\n",
              "25          1.129944    2.289355    1.328121\n",
              "26          1.214223    2.290179    1.922024\n",
              "27          1.261996    2.291117    1.904141\n",
              "28          1.312890    2.292159    1.803441\n",
              "29          1.329480    2.293303    1.684829\n",
              "30          1.308079    2.294554    1.472639\n",
              "31          1.269078    2.295922    1.439374\n",
              "32          1.580647    2.297414    1.893259\n",
              "33          1.642675    2.299051    1.356047\n",
              "34          1.676980    2.300848    1.595102\n",
              "35          1.686152    2.302812    2.042633\n",
              "36          1.677191    2.304957    2.022744\n",
              "37          1.659493    2.307280    1.935177\n",
              "38          1.640727    2.309775    1.858802\n",
              "39          1.627850    2.312426    2.048710\n",
              "40          1.622207    2.315216    1.804566\n",
              "41          1.626158    2.318121    1.747126\n",
              "42          1.718984    2.321111    1.826398\n",
              "43          1.707336    2.324146    1.834131\n",
              "44          1.695689    2.327190    1.754053\n",
              "45          1.686405    2.330204    1.903494\n",
              "46          1.681409    2.333157    1.893880\n",
              "47          1.681971    2.336016    1.843600\n",
              "48          1.688615    2.338753    1.813920\n",
              "49          1.701080    2.341338    1.781467"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8KqB9znKRJ9",
        "colab_type": "code",
        "outputId": "6a7d56a2-6166-43ba-f9f0-85da25ca9702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "print(df.min())\n",
        "df[\"ridge_rmse\"].sort_values().head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr_rmse       0.551585\n",
            "lasso_rmse    2.287534\n",
            "ridge_rmse    0.506790\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "poly_range\n",
              "22    0.506790\n",
              "24    0.507277\n",
              "23    0.518933\n",
              "21    0.602170\n",
              "20    0.736622\n",
              "Name: ridge_rmse, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcV8ulPbKdfq",
        "colab_type": "code",
        "outputId": "27a95635-ed58-406b-ec29-dac28ef87bc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "poly_features = PolynomialFeatures(degree=22)\n",
        "X_poly = poly_features.fit_transform(X)\n",
        "ridge = Ridge(fit_intercept=False)\n",
        "ridge.fit(X_poly,y)\n",
        "\n",
        "f_x, f_y = f(1000)\n",
        "plt.plot(f_x, f_y)\n",
        "plt.scatter(X.flatten(), y.flatten(), s=3, c=\"black\")\n",
        "plt.plot(X.flatten(), ridge.predict(X_poly).flatten())\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXd4U+UXx783SXebJt0jadmyZwVx\nYEBwT1C00LqD1oWyymoCURFwoYxCAirLovITBURF0eIEKUPZe3QALW26Z5Lz+yMkpiFp0+QmTev9\nPE8fMbn33PO+9+a85573vOdliAgcHBwcHO0HXmsrwMHBwcHBLpxh5+Dg4GhncIadg4ODo53BGXYO\nDg6OdgZn2Dk4ODjaGZxh5+Dg4GhncIadg4ODo53BGXYODg6OdgZn2Dk4ODjaGYLWuGhERAR16NCh\nNS7NwcHB0WbZu3fvFSKKbO64VjHsHTp0QE5OTmtcmoODg6PNwjDMeUeO40IxHBwcHO0MzrBzcHBw\ntDM4w87BwcHRzuAMOwcHB0c7gzPsHBwcHO0MzrBzcHBwtDM4w87BwcHRzmDFsDMMI2IYZiPDMMcY\nhjnKMMxQNuRycHBwcLQctjz2DwB8R0TdAfQDcJQluRwcHBysoNFoIJVKodFoWlsVt+OyYWcYJhTA\nMACrAICI6omo1FW5HBwcHGyiUqmQl5eHtLQ0pKamtmsjz4bH3hFAEYCPGYbZzzDMSoZhgqwPYhhm\nAsMwOQzD5BQVFbFwWQ4ODg7HUSgU4PP50Ov1yMrKQl5eHlQqVWur5RbYMOwCAAMBZBLRAABVAKZb\nH0REaiJKIqKkyMhma9hwcHBwsIpcLkdmZiYkEgmSk5MhkUigUChaWy23wIZhzwOQR0S7r/7/RhgN\nPQcHRzukLceq5XI5cnNzMWzYsNZWxa24bNiJ6BKAXIZhrrv60W0Ajrgql4ODwzuxjFW3NeNuGpTS\n09PNoZi2PFDZgyEi14UwTH8AKwH4AjgD4Cki0to7PikpibiyvRwcbRONRoO0tDTo9XpIJBLk5ua2\ntkoOI5VKkZeXhwGJofAPCMJTk+aYB6q20BaGYfYSUVJzx7GS7khEB67Gz/sS0YNNGXUODo62jWWs\nuq3FqBUKBcYPiUHOE4TshysRXXcWMpkMfD4fMpmstdVjDVY89pbCeewcHBytAhGK5/VERVEefPnA\n2QofPPZtEOexc3BwcLQ1THH0TcsUCG8owBu/1GHJHh1uitMjgl8BsVjc5t4+moIz7BwcHO0eUxw9\n94fl0BODXxImIL/3BADA0MhqBAUFQS6Xt7KW7MEZdg4OjnaPQqGARCLB2OtjcaAhAfXd78JO4SiU\n8MJwf6+QduWtA5xh5+Dg+A8gl8uRe/Y0IvUXsY/XC4ZfNRAJ9DjoOxB39g5vV946wBl2Dg6O/wqX\nD4JvqEduYC+c+3UTnh/VGz9XxAGVl4Hyi62tHatwhp2Dg8Np2tLinobzewAA2/ddwKpVK1F+eCf+\nMXQyflmwvxU1Yx/OsHNwcDiNaVLSm1dwmvT6O/tLFJEQf+/fi7S0NMyfPQWHtALjQUXHWldJluEM\nOwcHh9OYJiUVCkUjI+9NmPTia0/jpEEKXf5R6PV61NbWQpt3FpcNoTj+xzdeOSg5C2fYOTg4nMZU\nVEsulzcy8t6EUa94dAuqhDaoI5Yt/gASiQT+/v6oLTiB0xSPytx/vHJQchbOsHNwcDiFdejF0sh7\nE3K5HOcP7kYQamGIuM6s54IFCyAylOEMxaJHpAASSbzXDUrOwhl2Dg4Op/DW0IstCs/8DQAIju9p\n/kwul+PknmycQxwCqRph/p4vr+IuOMPOwcHhFN4aerHFlXMHAQCxXfo1+tzfh4/aUGNmjLD+cpsY\npByBM+wcHBxO4a2hF2s0Gg32/PA/VJA/OnXoZP5MLBYjLCwMl2p8AQADO4W3iUHKETjDzsHB4TSW\ncXZvTXdUqVSI869Drk6M1Z98ZP6stLQUWq0W2376AwAgCWFaU01W4Qw7B4cb8FYj5yzWBtzk7U5X\nvI78wmKoVCqv3VlJoVAgIaAG56sDzKEWhUIBkUgEhmFQVliAIhIizE/fbkIxXD12Dg43YNqppy3U\n+HYEy/YAQF5eHkJvGofQmx4DdPXoWZ6DXRuXo6ysDETkVe3W6w2oVcVg/aWOmP7FSSxYsMAcPtJo\nNFAt+QRbHqhGeYkWx/vN8urQElePnYOjFWlLE4uOYGqPTCZDZWUlAroNhejmcdCd2YP+HaNxJHQw\nKskPALyutvmli3kIYupw+kottFrttV55+WXkUwTignSto6Ab4Aw7B4cbaCsTi45iak92djZKy8oR\nPvxpkDYPw/3PYd+HaeDzeQi9KRmmCIA3tfvyhRMAgFOXKgGg0RZ4KpUKeedOI68uGHG+1V4XRnIW\nzrBzcHA4hEajQWVlJSJ63wy+KBZLX7wPO7N/Rt7JQyjb/x2CegwDzz8YrRHebYqyi6cAAGcvlgIA\nsrOzzd+Z3kRKGDEC+XqE+RnaRZydM+wcHCzT3iZOTZgySQJ6jYAo0AejYmuw/eWeWHaPP4SntoER\n+CL+hnuxcOHC1la1EQ3F5wAAL0+bc014zPQmEtF5AADg+m4xXhVGchbOsHNwsExbqHjoDAqFApLE\nTuAnDIDPwU3QZ96KHvUH8MxAf2TfXwJh+Wl0G/6wV4VhAIBfdgHljBBPPf+y3fCYb1g8AGDzpyu9\nTn9n4Aw7BwfLtIWKh84gl8vx8bY/QAwfM4K+AlNfAch/hu9zOxAbwsNkw8c4Wc5Ddb13TUIG116E\n1jemyUE2JMJo2Cuu5HlaPbfAGXYODpYwGQ4AXl/x0FlmL8tCF90pjO5QjaPikUB0TyB+IE4Ib0ZK\n9BnECCqx+2xJa6tphogg1hWhNiCmyUE2PFoCAzGoKs5vBS3ZhzPsHBwsYW04UlNTkZaWBplM1i5e\n7wEgTxeCJ+s3oKqeMPB5NQDjgPb8xwfAZ4BHBTuh2fST14SfSqrqEYUSGIJjmhxk48OFKEEI6ksL\nWkFL9uEMOwcHS5hWM1ZVVUGj0SArKwt6vR5ZWVmtrRorXC6vRZAoDPeFHMfe2gQgKByAcUD7/WgB\nfivgY5zvr/j9xEWvCT8VXNFCxFRBIIpvMgU1XhSIIhIBFZdbQUv24Qw7BwdLyOVyBAcHmxfBJCcn\ng8/nIzk5ubVVcwlTiGnBqi8g4x1AqI8ew1780Py9yRM29ByNGMMlXBchgDgiCgqFotUnj0sungMA\nBIRLmjwuwJcPLS8MupJzXvO24RJExMofAD6A/QC2NnfsoEGDiIOjPaJWq0kikZBarXbo87aARCIh\nACR9YBJ9nXEPGRZ0JNI1XHtgWQGRUkjzZ04gSb+bG50rkUg8rLWxzx8efQ+RUkgVh7c3e/yP80ZT\nwaz4VtPXEQDkkAP2mE2PfSKAoyzK4+Dwehz1SNtydozJI4/vdyOGCQ6B6TwC4AsaFQPTaDSAMBaX\nBBKM4O/DPSnPNzq3NSaPVSoVRL4NAIBtP++2e5zpHp4v1SOCX4UwsajtT3Y7Yv2b+wMgAbADwAhw\nHjvHfwhrj9Seh9qWPXYioqq6Brpn5lIipZBo/3oi+retlu01bFdQnUJMXce81uptVavVNGfCXURK\nIUmjQu0eZ2pHeupwIqWQ+nWJ86CWLQMe9tgXAZgGwGDvAIZhJjAMk8MwTE5RURFLl+XgaF0si2NJ\npVLIZDKbHqpp4g5Am4rhmuPrK9bhJvxj/LDzCAD/ThZbFv1iEm+EL6NHnzBdq7+dyOVyxAcTKvU+\nqGywb+pM99AvzBiHnzHxOU+p6DZcNuwMw9wLoJCI9jZ1HBGpiSiJiJIiIyNdvSwHh1dgylXPyspC\nXl4esrOzkXtsP3b9+hMEAgFSU1MbHd/WQjLTpk1DXl4e3v9kI27mHURDRA8gJMb8fXBwcKMyuJAO\ngQEMbgwvx+yM1g9nxAfU42J9AO655x67x5gG3eH3PAwAkN040FPquQ02PPabANzPMMw5ABsAjGAY\nZh0Lcjk42gQqlQp6vR6D4/nYcl858HZnZCZ+g6X3BWPTF41THa1TIr0dhjHuKuQX1QEDeCch6Hiz\n+TubpRPWfYFyYVdcLzgF2f2PtZbaAIDqeh2ieaUoqBY0Kvxljz0HTwIA/tix1c2auR+XDTsRzSAi\nCRF1APAYgJ+IKMVlzTg42ggymQyjOvvglycDIfYzYM6ZXvjMcBvkfYGfpg7AT4f+3XDCOiXS21mw\nYAFEIhH6J4oQzNRh4ttrkZqaek3YydLIn60LRx/eWbyimN+qYad8bQ2iGS2u1Ps6NBm68hPjILz/\nz51tYtBtCi6PnYPDRU7s+QlfPOyPM2UMbr/4Ij6Jm4VZp/rgY//HMZh/Auc3TEbU9feYs0faUpkB\nuVyOtxYsxCBxBQDgm3+KsH79+n/DTlalE2QyGTRf/QIxU4mL5060atjpUlk1olCKoaMecmjl70tp\nz6GWfBARzG8Tg25TsGrYiSibiO5lUyYHh1dDBM39AeDzgAzmFdR1uAWGXeuQMVKKKQvXYvEeHZ7g\nf4/BshGo5AuRnp7e5jbheHPJRxjIP4uiWj7OaAn+/v52y99mZ2cjJ68OAHB73+hWHcDKrxTAh9Fj\n2eovHPLAX3r+WZRAiLhQxzx8b4bz2Dk4XOH0DvQNLIJynxg5gTfgyRs74EJ2FuRyORiGwawfq1FY\nDczyzULY7S+AiFp9NWZLeejJFzGQdxK7LzLg8/n44IMP7A5MCoUCWp9Y6MFDj8DSVtD2X2pLjJUa\nj5y96JAHzjAMyvki9EiIaDODrj04w87B4SwGA7BDhXK+GF8nTIFQoEP6nd3NXy9YsADVej7m/1qL\noT4ncUOCH55WfNjmMmM6d+uGLrwCHC4WIDMzs0mjJ5fLcfJcHooDO6GT4Tzy8gtarZ0NpZcAADrf\nUIc98BqBGP713lOd0lk4w87B4SynfwIu/o0TfSZDF9YJbz5yPQJ8+eav5XI5MjMz8e3lSNQxAXgt\n8FucEHRERkbbibEDgCFvHwAg/cPPHPZkq8J6ozf/HCTd+7daOw2VhQCAcfKJ5syd5qj3EyOgXtum\n3qhswRl2Dg5n+WsFKDgaGad7oHtMCO7tG3vNIXK5HMfP5sHvxudwi343CvPPou/I0W1qsVJgyREA\nQO9RKQ7r6hPXG5FMOdauW9dqYQ1+tdGwZyxY4vAbkiEwAiKUt6k3Kltwhr0N09Zite2K4tPAye04\nkzgWR4vqkCbrbM75trwvpn9/ftIPPBgw1m8XPt9jNOptISRTp9MjtuYk8uoCcfhMvsO6ijv0BQCU\nXjjoTvWaxFCajwq9L264ZbjDb0i8oAgEMvXo0rlTm3mjsgVn2NswtgwDZ+zZxW5/7l8HA3h47Fse\nhAId7unzr7dueV9M/578ViYguR4pAb9j26ECLF6+EpWVlY2W43sjZ69UoQdzHtqgzi0KHwXF9wYA\nGC63Xl3AIJ0WhfW+jdIym4MfYlwV//MP29r0BCpn2NswtvKh7XmBnMF3Dpv9aTCg4s+P8P05oChq\nCAp3fY2PP1pl7l/L+2K50vST/bWIrj2LjrpzeGPNNpSWliIoKMirDcjpgivoxBRgx8GLUCgUjusq\njEM1E4DAspPuVdAOdTo9ogRVKG7wb9HA6SeMAgBUlFx0l2qewZFKYWz/cdUd3Ye9KoKtWRe7LWOr\nP7csnkakFNLTD8soYerXFBwlbbJ/Td9FBfFIrwihtyc9THHj5rWJao/r/vclkVJID/X0a/Gzc1TZ\nn36fmdQqbczXVtPJjO50IXNMi847tXcHkVJIOT9scJNmroFWqMfO4QXYW/zSllY7ehO2+rN05wpU\n1BF2Ro1Dzdl9ENRXNNm/pu+09Xz8kavH7dgNX0lvwCfAk01xjkvGio6FFN6iZ0ej0SCnoB5dBJeR\nPmOWu7Szf/21nyGSKcWFktoWnScMN4bU6soL3aGWx+AM+3+Etrba0WvRN+CezgZszg2GLiQOfgX7\nsXDhwibL8pq+Cw4OxlfHdOgbUoZ4XjG0gRKvnjgFgODSY6hhAvHboZY9OyqVCoeLgCimDGERYjdq\naJs1n25AKFONPw8cb9F5oeHGypX6iivuUMtjcIa9neJKTJ2LxzfB+d8h9mfwnS4J1FCLEz9/Cblc\nbu6z9PR0u5kuCxYswO4y4wbQdwn2IrzvcK9+g2rQGxBXexrFwV0AXstMhUKhwLlSAgBMetbze74+\nNtpYprfvkFtbdJ5vkAgN4ANVnGHn8EKam0Q1VeizZbzbQhpeq3FsG3QQYE/MGPQSk3lBkqnPiMhu\nSEYul+PxV+fifDmDkYJ/ILpuCAzkvbnsedoadGbyUS/u5tT5+WXGben6JHreY+/TVQoAGH7Xgy06\nT7NyJYr1QaguOucGrTwHZ9jbKM151fZiviYDZNoYwpbx5uLxjTH3tVoNHPsGJ326o9Y/Aj2CaszH\nmPps4cKFTYa8VCoVvjtZh54NB1FZU4s3lq3x2kE0vyAXYUwlBNHXtfhclUqFXX+fgo54oOLTbtCu\naRrKLgMARqfIWzRoqlQqXGnwB6+Ki7FztAJNedUajQYqleqa9DSNRmPOnU5OTjYbb9OmxIGBgQgL\nCwMALh5vgamv/7dsDlCeh1VnI2Cor8HnHyjNRh9wrM8UCgX2lYYiRKBHf95pjBj3glcOohqNBu8p\nJwEAhJIeLT5foVAgOk6CAgqD9sSufze89gAajQYH/9wBAPjnzOUWDZoKhQJavT+iA/TuUs8zOJI6\nw/Yfl+7oOk1tjmwv9a65z2G1MTGHEVNf/+/lJNIrhNR/4nKKGzPL/DkA4vP5jqf1VRWTQRlK77w2\nmm5W/s+9yjuJRCKhl5JHECmFZLhyusXnm/rmp0l96O8Z3T36XEkkEpr30v1ESiF1Toxvcbrl34vG\n0HllVzdp5xrg0h3bN01luVhvsGzylGQyGfh8PmQy2TXHm5bDMwzjdd5ja2AZ6jL1dSf9Kewu9IHW\nXwL+pcPmDSb4fD70er3ZM2wuTKZZ/z/kFOhwo2E/LlQLUFmn82TTHEKhUKB7OIM64mPV/35o8fmm\nt5yTFT7o6FMChuF57LlSKBSIDtCjXO+L9FnKFr95XirXQUQVWK72vnkPh3HE+rP9x3ns7sPSk7f2\n0JtaRNPUG8B/kWv66qqXveCpGylh6tf0aOpTJJFIKCUlhUQiEYnFYnPf2etnUx+LxWJ66zY/qpst\npG7pX1L28UJPN88hvk8fSkfTOzjlaZvauuQ1o+f8zJMpHnu+VqxQ05aZI+jE1DindH/3iUFESiEl\nduvlBu1cA5zH/t/B0kO0jL1be+6We1RaY+sNwJEMmvbKNRPIZ7LBgFDQ8wnc0DkSv//8g3kS2lQa\nAIDNfrZOhSQiHKsWwZcPDOCfgXrTDq/rX4OB0Nm3BCcrAlBSUtJi3UzP0033jAMAFJ8/4rFJ4tff\nWohIfiWKagVOvSV07N4PAPDSi8+zrZrncMT6s/3HeezsYukh2vK8nS0nYBk/dub8dsVXL1LF7HDq\nlP41yZ5/3dzPKSkpdt+QTJg+F4lE/96bqmIipZAyFU9RzLi3vK5/86+UUb1CTG8n93RJt1NHDxAp\nhbR+/gse89jfWrKKTmVcR/tev9Wp80/v+IhIKaRdf/3JrmIsAM5jb3/Yi91aepe2VkBaFqIynZua\nmgqBQIDU1FS71zPJNWXQWMfs2zuWaY6V/2zGD5eF0IOPPzf+G3dfu3btNRs6W3uJNlMhA8OAyO7o\nWrYLPjHdwAh8vGZuQ6PRIPmhu+DD6HGmFC5VoIyUdoWOeOge5eexTKvhdz2ASKYM0Z16O3X+3r+N\n9ed//3k7m2p5FkesP9t//xWPne24dXOet+X1RCKR2Uu0da7JC2cYplGM2JYn6sj122OM3tReWa9Y\nIqWQJslHU5xcTeNTUti5wOZXqHSmmDqkb6aQjv28pv8kEgmNvT2JSCmkUQM7uKzTOUUX+urlvo3m\nIdzJN/vOECmFtHBMJ6eud8+gBCKlkJ4ce6cbtHMNOOixc4bdjTgbArFnJC0/tz5GrVY3CpmIxWIC\nQGKx2KbMlJQU4vP5FBgY2CjN0aQzwzCNBgZ7ellOCDrTVm/G1Lbf30slUgrpxqlqengei1X/DmQR\nKYV0+/RlJBwy5tpwTSuhVqtJkXojkVJIof48l+/pzumDaO/Urh57Pj774XcipZDkQ4ROXe/TpfOI\nlEJa8vpEN2jnGpxh9zBNGb2W/EitDbQ97GW8mPKpHbm2ybMPCAgwe1Mmg+/r69toYGhOD28wSG5j\n3cNU9U4/SkzfSj8fu8yKSLVaTf0SQomUQprx6lMUOXo28fl8rxkgv5tzN12eHc+Kl71VeS8VzY71\nmMe++ouNRo97aIxz16suIVIK6atlM9lXzkU4w+5h2Kh3bmnUrRe8mIywZcjEVgilqYGlQaens0WV\n9PvJIvrxyCWSDL2X/BL6kF9kAi1fvoLIYGjksTf3Q7TWoV2iayB6M45ylj5JXWduo+o6HStiTf2c\nPymY/vfKIEp4eZ3DA7K7UavVtHt6H/pzai9W9Ni+fCqRUkhUW8GCds2zatVS4/Vyc5wToNeTThFK\nH7x8p9c9144adm7ylCXYqK+iUqmg1+vBMAyEQuE135WWlkKr1UKlUkEulyM4OBharRbPPfcc0tPT\nzdcODAwEj8fDq5Mm44ogAtOzdmGochN6KL6D7J1svLryO2xeuwiqEQH49Qk/nE7j4+mC6cBcEc4+\nU4VTE4XYmuyPyTcIIB89okl9LXcBapdVIS/+DdRX4vuqrhiUKDYX/XK1rQqFAgEBAfgzT4+kwEtg\nAkUo1/HMk7AqlarV+lGlUqGLTzGOl/uykp7IiBMBAFWFZ12W5RCVV+u8BEc6dz6PhzKDP4T8eq+s\n4eMIjHEQ8CxJSUmUk5Pj8eu2NvZquFh/X1VVBa1WCz6fj8zMTADAtGnTUFlZCZ1Oh8DAQCxatAgA\nkJaWBr3eWNdCJBKhoqIC/KjOCO59GwK73wx+YChI34DIohyM9fkVY6VadDCcBwBUNQAHiv1wtjYY\nRfwoQCyBv78/4lGEbg3H0D2gFACQ79cF8eOWQLP9UCP9rdsjlUqRl5cHiURizsxp8/y2CPhRiaTa\nTDx1x2D4nvq50T1ypa1SqRTjEwsxf6Q/+tWqUbJzHXL/3NLq/bhi2Yd4rjADypPdIZE963Imy68/\nb8MtO5ORd9dqSIa0rNqiM6xe8DKeqFkDzLrk1GYmGo0GI868gcPUEZc7j/eqmkkMw+wloqRmD3TE\nrW/qD4AUwM8AjgA4DGBic+e09VBMS16Xm1oJ2tQ5ppCMSCRqFJ7B1YlOU6jEvPIxLILE/UZSTMo7\nlJi+laST/keDXl5CD428njY+GkQNGSFESiHtTRPTX+8+Srd0DaXgwAAKCAhoFGM/ebmCpA9NIemk\njTR4yipSpQyhS1ONseCvU8NI7G87nt5uwzLrHqbyd/pTYvpW+jtXy+qcglqtpkevjyFSCml8+huU\n/FaWV/Tjsb9+IFIKad8PWazIO3DkGJFSSJvmP+2RMNOnc5OpZm6M0+dLJBL667WO9MvMIV73LMNT\nMXYAsQAGXv13CIATAHo2dQ7bht3TccmWxNObWzxkD+usFT6fbzbipowVACSRSunzPRfoxrd2UGL6\nVoqTqylu8J2U/e4TVPJ6FyKlkIqmBtP8kX7UOVxwzQBjqy1qtZokXXvR9S8vocT0rXRzxga6snUO\n6ZRiujQllEb1EF0zD8DGHIPXoWsgejOefl+USt1nbCaJVGozDdQlqrVXFyo9SQlPvOMVk6d7N31A\npBTS2RP/sCLvoraaahThtPzp/m5vm05voM2z76CSeT2dlqFWq+n7FzvTPxl9SSJNYFE71/GYYb9G\nIPA1gFFNHcO2Yfe0UXHWY2+JbNMPXCQSXePBmby6iD7D6PqMTZSYvpXuX/wrvf3OfFp6TwCVTzd6\n5/tfENHj/XwoOjz0mtRIe2mT1kx7fzVJX/mUpK9tpOG3DKYyVUdqUIbR6J6+jfrcGyb9WCcvh0gp\npFmqOSR9bK77nrEPB9J3r/Yl6aufkUgkbtV+VKvVtPjpJKpVhFFm5nJWZOr1Bjql6E675t7q9rYV\nVdTSb7OH0uX3h7kk58/XR9KFjM703rKVLGnGDq1i2AF0AHABgLCp49g27CbvNiUlpU0aGFvhGstX\nfZORZxiG1Go1HcwrpXGaPykxfSvJ5v9Ae7Z9TIaP7yZSCqlBGUafjwunTUtm21xs5EiOvOX/i8Vi\n4geHUczj71PC1K+p+y13U06amBoUofT0jdFtqp9bzG+LiJRCSkpfR30efJ74fD4NGTKE/edr47Ok\nnSOlxPStNG/JR+zJdQKxWEzbXulNx2Z1Y3UQ+2OujC7MS2JNnj2OFJTR0YxedHHFaJfknFnzEpUr\nounoxTKWNGMHjxt2AMEA9gIYbef7CQByAOQkJLD7etNcaMGdsDGQWIdrrD100ypSQWg0SccqKDF9\nKw16dTl99eZ4qpgrJVIKqXBmNL15dyStznz/Gv0s8+Kt891t6WD5/6Y3hkChmOKS36TE9K0UO+g2\n2psmJlJFEJ36yel2ezNqtZp+eCqMTkyJpcT0rcQXRrmvbs6fy4iUQro+fS1tzMllT64TiEQiOjGj\nI22ZlMTq4PX9gnFUPieeNXn22Hm8kIoUErq8/jmX5Jz/UkGkFFKHJJlXOS8eNewAfAB8D2CSI8e7\nM8bekjADGzgzkNjzjk2etXWcdVGmhmLufIESpnxJj8x4hza91JfqZhvDLT8+KaT7ugmIx1y7SYat\nvHh7C6Cay4tXq9UkCougmLEqSpi2mUZPmExHXhZR7Zxo2rBsXqtP+LFNojSeStNDaPUrN1OcXN1o\nnoP1Z+r8LiKlkF6YraI5mw+xJ9cJNCsyqV4hos/nPsqq3M1Lr+ay17jXA9645xzpFaGk3apwSc6l\nHz40Gva+g71q3siTk6cMgDUAFjl6jqeyYthe0u/qsc3pZR2GWbpcTZnZp2iwchPNnjmRCub1J1IK\nqXZOFGnGRNCUpx5sNJFqzwu3tdjJls5N9ZfpO/B9KD5lASVM2UTXdb+OiqcJ6dgrIgr2bV+7L325\nJINIKaQXp02lsFFpLdshqaVgYwcsAAAgAElEQVTUVZFeKaIPX72PbmnlHZUq848YHYas95s/uAUs\nemMKkVJI05++363O1sfb/zL+Rn5b5pKc0r8+JVIKafjd93mVs+KoYWdjgdJNAFIBjGAY5sDVv7tZ\nkOsy9nYMsod13WxHFic0tZORPSwXM5n2Gw0LCzPX8Z6/YCHe/+pP7MitRfAPU/EzJuB1n48RKw7G\nr6KH0WlJHab9pMeqr3aCiMAwDMRiMTIzMxvpYbqOKRfedB3A9v6cTfWXTCYDwzAI9PNB9Q8fQld6\nCVWjFHhmZxi6iglL7xO6VAXQm9BoNDi8dTkAYDfTF4EVudf0Lav4BuJoMdCLTuBcmQ7qVty5Z2vW\nSgDAwdwKVuVu++0AAOD4vl/dWpe9tvQSAMAvNNolOUGhxsVNac+kelUeu8M4Yv3Z/vO0x95UznFz\nE5f2YCvMY/aEr3q7O4/k0oIFc2hPhrG6XvWsUPo8OZw2LZlFEkm8OUzjqJ62rmPPg7cOAdnLwVer\n1RSWcB0lTNxASbM3Uf33SuNr9tFvXOoLb0EikdDmxwLoxJRYSpi6mT7M1Lj1emq1mlaPEdKV6WGU\nmL6FJN37u/V6TfF6svGtsOfAwazJVKvVJOk1kEgppMmj2Kk/Y+86jz31pPFZPPOLa8Ly9hIphfTp\n6kx2lGMJ/BdqxTRnXE1xY1O4oqkQgyN55s4sNmpOf1MRrpsH96HPlA9TsSKOSCmky3M707oXh1JE\n0L9xXZMxdyae3VRf2BvQ7F3T1P7pi1ZTYvpWmvXFXrryRncqnBZKzz/+iE392lK2kmbFcipND6E1\nr8koJuWdZguhuYpEIqEXrvchUgrphvTVNOm9NW69XlP8orqTChVSVgcziURCPlEdqEoRSR8+2tFt\nYS2JRELPyccbDXvhMdeElZwlUgrptQljvOqZ/U8YdkeMq704s4mWGJyWGFdH5CZGi+iFW6Np71Tj\nQqJ6hZg2TehEt3XxJbEotNEkp2VKp7PXs3dcU5PPAQEBjd4oLPtBIpHQvG1HKDF9K428fQQ1ZISQ\n5v7Gx9t7G/Bq8vcTKYX08vR0Cr0lpVHpYnegVqvpwYHGFajPzlTRuPlZrTYInl1wE+Uob2B1IFar\n1STpfB2dzOhOX03o7LbnQK1Wk/I1Y4llqip2TVhNKZFSSIrn7/OqZ7ZdG3ZLT9eRCoSuPqD2slaa\n8jzsDjp6PdGZnXRw3nCqzhATKYV0ZHYPmjFuKEUI/c1yTStOTbnr9uQ5Yzib6hPr61iWMbDO4lGr\n1VSv09P9S36jbjM20/Kx8URKIY3sHmq+Ly0Jb3kNfywhUgppSPpqkgyU2dywmnVqK4iUofTJvOcp\nIWVeqw2C5XMl9N1bj7KeNmwwGOiXjJvp5Jy+bnsO1Go1LU5/lHRKkfF35goGA+mUIlo86QGvembb\ntWG3jkuzRXPZIs2lDDYpqzSXKHsh1b3bm0gppFJFDK2Z+SDJ7nuQ+IFCc3tMBtSUu24y7M3p5ky8\n3V7NF8vP7L0pWB43f8kqSpj8Jd0/dw0Z3rmOKPMm0qxY3mgwtNbL20IzjfTJGkfFb3anHhnfUl2D\n3m3PmzXa1zvTttcGUNcpn7dO+ujVfVg3LZ3ulvuzWTWGSlUdWJNnjSShA2XNup8uzYhyWZZaraai\nWdH0WcYDLGjGHu3asFvnXLfkvKYeVnteSkpKyjU/bHuyGhnCuiqivz8nw5qHyKA0FtL6bfZQmpox\nkzre9Szxgv6NeQcEBDQyoI4MHo60qalzXAmPWPaVRCIh4eAxlJi+lfZ9oyZSCukVWVSTstn2CF3F\npI+Az6eauTG07fWH6MmPdhOR5wqcbU4No7NToygxfStJOnf3eP/UnTHuPPTlhlVukb/h7ReNYZKG\nWrfIf3vpKto+W0YHX4tjJanh2JR42jLzNjIYDCxp6Drt2rBb05RxswyjOOplW3uZlh6bvRi3CR8B\nn0Z24tMnDwZQxUyjMc+bnUCLZj1BN722mFLnf0qlVfWNwkmmkJL1dd3t1Toj39SPlkvr1Wo1SaQJ\nNETxJSWpvqOGZTdTuSqBOifGuzQH4UlMg3evSJ4xe2PmVHpm4XqP6rD73ceIlELqk/4ZTV+02uP9\n883bE4iUQpr79ntukb8u802jYS8+7Rb5+86X0L6MgfSDPMblAVGtVtPuVxPp19lDacly92ZFtYR2\na9htGQST4bUsZWudvWJrZyJHwxvNDgoGA21coqTloyPMJW5LZ4XTp9PvprHT36a4JxdRcN9RxAj8\nKCAgwK5unnjdbynWfWTZj9bfH84vo04zvqGVq1cZf8B/LPE6A24P0714cbAfkVJIN09fRZLe7KX8\nOcK2DycTKYX06IyFJL39aY/32dLU7lSrCKOE/re4Rf76rDVESiHpT2W7Rf73hy7ShYzO9Om4qGYd\nMEf44cXOdCijD0mu68uCduzQbg27rVd4y1CJpaG0NKC2CmFZhiIsPVHTa7fl99cYKIPBmD3x41wy\nfGjM0a3LCKVv04fS8zMyqMukLIq8byoJOw9opJvpj2EYs06WA4dbVzg6gHU7LfvblCVj0t36eyKi\nuZsPU2L6Ftr5fCzVzI2h7h3jvW6wsoWp3afmD6NCZSIlvLKOVqzw7H3o38WY6qqc9DhF3DfF4332\na/oAOp7Rg8Y+/oxb5G/cnk2kFFL5rtVukb9u1zmqUkTSe/eIWOm7PW+MpFxFJ5q7+GPXlWOJdmvY\nW+qx28LW5KG112yZ1WEaDBKk8fTV4plE388i/ft9iJRC0ilF9OuMJJo581XqO2099Z24iiIH30fi\nqFjzeZbL/q2Nu6fCLo5ibagt9bI1qFrrXVpdTwkTP6Xbn5pIpBRS1ktuqIboLgwGMrzdlbbNuZsm\nZu3z+OXVajVdmhJKm6cPp4TnNR7ts5SUFDo+NZ6+mSlz24Dy/YFzREohXdqscov8xd8dIFIKadrN\n/jRkyBCX5V36/DWqVESytoE5G7Rbw050bd51Sya2bHmdlp/5+Pg0Mu7rMt8m2ruGNj8RRcXTRebS\nuNkZw2jKzCnUb/JqihyjIOmtj9Hlshq71xSJRCQQCK4x7t7myToyX9FcP7/wzjpKTN9K2yfEU+FU\nIXVpItbuDZjatWGZMQY8Y+Zr9PmeC62jzNoxVLhgIHWcvpVq6tnZONsR/Hz4VK8Q0Qev3suKUbTF\ngQtaKlRIKHf1s26R/3bWt0RKIT3Z36dReq6zFH9rfB6+2uOeOQFnaNeG3Tojw5YXaTL2Q4YMaZRt\nYit17V8Z8bR28Rs04dZ4WvN4Ip2cYlw0QkohXVQk0oZZ91Pa9FnUW/42PTpvA/145BItWa5xKivF\n0cHIWzx5R/i3XWHU67XVNPpVpTFDZoiv1w1glpju/+QRUURKIY2YvoIeeWJC6yjz41zSzwmjbulf\n0oELWo9ddspTDxorTD71kHn+hG0ul9XQgYz+lLf4TrfIn7diNZFSSHd1EbDiNFX/tpxIKaT1P/7F\nkoau064Nu8nYrVihpswVapIkdKClyzVGI9uhC/kGi4jnH0K8wFDih0SST7iU/OO7028ni+iuZ9Mp\npNet1GvYnfTgmAforcnj6ZNXhtHu9N5Urog2G/JiRRxtnz2cVK+Nozc++oKW/XSSdh4vJEnHLnZj\n4e4wwqZ8dsvVj95k7G2FagBQYId+lJi+lY7NHUQFU0Jp5QrXqu25E5PuJ+YPp6JZ0RT37DK3Gbdm\nObSJSCmke6Z/SFm7z3vssrojW4mUQhp1/wOsTDzavIbeQN9mjKSi+e6ZjHzzvXeM6ZpLMlj5fej/\n2UikFNJHX3pPDSRHDTtjPNazJCUlUU5OjlPnLlnyLoovnkUDBKiHAA0kQAMEaAAfPtDDBzr4MDr4\nQgc/1EPMVEKESoiYSoSjAnHMFcQxxfBh9GaZZQZ/HK+LhF6ShLqIPtidb4Di7WVo0F4CdHUYP348\nsrOzoVAo8Msvv2DdunUAAJFIhODgYMhkMmRnZzfauV6hUGDatGlgGAYLFixwukJcWFgYtFotxGIx\nSkpKAKDVd7G3xFIXmUyG9evXw/RMRT0yFyMT9FgfvAi4dxGQ9FSr6toc9H5vfFccjfG7u6Hql4+w\nZMkSz1f2Kz4NLB6IWQ3PYO0RPjLu7uYRHcp+fAehv72OL0b+jkdu7u2262x4fTwepB3wz7gIMAyr\nsue/OQPTG5YBrx4CRFLXBZ7+GVj7INSdl2JCaorr8liAYZi9RJTU7IGOWH+2/1zx2C8uvsPsVTvy\np58jptp5Hajy3f5UvmQ4HZwno8VjE+nNsb3p9s4CkgoZu963ZaYKrnrNpn8zDGOeFLVcZGTLe7V+\nJbSeI2jKu7D1vbd47NYhJctJaT6fTz5RHSkxfQsdmJxIx18WUphY1GSbW7Vd2vPGjJSZL1FA1xta\nb/5Dryd6M54+mTSKosctMCcEuLtPLq15hgoVUvr9ZJFbr7PqbWNKJ1WXsCrXYDDQe7PlRtn1tue6\nWszVmkHLMj9gRx4LoL2GYlatWEqJ0aGUGB5AXaICaEAHEX2+VEV08R+S9YqlTmKGJEKGusWJjIV8\nDAabMW3LHHJ7xsY6VdKyfotlvRjLQlmma6SkpBDDMBQYGHhNqqWtreq8OQZtj6YyaEx9Hjd6Jr2S\nPsUc+7TVZjZWwrrMgSyjjtOXkCgqtnV3g1p1Jx2dM4Ckr37mkUl2tVpNf72aSLsyBlNuSZXbrkNE\npMl8z2h8L/7Dqtyymnr6aNYjVKeKY09oyTnjYrUXU1vdiTLRbg27vYlTy5Wc1j9KW96ztRFyZPm+\nZf0We8balm62/t3UgNIU3uKtW+rSVHrp+StV1C19ExXMiKEfnwi2mY5qna7q7rbZ7MOvX6KKOXE0\neslOt17bIb6ZSvWqaOqQvpnE0q5u7xOJREJFMyJo3cz7Sad37/L5lVmfEymFZGC5dv+pwgr6evYd\ndGYqixus15QZV+JOfNRrHK92a9jtpTra8vYsDU9TNcIdqdZoOt7W4idrXayv15LQS3N4k4fvqKc9\n5s0NNH/GM0RKIfWO4tnc6MMtm0TbwVYf6hb1px9n30rvbj/eSK9WGUT3rSVSCkk2XUOT33d/bfbV\nme8TKYX0boZrG0A7wrofdhs3kPltOaty/zx9hX6ffQP98Xwke8+QwUANSjEtTh/rFY4UUTs27CZM\nhtQU37auVGjLWFj/UG0tVHLkupZvCKbzLXGn8fUmj91W/1kPcBKJhMLiO1GfyWuoKkNMK+/3tzmI\nerJd1gPtdXHGMhBvzHyelB9+3OSCLI9QYFxokzZjJknves79fXN1M+1FSz90j3wLthzIpVpFGF3Z\nNJ1VuZsP5NOxjJ707bOuFwCzpPKNDrR+9kOkd/ObjKO0e8NuGV6BjeJc1iEPomtTB22VpG3JZKXJ\nU7XeYcebjK87sdVOy/tiOdEcc88rtGbmg1QzS0iRgbYH49ZAIpHQ2F4CIqWQ7nttHvEFPvbLSHgA\ntVpNkWGhVDc7hBZPfpBuV33h9gHGsNeY//3hF9+7Rb4lig8/pnMZXWj/G8NZlfvswvVUpJDQP/Pv\nYFWudkE/2jJ7FGmr6liV6yzt3rCbJicdyTwxYW2Ibf1gmvvMVliluRIG/yWsPXbzW1PX3jRyxgoi\npZA+u1pmwBt2VVKr1fTx6FAqV0SRdMz0Vq/XY3rW9j8XRD9N7ku3LPjJ7QNM5daZVKsIozW/n3KL\nfEsk3frQH7NvoL9eTWRVbuK9L5BeEUrv3x/JqtzTqv702+yh9NYS10sZs3Ef271hdzWMYu//rWPx\n9lL6mhsMbMn/L2LZB2PmbaBfZw+l0rmJRHqd1/RP7bt96YfZt9LL765tdX1Mz9v6R0JJq5RQYvpW\nKq+pd+s1S1aOoeMZPSj7eKFbr6NWq0kUFk5fzLqbiuYksio79XWNcb+D9x5nVe638ng6lNGHwq+7\n3jVBteX08zNiurebwCVHpt0bdmeNgi3jbcKWgbb28lvisTsz+LRnJF170YRpM43pbse2tYoO1zw3\n2gvGzIeZL1JRhXs2gHCKPzOJlEJKSl9Lwk4D3JoZc3FuV9o2+zZasNQ9G2yYMP0ePpj2KOmUYiJd\nA2uyZ2ZuMD5Xh75kTSYR0brxMZSr6ESiXsNcE1SWbyxQdluURzx2XrMrmLwUuVyO3Nxc86o8jUYD\nqVQKjUZj83jT9+np6SgtLYVWq4VKpWp0jEKhMK8aNWHsy3//a3ldlUqFvLw8ZGdnm1eASqVSpKam\nQiqVQiaTQSKRgGEY5OXlXXO9/xIajQaVRfnY/HcJLhnEOPO/Oa2ih+meme/F2Z0AgKLIG7Apa02T\nz5BHiekDAOjFOw9DaJzN55UVdPWI0BfilD4Wi+fPZV++BabfV5V/NPjQA5WXWJNtqCw0/iMokjWZ\nAFBWY4AYFfAJFrsmqL4aALDgvcWeWc3siPVn+4/tHZSIms5EscyQEYlELa4Gac/btpdl01w2zn8R\nU9/4CCPp3emPm3fS8XTfWL9xbUyNoiKFhMa/9alHUy6bpaaUSCmk+dNSKeyOl9znsV8+SqQU0kuv\npnlsUdaMuQoipZC+XjyDFXlqtZpenmwsE02Fx1iRaWLX248SKYUkHT7Opb7ZuNjY5i3vT3RJH7T3\nUIw1TRkIWxky7sDWtnEcRkz3Z8iQIdTz7lRqUIio7Kt0uymjnkAiiaeCaWG0efbtJOl/S6tPnFpT\npupIW6bcQEMV7IYXGnH4ayKlkO5+ZqLHBrURjz5NpBTSi8OiWZEnkUppzow0o2GvKmZFppm/jLH7\nbrePc6lvRt/QkUgppOTRrmXtOGrY22woxpqmQjOmV8DMzEy3vgZlZ2dDr9cjPz+/kS4c/96f/Px8\nHP/lG3yvHwT+P+sRIDB+z7BcEMoR3pvxPGIDdMihnshIS/XIM9IShN1uwqDgK8ivAlao3RMeoqLj\nAABxxwHXhCHdRQUFAACEvBpWwl6TZigRwauAHjzAX+SyvEYEGEMwkshQp/tGo9GAzzOGcpOG3MSa\nak3Rbgy7NZaxVGujb0lzsfmWYCtGz9EYhUKBWFEg9gTcgiB9OTTTH4VEIsGCBQs8rsuDA4zx2B2n\nasEw8L7BOKYvYqkQwQI93li0gnXxGo0GX656F/kUjhG3DvNY+48ePoJSCoJU7MPKvMHtDzyMcJTj\nSq0AmlWrWNDQgquG/babBjndNyqVCjzGAAC4+VYZW5o1CSuGnWGYOxmGOc4wzCmGYaazIdNVHDWy\npgEgLS3NZePe1ADCYcTUR2kvTcNpikMf3YFGE8+me8DmgGsLjUaD7z9+E7mGSOz96y/vnNiO7QsA\n6MGcx8PyiayLV6lU6BCiw2lDHDpEBLIu3x7Dh/RHAUWgY7gfK05QUUUdIpgyXKoi9u9jQBgAgGq0\nTotQKBSIi4oAAAQFh7KiVnO4bNgZhuEDWArgLgA9ASQzDNPTVbmu4qiRVSgU4PP50Ov13vnjbqdE\nhwbguPRRJNQcxaUjf1yTrXJN9goLWA4W816fi2FR1fhN1x215/+BTCZj7TqscTUzpg//AuJ6Xs+6\neEVGBrqLDThNcUgMD2Jdvj1uGdQb+RSBPlIhK05QYUUdophSlNQL2H9bvuqx82qdN+xyuRyPj38U\nABAc0kYMO4DBAE4R0RkiqgewAcADLMj1CHK5HJmZmXa9e3d7ju0Ze32n0WggFovxrFKNavLFnjWz\nUFlZCbFYbL4H7ghrWQ4WH0xNgVDQgO9yAwCDDtnZ2axdhzVCYoHACAwJyMfRixWsi5c/ejeCBHqc\npnhIxZ7z2D9coEI+hSO4vogVedt++g2RTBliOvVm/235qmH3qSt1SUxDTSUAIDS07Rj2eACW2/jk\nXf2szWDPu9doNEhLS/vP56A7iz2vW6VSobS0FBcLLuLzS1KM8jsIH19fBAUFme+BO8JaloOFqOok\nGoiPnw8XNhpQvAqGAWL6oBfvPI5eLGdf/pUTAIATVUFY/THLsekmUMyehfz6YIQKGoDaMpfl/fxn\nDiJQih1//s2Cdlb4hUDP8BGgL0edTt/88XbQ11bCQAxCgoUsKmcfj02eMgwzgWGYHIZhcoqK2Bmp\nXcHam7TlXapUKuj1evD5fO/84Xs59rxuhUIBkciYvfDB9nPwZxrwyoMDzMelpqZCIBAgNTWVVX0s\nB4tI7T78pe+KvMN7Gg0o3sbfhYSomlMoKquEtqqeXeFFRsN+pFDHyhyTo8jlctQExAAANn70gcvy\nbhjQGz6MAQNvvdtlWdfAMKj3CYUIVdBWNTgtxlBXhRrGD3y+Z0wuG1fJB2C5waDk6meNICI1ESUR\nUVJkJLurwxzF0ng7EtP1VJpke8WW123q+3vvvRcikQjny4AjTFc8HnMadzz4GAAgKysLer0eWVlZ\nrOhhed81Gg0G95CiR0AJdlyJgCjI36sHbfWW3fDjGdCVyWffa79yHKUUhEslFR6fYzqUa/TUt6xb\n5rKseJEvAODG2x90WZYt9H4ihDKVKHFhYKWGKtQy/ixq1TRsGPY9ALoyDNORYRhfAI8B2MyCXNax\nNN7W3qQt75LLcmEf0z3IyspCaWkpgoKCEHf3VCQwhdixdT0AIDk5GXw+H8nJyaxeU6VSQaVSISnB\n+AMb+cQMlJSUePX9vfXRlwEAPZnz+GjTdtbkajQa/LF1HU5THB667SaPp+lGdOkHAJA/cqfrwqou\nG/8bHOO6LBuQvxhiVOKOB8Y4/1ZTX416JoBdxZrAZcNORDoALwH4HsBRAJ8T0WFX5boDS+NtbbQ5\nI+4ZTPcgOTn533j3wNGo8IlAp7Of4kJxNdauXQudToe1a9e6dC2Tpy6TySASiVBVVQWZTIb7e4cg\nn8KRlDSUpVa5j7HPT0d1A9BDfwzb/zrCmlyVSoXOoTqcMsRj/P0jPf7sX3/jCNSRANf3kDZ/cBMQ\nEXyqr9aJCY5iQbNr4QWFQXTVY09PT2/x+RqNBpXFBag28N2gnW1YCfgQ0TYi6kZEnYnoTTZkugN3\nGG8ua6ZlmO7B2rVroVAooFKpoPnoEzBJT+NW3t+Yl7kKUqkUN9xwgznO7mwfWxZpCw4Ohlarxa4/\nfsctwXnYXhiOZ55+0j2NZBMeHxWBieiFM4jtkcSa2LdmvYboAAOOkxSdI4NZk+soMaJAXKRw1F85\n75Kc8lodxIarqYjB0Sxodi38oDCEMlXgBwjNxQBbgkqlQgivHleqW36us7Tblaeewh351v8VLPsu\n+MZnoQMfSTW/4nItD7t37zbH2Z3tY9PbgUwmM6dTTpGPQRBTh437tMjKymoTA3N0v5EYEFwCrd4X\nDXoDKzJTRg0AABxtiMGMic+xIrMlxIkCUEDhMJTmNn9wExRV1CKKKYVOEAj4uWeA8g0OhwiVEEVL\nsHDhwhafr1AoIBQ0gB8U7gbtbMMZdhfhygg4T6O+C4nG1rM+eETwC+Jk4yEQCMxxdmf72PR2kJ2d\nbY7nd8MplFIgduw/h+Tk5LYxMMf0gb++ElGGyzhdVMmKyD83fwQAOFgswAaWJqlbQmyoP/IpAj6V\neS7JKSyvQyRTioYA94RhAIAXGIZgphZPPzvBqbf9p595FiG8WgRFxLlBO9twht1FuNi881j3HXP9\nswhlapDcrRbT3lkJnU6HYcOGmSe7ne1j08CQNk2BQTW7UBg3CrX1OnM4yOsH5qulBXox51jLjLmw\n51sU6kNwuagESUnshXgcJVrojwJEIKC2CNA7n0b42ebvEMWU4sCpAve9dQUaFynVVRY7dXp5TQNC\nUA34eSaHHeAMO4cXYAqHFPomwhDdFxN8t+NvdIDBQDY96paET0zplQqFApJQQMhUI+7GsWYZgBcW\n/7Imqhf04KEPTuGz735nReTwXtE4jkQ0lOQhP/+a7GS348PnoRhiMCBsUL/rtJxN3/2ECJThQnGt\n2966dvyxHwCQf+aoU+eXVtcjBDXgBXhm1SnAGXYOL8BsvF9/HbybXkZHykX05Z3YtD/fpkfdEmNv\nPnb+uwg69Q1qeEEI7jGqkQyvj7P7+OPgZQP66o/g18NnXZdn0CPCUIRjlAAhqlvtbeWU1jiZ+D8X\nFikNHX4HIplSlNa7bxHhqk+/BABUX3FuACyrKIcPo8eXW7/32DPGGXYOt9Oc4TStRK2qqsLKXSWg\nUCkmB36Lt749irHjn7ym+qO1sW+q9INMJgOfz8d1d4zHKGYXTvr0hLRjF/O2habMHG+Ps++9zKC/\nTy4E4VKnMjMaUXIWPH0djpMUg7pKkZaWxvoqX0eo8TVWTrwt6TqnZUgSEiBkavDcZOdDdc3x8OMT\nAAAxIj+nzq8qLwEAFBSVeuwZ4ww7h9tpynCaQiV1dXXQarWYmj4DzI0vo6fuCDrVHMKC7481kjFh\nwgT88ssv/6ZKXj3fuvSDqdDY+vXrYWAE6BFUCiFTgzc2HW60T61cLm8TcfbOw8ZCKGhA18BKFFXU\nuSas0LjM5DhJsTVrFaurfFvCoXNXAAAVec7n5+efNNaHeXG6ym3ecB3PWCAtkKqdGlSzf/gOAFBv\n8FxpEs6wc7idpgynyWDX1tYCAOrq6tDtsddRofeFvGoVPt19AXvPlzQqq2uZApmWlmb2vi1LP5gK\njRERhEn34xH/3dDywjDq2TltcoWxbPxkAEB/3mkccXUC9fJhGMBDlbALHntkDKurfFuCJCYSRSTE\nwK6xTstoKDFm1Zy6XOk2b1j19mIAgBBVWLKi5cXSdv+eDQCo1cNjzxhn2DncTlOG02T0x48fD4lE\nAn9/f5w8l4/3fqvEKFEuulYdgHzlr8j+7U/zOXq9HvHx8eY6+pbet6VckUiEsNhEXHfjSNzEO4TV\neyshn/BcI2+/raDZlI2yOqA/cwqrv97hmrDLh1HAi4U0Kpy1Vb7OcPpgDvIpAgLTylEniAsxbqlY\nzQtxmzc8aboCDQYGYqYCCz9oeW2bmwYPBAAUFpdzMXaO/wbWK1GJCAEBAVhxgEFpLeGVysUorueh\nvs+DEIvF5r1Rc3Jy7CL+a10AABtTSURBVNbR12g0mDZtGhiGwa0vLURqwG9gQLgQdgukUinS09O9\nPqZujer1N/BXng796Dh27Dvmkiwq2I/9ukR0jw1hSTvneHLsQyigCPSIc06Pmno9xDAWE/t13wm3\necPyCRNQyw+GCFV45oVXWnx+pzjjwqQLhWVcjJ3jv4cpfFJfX4+LpTVYvI+H+xJr0PXwcgT0HI7g\n3iMwfvx4c+jA+k0gNTUVPB4PEyZMQGlpKaqD43G43AdP+2WD1+NefPHjHuTl5YGIvD6mbo1CocA/\nxQL0EOTDTxhprlTZ4myeykIw5fk4oO+InrGey6u2xXOPj0U+RSCkoQgatbrF518uN646NTB8IDDM\nDRr+i48wCqFMJW4ZeVeLz6Vq4+Spb2gMF2Pn+O9hXSBMMuYNVPOCoYj+HbqCw/C58Um8OHeReeGS\ntVHLysoyT27x/IMRfvereKB+GwL1ZcANaWb5Cxcu9PqYujVyuRyT38uCgCH0DatF+szZzmXzFBwA\nABw0dEL3mNY17FEhfsg3hCGAb8DihXNbfP7KTzcililGGSOEZtVHbk1ZZQLDIEYlip0o3cuvNRr2\n/cfOcTF2jv8elmGZ3NxcPPXcSwi8Q4lhUsLxSV3RITIY8jU5yDlXYtOoJScng2EY+PgHIHr0LPiF\niDBNlG3cOzTxpjYxSdok8YMAAP35Z1DlI0JxcTECAgJQVVXlsEHL2aKBgYCjlIhOkZ7b59QWPnwe\ntDxjmGLua8+2+Pw1G7cgFiU4VVjj9pRV/tUKj1NmKls8eAjqtKhmAgG+j1t0swVn2Dm8m6SnUSyI\nRem6p3C//1FEBPshZdVuPDxp3jXhlLVr16Ksug6xY+fCV9oHoy+8gwhDIXDrdIBhvH8hUjNoNmzG\nuXIekngn4BffHTU1Naivr4dWq7WbSmrdXu2hn3CyPgzlJcXw8dBuPrYw6VbONy7Xf2hEy8oaaDQa\n1PMDEcOUQCTp7vaUVX5QGEJRiYp6avHgwa8pxpU6gUefO86wc3g3fAHkX5UhPpjgu306/n73CVTm\nHcemy2G4/fUv0UP2ECpqG3Clsg6f5+Ri1Hu/gBfbA367V2FO7wKjl9v9HgBtvxKnSqVC9plaDGaO\nILhDH4jF4kZ17W0db93epHg+DlJnRPvrPKn6NZh023fqovGDFlZ5VKlUaPAJQhxTjK4Dbnb72xgT\nEAYxU4WQyNgWDR5EhGBDBa7U8j363HGGncPrCeoxEkv+qkfaAGBwUD7yV09G7e7PsPeCFimrdqPP\nnO1IeuNHTNv4D8RBvvjyhZtwfHoPBOtLgdvfNG4KjbZfiVOhUOBguRDhvCoMH9AVJSUl5rBVU6mk\n5vaWX4RYUIdD/B44vvtnhIWFtdrbi0m3Xr0HoJr8YCi90PLzYyLgzzRgzvsa97cjQIwgphZ333NP\niwaP6no9RLwqlBt8PfvcEZHH/wYNGkQcHI4ikUjIXwD65/kgujQ5mDqIGBKJRFRV10A7jl6iZT+f\nopW/nqGccyU0PiWFZB19SK8QEm2e2Nqqs0/xaSKlkGbNnEjvLltJEomE1Gq1Y+ce2kSkFNKD098n\n/w4DCABJJBL36tsMae+so6MZvejkm0NbfO4L73xCpBTS6B4C97fjr5VESiE99eHXLTrtQnEVncvo\nQudWJLOiBoAccsDGch47h9diubWdf7AI8u0+CArww49PhGLxW7MR6CvAiO7RSJN1xjM3d8SgRDF2\nf7sBn4/xw4liAzBqbpuPq1+DuCPqA2MwmHcM76/9ukWhpYPbVqJGz8ch6oiA2iKIxeJWf3vZsuET\nXKAo6ItPt/hcfpUxjFPvH+H+dgRFAACYqistOu2j9Z8jnCnHhStV7tDKLpxh5/BaLLe202q12HVa\ni+Bnt6BzZABSqldhy5IZEIvF/4YULuzG7ufDwOcxWFU9EvAPNcuYNm1a+zDwDAN+x5swhHcMN947\nrkWhJTr/O3KqY1BfoUXJxVyv2Mj7paeScZ6i0TFEDxgc3x2qtkGPkDrjJtZbsve6vx1BkQAAfm3L\narJ/mrUewUwtft1/3B1a2YUz7Bxei82YeOJQ4OnvAIaP+64sw6YH6qG6oQbd/0oHProdYeFRCJu0\nC29/tMm4ifDVLfHq6+uRl5fn1GbE3sbv+QyiGS2Kzv7t+AYkteXoHUHYy++LXrGtm+ZoyWsTnsR5\nioIvGrBe/Z7D510qq0UMU2JcnOSmvU4bEWj02P3rtajT6R0+bfzouwEA/W6QuUMru3CGncNrsZvp\nENsXeHE3/hLejYggAcb39UXHyEC8tYtBwvw8aDYbN6MwrWQNCgqCr68vALhe8tYLePE9Y33w2yKK\nkfbyRMdWoeb9BR4IewT9MfrWQR7Utml8BTycqwoAAHy6+A2Hz9N8uhGxTAnKIQR4fHep9y9XQzER\nTDmKKx1fpDTgugQAgOzOh9yilj04w87RNvENxOBJWei9tAzi+WXok1mFmd+XIbew1Bx2say5vnDh\nQvOq07aMRqPB4bwyHNT6YrjgIHxiukGlUjWfynlmJww8H+w3dEV/qcizSjfDuQqjYY72rXZ4V6zF\nK9ciFsU4VVTjbvWM+ItgYPgIY8ox5NZRDuv5zeefAAACwz233ynAGXYOL8aeF2qqCRMUFGT2VsvK\nyszfm8IullUf2/yq06uoVCoQEb49XofreccR1bkXZDJZ86mcp35EbnA/1PEC8J5iEgQCQatsrmEL\nfVAUdMRDJzHPoYlglUoFJigMMUwJcrUNnpk34fGg9w9DOMpRXFXvsJ4ivrEcNRMc424NG8EZdg6v\nxZ4XaqoJU11dbfZWLUMsvr6+bTpfvSlMBrxeejN8GD1Gdg3E1q1bm9zw+9PMt4HCI1h7TozA2iJk\nrV3daptr2CL/1DHkUwQ6h/Eb1d23h0KhQGBEHGKZYpy5Uu2xhT//b+/eo6OqrwWOf/dMCCEJIU+S\nmEQShFoovrhoV31U7IPaa5W2y7r0itY+RhoftdUWrq13qNTeNlarLntLV6ba2kDx3nXVpeXWKlZT\nq+UhLwUBJUgeBCGBJEDIe2bfPyaJCSQkkMycmcn+rDWLMDmZ2Wcy2fM7+/zO/mliJhlyhMz8qcN6\nb3m9XvJTXHSpCxIzwhDhRyyxm4g12Ci0tyfMuHEcOnSIQ4cOkZaWxoIFC6K2yddw9F2Y+4mX3qGp\ncxxfzNyHjE86aRlmyzMPAfD3hCvYu/HV3vudWFxjINd89hKqNJtpmfGUl5cPub3H4yEnI4VE6aD6\nsA7rw2A0uCdOJkOOsMj702G9tzweDzPzJgbbJrjCm2otsZuINVj5pKysjEAgQHZ2Nq2trbS2tqKq\nJ70KMxbms/c9gvnRfyzhxX0pXOnewMLF9/d+AA60n9dfMImaY3Hsck2hrXorIkJpaakji2sMJHWc\nn2qdzFlpMuyjrI9lJQCwuyEwrA+D0eBOziTTdfSUliaMbznA3pbw9okBS+wmivVNAh0dJ5+pEO19\nYqD/EYzH4+HaH/+eZGnjnJQjvR9oJ+xnSwOzEg7wfEMh6u+ivXY7qampEXU089RvfkWVZpM+3o9n\nwbVDbh8IKJPdwXMqVUcIW8lt254DpAWaWP/O8Bc6SfM38mFLePvEwAgTu4j8UkR2isg7IvKciETW\n6XYT9U420vZ4PKSmBt9yPdMZBxPtfWLgxCOYcVMvozEuk4KaF/AHgucY+u6nz+fjh1fPIN4NLyZc\nyaSuJvKysygpKXFyN/rx+Xw01+2lyh+cTvjck48MeWR14GgbZ7qDPc6/f/+jYfuQevH1t0hxtVGx\np3JY2/sDyhnuRg50JoX/fTecvgOD3YB5QFz31yVAyXB+znrFmOHKz88/aU+T0tLSAfulDHZ/rHl/\n5WL1eyfp5s1v9bu/tLRU3W63brw1SXd+L0OnLP6zLiuvcCjKwfX8fufdcb/qkhQtvix7yB429z32\nB336x9fo4Z+Et8/NE8WXqi5J0ct/8F/D2v7goYOqS1J0Q9l9oxYD4egVo6ovq2pP/8+1QP5IHs+Y\n4w010h6sDh8LpZfhyPv8nXThpuuNx3vv8/l8FBcXc3EezM51s37y1wBh3swwXKF5inp+v/GZZxFQ\noSCx7YQeNscftT31v6s4U+rYWXfqqxmNxJp3dgGQpK3DOmdzZH8lAJJ2ZjjC62c0a+zfBF4c7Jsi\ncquIbBCRDfX19aP4tCaWne7881govRxvoGSSmJHHmtSrOL/+BT5z7pm9M2cCfj8ln0ugxTWRv0z6\nGtMnJzM1KzniTiL3/H4vvnA2NZpJUXIHqsHFLHpiPP5DunDWHArkAO0JWWGN9errvwlARnw7S3/2\n8yEHDi11ewBIyCwMR3j9DTWkB14Btg1wm99nmx8DzwEynMMEK8UYc+oGKkstWLBAC2acp03eHN38\n3WydXpinpaWlet+8yapLUnR/uU+nLF6lBZ//Rm956vjHiAQr11Xp6vsu1+13ZWpaWlq/GI8vq029\n7l71eyfpw1dnhjfI+l2qS1L0e/cu1mu/vnDIUt+mZx5WXZKic2afO2olQUarFKOqn1PVWQPcngcQ\nkVuALwE3dj+xMSYEBjoKWblyJTU73uHOhus5J7WNNd9K5oqGFfz0U21UJczgN40XoQE/tW8+1zsH\nPhKPZKZmJVOheRRN7OTqq77YL8bjj9ounJGPS5TZn/1qeIPs7heTLkdYu2X70EeSTdV0qpvN7+6K\nulkxVwKLgGtUtWV0QjLm1ERaeSFUBipLBS8yUp597W0Wdt5NfMIEMps28+v1HXyurIWytdV07Pw7\nk8ZL7zTJSLx4qygziQrNI8GtfLDptZPGmO06AsDcr3wjnCFCwiT8uMmUI5xz4cVDvufimvexn3Ry\nszLC/kE60hr7r4GJwGoR2SIivx2FmIw5JWPlROlAysrKWLBgAW3vvcHatiIuaynBV/AIJe/mkHfd\nT/B3dVJf/hRJSUkRl8z7ykyOp5Jgo6z7Fl436HaNxzqY3F7V/UMfC0doHxGB5Gyy5DDbKqqHfM8l\ntdRy0J3tyAfpSGfFTFPVAlU9v/v2ndEKzJjhitTyQriUl5fj7+rk8F8fxR9QyuryKLr9SSpbx9P6\nj9+TEheI+NdGRBiX8wkAvnDB4LNIdtc3M0320TE+AxLTwxVeL0nJJVsaufzKawZ9z/UcQU5qqWTH\nkfGOHEnalacm6kVqeSFcvF4vqampHKrcwYdP3c34ht1UbXuLlpcepX79nyN+tN6jMC+bfWSidduB\ngUtsu+ubmeaqJRDu0Xo3V0ouea5G8qbNHPQ9t3TpUg7X7SXD1cyuI/EsWrQo/HGG/RmNMaPK4/GQ\nnJxMa2srhyq3s+Hx26kuW0xn5QYmTJhAbW1txLToPZkZuSls9RfStXcz0L/E1pPkn139T6bJPuJz\nZjgS47s1DWQEDrJ+265Bt/F6vVwyIxeA3YfdiEi4wutlid2YGOD1evslELfbzYMPPkhHR3Be+PLl\nyyP+5PKM3BS2BQpxN1QwJSet30IpPUn+ve1vM0mOsbbi1NYeHS3PvLyGSa42avbVDrqNx+Ph+7cE\nV0yqaYl3pIWDJXZjYoDH4+HGG29EREhMTGTZsmV4PJ5+rXkj/eTyx3MmslWLcAkUJhxl1apVvd/r\nOY9yblZwRvUjf1rtSIz7jwX/zU0+eepc90pw+cI9DV2OlMEssRsTA3w+X+8CJOnp6b3JpKysjNLS\n0qg4uTwxYRzVruCJ08vOSkZEeksxHo+HzTsqODfxIABXfftHjsR41Q3B1zU3vo3m9q5BtzsrPY4D\nmkpLc3O4QuvHErsxMWDp0qX4/X7c7uAqRGlpaaSnp+Pz+fB4PMydO5fi4uKIr7VP+9hM6iWDB267\nlpKSkn4fSA898d+c49pDvWsytyy805H4rrr+2wBkSyOP/27wfvafnJ5FpeZwh+fr4QqtH0vsxsSA\nnlLFsmXLKC8vp6mpicbGxt7yy8qVKyNqObzBnFeQyqauIvzVb53wvT/95XVmufbw5u4jDkTWbWJw\n7dJsaeBXy54cdLNc92GqA5O57RZnVqmyxG5MDOg75bNn+mPfLok33HADbrc7YpbDG8ycKWmsDczA\nfbiSxx9Y1O8ioJkzppMnhzg28SznAhyfQnOnkC2NuJJPnEfv8/mYkp1KYsdBPuAMMpJOvk5AqFhi\nNybGeDweGhsbaWho6Fdr7+rqipjl8AazcfWzvNl5NgCX5mlvKSYQUGaM2wfAb1/a7lyAIhzVRHKk\nkbNnf+qEby9atIgz4oN19e2HJ3DzzTeHO0LAErsxJoL8/IGlbP2wjYP+RO6ef37vUcj7dUe5NGE3\nB9vj2H4o/PPC+9pzsI3JgToqDzSd8D0RYWZWMK3uaIp3rPRlid0YEzHmzp1LW+UWXtULmerfBZ2t\nAKypqOdS11bWHIjnFyUPOhpjxrQLKHAdZNq5F55wdWxJSQmfLJpEq46jqrHDsdKXJXZjTMQoLy/n\n2M43eS5wKa6OZnjvRXw+Hy8+9RDZ0kTieV9xvD3C2Z/8ArnuI1Tvr2fhwoX9zgN4PB6+/eXL2K15\nLL7rNsdKX5bYjTERw+v1kp3g5333dA66MmHdb1n6y8f4VvZODnfGcdMDETCrJ60QgDMnKorgdrv7\nXSMQqNvJLs3jjEkJDgVoid0YEwF6ShoANTU1FM87j4fb50PNOl64MYUvxG3iofXQOvg1QeHTk9jj\nDpFeMK33Kl8A2o8Sd7SWXYE8zkid4FiIltiNMY47vqd++/ZXWdk0i6f9V3CBvss6OZ8/vT+BBx90\ntr4OfJTYpY7nX3mzN6n7fD7mXxzsOrlL8ynKTHIqQkvsxhjnHd9T/xcP3E/t017uee88pm/9Jpty\nF7C7ai+A86tlJWURiJvAmVJHVcOx3ruXLl1KnivYnOw9mWojdmPM6IjWZQJ7LqzqadHr9XrJSRRa\nX3mcimcf5c7bgu0QiouLnV8tSwRJL2Kq6wDVhz5aEdTr9XLZtBQOk0x8egFul3PTMi2xGxNDonmZ\nwL6x91xJW1JSgtvt7m2H4Pf7geC0SCfJ5BnMdO+lou6jJl8ej4cbLp9BhXsaRVnJDkZnid2YmNJT\n0pg7d27UjdwHWuLw9ddfJxAIkJiY2NsWAYLTIh2VPYscrWNHRcVHr3NXO1q3g42dBUx1sL4OltiN\niSk9I93y8vKoG7n37XfTU1JasWIFqkp7eztlZWUsW7YsMloQZ88CIM+/j9q6huDrXLsJCXSysWsa\nNTs2ORqeJXZjYlC0L/DdU5ZJSEjo17wsYta3zQkm9o+7qknILgq+zlVvArA+cDZ/eORnjh4tWWI3\nJgZFTAI8TT0fTI899lhkNi+bmEuLJHGO7OHm794bfJ2r/kmNnEFDIIm2Ax84erRkid0YE3Ei/oNJ\nhAPji/iUbGNfezx0ttH5wT94rSmHJH8zeTlZjh4txTn2zMYYE8WeeLWCBy5u4/CBPVDxCuO0g5fc\nn6a5cis1NTWOxmYjdmOMOQ0zv/ID/ArXpWxlyx/uob7Nxbq42Xz14k84HZoldmOMOR3/VvxDXq5N\n5Pa4Fzh/wn4er51JZ0AonNDudGijk9hF5B4RURHJHI3HM8aYaNAw5x5Wt5zNis4rWJF5B60V63n4\nP3/idFgjT+wiUgDMA6pHHo4xxkSPG7/zA7K/+zL3y0JcCcmMr/hbREwxHY2Tp48Ai4DnR+GxjDEm\nqpybn8obi6/ALULGz692OhxghCN2EZkP1Krq26MUjzHGRBWfz8e/zJzOsyv/6HQovYZM7CLyiohs\nG+A2H/gRMKzjDhG5VUQ2iMiG+vr6kcZtjIlhPp+PtLQ00tPTI77fTc9VssXFxRETq6jq6f2gyDnA\n34CevpX5wD7gIlXdf7KfnTNnjm7YsOG0ntcYE/sKCgrYuzfYfz0/P9/xeeEnc9NNN7F8+XIg9LGK\nyEZVnTPUdqddilHVrao6WVULVbUQ2AvMHiqpG2PMULxeL6mpqaSlpUXEyciTWbVqFQAiEjGxnvaI\n/YQHEqkE5qjqwaG2tRG7MSZWpKen09jYSFpaGg0NDSF9rpCP2I/XPXIfMqkbY0wsKSkpIT8/n5KS\nEqdD6WW9YowxZgR6GpX1dHOMhMZlo1aKORVWijHGxJKek71Rf/LUGGNMUKQtbGIjdmOMiRI2YjfG\nmDHKErsxxsQYS+zGGHMafD4fBQUFEdNGoC+rsRtjzGkI10yYvqzGbowxIRRpM2H6shG7McZECRux\nG2NMmERavd1G7MYYM0J25akxxsSYSKu324jdGGOihI3YjTFmjLLEbowxMcYSuzHGxBhL7MYYE2Ms\nsRtjTIyxxG6MMTHGErsxxsQYS+zGGBNjHLlASUTqgaoRPEQmcHCUwokWY22fx9r+wtjb57G2vzDy\nfZ6iqllDbeRIYh8pEdkwnKuvYslY2+extr8w9vZ5rO0vhG+frRRjjDExxhK7McbEmGhN7KVOB+CA\nsbbPY21/Yezt81jbXwjTPkdljd0YY8zgonXEbowxZhBRl9hF5EoReU9EKkTk352OJ5RE5EkRqROR\nbU7HEi4iUiAir4nIdhF5V0TucjqmUBKRBBFZLyJvd+/v/U7HFA4i4haRzSKyyulYwkFEKkVkq4hs\nEZGQL0YRVaUYEXED7wOfB/YCbwE3qOp2RwMLERH5NNAM/FFVZzkdTziISC6Qq6qbRGQisBH4cgz/\njgVIUtVmERkHvAHcpaprHQ4tpETkbmAOkKKqX3I6nlATkUpgjqqGZd5+tI3YLwIqVPUDVe0Angbm\nOxxTyKjq60CD03GEk6p+qKqbur8+CuwA8pyNKnQ0qLn7v+O6b9Ez2joNIpIPXAX8zulYYlW0JfY8\noO9KsXuJ4T/6sU5ECoELgHXORhJa3WWJLUAdsFpVY3p/gUeBRUDA6UDCSIGXRWSjiNwa6ieLtsRu\nxggRSQaeAb6nqkecjieUVNWvqucD+cBFIhKzZTcR+RJQp6obnY4lzC5V1dnAF4Hbu8usIRNtib0W\nKOjz//zu+0wM6a41PwOsUNVnnY4nXFS1CXgNuNLpWELoEuCa7prz08BnRGS5syGFnqrWdv9bBzxH\nsKwcMtGW2N8CpotIkYjEA9cDLzgckxlF3ScTnwB2qOqvnI4n1EQkS0RSu7+eQHBiwE5nowodVb1X\nVfNVtZDg3++rqrrA4bBCSkSSuicCICJJwDwgpDPdoiqxq2oXcAfwEsGTav+jqu86G1XoiMhKYA1w\ntojsFZFvOR1TGFwC3ERwJLel+/avTgcVQrnAayLyDsGBy2pVHRNTAMeQbOANEXkbWA/8n6r+NZRP\nGFXTHY0xxgwtqkbsxhhjhmaJ3RhjYowldmOMiTGW2I0xJsZYYjfGmBhjid0YY2KMJXZjjIkxltiN\nMSbG/D8IJ25tGvXN6wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqbLGgCqTwr8",
        "colab_type": "text"
      },
      "source": [
        "## >> Logistic regression\n",
        "\n",
        "## Logistic regression이란.....??\n",
        "- binary 형태로 예측을 하는 regression\n",
        "\n",
        "## 빈용 메소드 모음\n",
        "- **PolynomialFeatures ( degree = )**: polynomial feature 만들어주기. degree가 2이면 제곱항까지 만들어줄 것을 의미\n",
        "- **PolynomialFeatures .fit_transform ( 데이터 )**: polynomial feature로 바꿔주기\n",
        "- statsmodels을 이용할 수도 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upALragvUADK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic regression 에시\n",
        "# 먼저 데이터를 반응변인과 예측변인으로 분리하기\n",
        "Y = (df['Status'] == 'Developed').astype(np.int) #'Developed'면 1, 아니면 0으로\n",
        "X = df.drop('Status', axis=1)\n",
        "\n",
        "# 예측변인과 반응변인을 train set과 test set으로 분리해 줍니다.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 1. 먼저 모델을 만들어 줍니다.\n",
        "logReg = LogisticRegression()\n",
        "\n",
        "# 2. 모델 적합시킵니다.\n",
        "logReg.fit(X_train, y_train)\n",
        "\n",
        "# 3. 트레이닝셋과 테스트셋에서의 성능을 확인합니다. (이 경우 결정계수 R^2)\n",
        "print('Training R^2:', logReg.score(X_train, y_train))\n",
        "print('Test R^2: ', logReg.score(X_test, y_test))\n",
        "\n",
        "# 모델로부터 반응을 예측하고 accuracy, f1-score, confusion matrix를 구해봅시다.\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "y_pred = logReg.predict(X_test)\n",
        "print(\"Accuracy: %.2f\" %accuracy_score(y_test, y_pred))\n",
        "print(\"F1 score: %.2f\" %f1_score(y_test, y_pred))\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1TfWMl1TwQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statsmodels.api as sm\n",
        "model = sm.Logit(y_train, X_train)\n",
        "results = model.fit()\n",
        "results.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFNrbmwwWcMP",
        "colab_type": "text"
      },
      "source": [
        "## >> Softmax function\n",
        "\n",
        "## Softmax란??\n",
        "\n",
        "Logistic이 binary만 예측이 가능했다면 softmax는 여러 class를 예측할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUsNgvTvWpVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# softmax regression 예시1\n",
        "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
        "y = iris[\"target\"]\n",
        "\n",
        "softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10, random_state=42)\n",
        "softmax_reg.fit(X, y)\n",
        "\n",
        "x0, x1 = np.meshgrid(\n",
        "        np.linspace(0, 8, 500).reshape(-1, 1),\n",
        "        np.linspace(0, 3.5, 200).reshape(-1, 1),\n",
        "    )\n",
        "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
        "\n",
        "\n",
        "y_proba = softmax_reg.predict_proba(X_new)\n",
        "y_predict = softmax_reg.predict(X_new)\n",
        "\n",
        "zz1 = y_proba[:, 1].reshape(x0.shape)\n",
        "zz = y_predict.reshape(x0.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(X[y==2, 0], X[y==2, 1], \"g^\", label=\"Iris-Virginica\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"bs\", label=\"Iris-Versicolor\")\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"yo\", label=\"Iris-Setosa\")\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
        "\n",
        "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
        "contour = plt.contour(x0, x1, zz1, cmap=plt.cm.brg)\n",
        "plt.clabel(contour, inline=1, fontsize=12)\n",
        "plt.xlabel(\"Petal length\", fontsize=14)\n",
        "plt.ylabel(\"Petal width\", fontsize=14)\n",
        "plt.legend(loc=\"center left\", fontsize=14)\n",
        "plt.axis([0, 7, 0, 3.5])\n",
        "save_fig(\"softmax_regression_contour_plot\")\n",
        "plt.show()\n",
        "\n",
        "# predict\n",
        "softmax_reg.predict([[5, 2]])\n",
        "\n",
        "# predict probability\n",
        "softmax_reg.predict_proba([[5, 2]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gTEdK2mn6fBk"
      },
      "source": [
        "# 0. Machine learning: Linear model (with Pytorch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yv04oq_i6fBi",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YfPXOpIa6fBh"
      },
      "source": [
        "## 빈용 메소드 모음\n",
        "- **Basic**\n",
        "  - **torch .FloatTensor()** : matrix를 생성하는 메소드\n",
        "  - **.matmul( )** : 행렬간의 곱을 구해줌\n",
        "  - **.mul( )** : 행렬간의 사이즈를 늘려서 맞춘 다음 곱을 해줌\n",
        "\n",
        "    *: 같은 결과를 반환\n",
        "  - **.mul_()**: in-place operation. 기존 tensor를 변환시킨다.\n",
        "  - **.mean ( dim = )** : 평균을 구해줌. dimension을 선택해줄 수도 있음\n",
        "  - **.sum ( dim = )** : 합을 구해줌. dimension을 선택해줄 수도 있음\n",
        "  - **.max ( dim = )** : 최대값을 구해줌. dimension을 선택해줄 수도 있음\n",
        "  - **.max ( dim = )[ 1 ]**: argmax. 즉 최대값의 index를 반환해줌\n",
        "  - **.view ( )**: reshape과 비슷. 원하는 형태로 tensor를 바꿔줄 수 있다.\n",
        "  - **.squeeze ( )**: view와 비슷하나, dimension의 element의 개수가 1인 경우에 그 dimension을 없애준다.\n",
        "  - **.unsqueeze ( dim = )**: squeeze를 반대로 해줌. 원하는 dimension에 1을 넣어준다. 꼭 dimension을 명시해줘야 한다.\n",
        "  - **torch .ones_lie ( )** : 같은 사이즈이되 1로 찬 tensor를 반환\n",
        "  - **torch .zeros_lie ( )** : 같은 사이즈이되 0로 찬 tensor를 반환\n",
        "  \n",
        "- **Type Casting**\n",
        "   - **.Longtensor ( )** : int(?) 형태로 저장한다.\n",
        "   - **.ByteTensor ( )** : Boolean 형태로 저장한다.\n",
        "   - **.long ( )** : long tensor로 바꿔줌\n",
        "   - **.float ( )** : float tensor로 바꿔줌\n",
        "\n",
        "- **Concatenate, Stacking**\n",
        " - **torch .cat ( [ ,  ] , dim = )** : 2개의 tensor를 합쳐주는 방법\n",
        " - **torch . stack ( [ , ] , dim = )** : 쌓아라! list형태로 tensor를 쌓아라! dim은 어떻게 쌓을지를 말해준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3dedba00-76a1-49b9-cca4-4d0ec0695fed",
        "id": "KLBidX-v6fBY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "# in-place operation\n",
        "x = torch.FloatTensor([[1,2],[3,4]])\n",
        "print(x.mul(2.))\n",
        "print(x)\n",
        "print(x.mul_(2.))\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n",
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "45603a68-61e1-4ecb-dd7a-fa94768ccfd5",
        "id": "LH2di5iy6fBW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "m1 = torch.FloatTensor([[3,3]])\n",
        "m2 = torch.FloatTensor([[2,2]])\n",
        "print(m1 + m2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5., 5.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "dddf62ac-884c-4700-b2a4-bbc11740854d",
        "id": "bxpyKGmD6fBS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 사이즈가 맞지 않지만 차원을 알아서 늘려서 실행을 해준다.\n",
        "m1 = torch.FloatTensor([[1,2]])\n",
        "m2 = torch.FloatTensor([[3],[4]])\n",
        "print(m1+m2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4., 5.],\n",
            "        [5., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4671d164-6b38-4541-9c49-e1e52303c94f",
        "id": "T54o4pPo6fBO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# Multiplication vs Matrix Multiplication\n",
        "m1 = torch.FloatTensor([[1, 2],[3, 4]])\n",
        "m2 = torch.FloatTensor([[1],[2]])\n",
        "print(m1.matmul(m2))\n",
        "print(m1 * m2)\n",
        "print(m1.mul(m2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 5.],\n",
            "        [11.]])\n",
            "tensor([[1., 2.],\n",
            "        [6., 8.]])\n",
            "tensor([[1., 2.],\n",
            "        [6., 8.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "24ca01ea-a23d-475f-caf8-a356db08513a",
        "id": "63FT8LNO6fBI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# .mean() 예시1\n",
        "t = torch.FloatTensor([1,2])\n",
        "print(t.mean())\n",
        "\n",
        "# .mean() 예시2\n",
        "t = torch.FloatTensor([[1,2],[3,4]])\n",
        "print(t.mean())\n",
        "print(t.mean(dim=0))\n",
        "print(t.mean(dim=1))\n",
        "print(t.mean(dim=-1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.5000)\n",
            "tensor(2.5000)\n",
            "tensor([2., 3.])\n",
            "tensor([1.5000, 3.5000])\n",
            "tensor([1.5000, 3.5000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f38cbe02-4c19-46d8-ac24-661fb8cf8b3a",
        "id": "ARunkFlH6fBC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(t.sum())\n",
        "print(t.sum(dim=0))\n",
        "print(t.sum(dim=1))\n",
        "print(t.sum(dim=-1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(10.)\n",
            "tensor([4., 6.])\n",
            "tensor([3., 7.])\n",
            "tensor([3., 7.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9f9fcd97-a728-40c5-f785-a4a635983668",
        "id": "y-ncX52N6fA5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# argmax: 최대값의 index를 반환\n",
        "t = torch.FloatTensor([[1,2],[3,4]])\n",
        "print(t.max())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e4ab220f-72bf-4414-df7d-3b70866e2c83",
        "id": "FIg9V_s56fAz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "print(t.max(dim=0))\n",
        "print('Max: ',t.max(dim=0)[0])\n",
        "print('Argmax: ', t.max(dim=0)[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.return_types.max(\n",
            "values=tensor([3., 4.]),\n",
            "indices=tensor([1, 1]))\n",
            "Max:  tensor([3., 4.])\n",
            "Argmax:  tensor([1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "062a6a0e-a500-4c1f-e6d4-0fc400d6e182",
        "id": "ZeylQC7s6fAv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# view 예시 1\n",
        "t = np.array([[[0,1,2],\n",
        "               [3,4,5]],\n",
        "              \n",
        "              [[6,7,8],\n",
        "               [9,10,11]]])\n",
        "ft = torch.FloatTensor(t)\n",
        "ft.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9dc3da0d-f896-40f7-f7df-ab423fa9e86c",
        "id": "kCLR4hpa6fAo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "print(ft.view([-1,3]))\n",
        "print(ft.view([-1,3]).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.,  1.,  2.],\n",
            "        [ 3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.],\n",
            "        [ 9., 10., 11.]])\n",
            "torch.Size([4, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "097734bc-1be9-471b-efda-a479392ca324",
        "id": "3dEroZjT6fAh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "print(ft.view([-1,1,3]))\n",
        "print(ft.view([-1,1,3]).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.,  1.,  2.]],\n",
            "\n",
            "        [[ 3.,  4.,  5.]],\n",
            "\n",
            "        [[ 6.,  7.,  8.]],\n",
            "\n",
            "        [[ 9., 10., 11.]]])\n",
            "torch.Size([4, 1, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f1f7b935-770b-4d68-e2d8-404cffd15c6d",
        "id": "ObEoLjA26fAb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# .squeeze() 예시\n",
        "ft = torch.FloatTensor([[0], [1], [2]])\n",
        "print(ft)\n",
        "print(ft.shape)\n",
        "print(ft.squeeze())\n",
        "print(ft.squeeze().shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [2.]])\n",
            "torch.Size([3, 1])\n",
            "tensor([0., 1., 2.])\n",
            "torch.Size([3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f8230d28-7ae4-46df-f9a9-f4e77204f919",
        "id": "88wPLB-i6fAV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# .unsqueeze() 예시\n",
        "ft = torch.Tensor([0,1,2,])\n",
        "print(ft.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "30ab6d05-ca94-4384-9f47-ef34774afd4e",
        "id": "0hfVY0Zb6fAQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(ft.unsqueeze(dim = 0))\n",
        "print(ft.unsqueeze(0).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 1., 2.]])\n",
            "torch.Size([1, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a4850460-2ecd-4091-a57a-55595a374b03",
        "id": "vLmihUJH6fAJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(ft.view(1,-1))\n",
        "print(ft.view(1,-1).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 1., 2.]])\n",
            "torch.Size([1, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "47c8ddc2-5377-4b5d-9318-5d2a33eebebb",
        "id": "CbHLway36fAB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(ft.unsqueeze(1))\n",
        "print(ft.unsqueeze(1).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [2.]])\n",
            "torch.Size([3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2866f192-7c30-4dce-9ad9-c14b7dedb018",
        "id": "BTzknNLQ6e_-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(ft.unsqueeze(-1))\n",
        "print(ft.unsqueeze(-1).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [2.]])\n",
            "torch.Size([3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7e1fc330-c995-4def-fe36-c44e8fa88879",
        "id": "_TkqXGHT6e_w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# concat, .cat() 예시\n",
        "x = torch.FloatTensor([[1,2], [3,4]])\n",
        "y = torch.FloatTensor([[5,6], [7,8]])\n",
        "print(torch.cat([x,y],dim=0))\n",
        "print(torch.cat([x,y],dim=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.],\n",
            "        [7., 8.]])\n",
            "tensor([[1., 2., 5., 6.],\n",
            "        [3., 4., 7., 8.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d386dbce-7d79-4c5a-c198-df300fdae2d0",
        "id": "-v_XDhEo6e_m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "# .stack() 예시\n",
        "x = torch.FloatTensor([1,4])\n",
        "y = torch.FloatTensor([2,5])\n",
        "z = torch.FloatTensor([3,6])\n",
        "print(torch.stack([x,y,z]))\n",
        "print(torch.stack([x,y,z], dim=1))\n",
        "print(torch.cat([x.unsqueeze(0),y.unsqueeze(0),z.unsqueeze(0)], dim=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 4.],\n",
            "        [2., 5.],\n",
            "        [3., 6.]])\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[1., 4.],\n",
            "        [2., 5.],\n",
            "        [3., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9631789f-c587-494c-9816-514933fa34a7",
        "id": "ul1w9HVY6e_f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# .ones_like(), .zeros_like() 예시\n",
        "x = torch.FloatTensor([[0,1,2],[2,1,0]])\n",
        "print(x)\n",
        "print(torch.ones_like(x))\n",
        "print(torch.zeros_like(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 1., 2.],\n",
            "        [2., 1., 0.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rqjDn-746e_d"
      },
      "source": [
        "## Linear Regression with Pytorch\n",
        "- Basic\n",
        "  - **torch .zeros ( , requires_grad = True )** : 초기화 시킬 때 사용, requires_grad=True는 학습할 것이라고 pytorch에게 명시하는 것  \n",
        "- **torch.optim**: 모델을 개선시킬 때 사용하는 라이브러리\n",
        "  - **opotim.SGD( [ , ], lr = )** : Stochastic gradient descent를 사용하기\n",
        "  - **zero_grad ( )**: gradient를 초기화\n",
        "  - **backward ( )**: gradient를 계산\n",
        "  - **step ( )**: 개선된 gradient의 방향대로 W(weight), b(bias)를 개선한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1PQ47scB6e_U",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oX4FE47Q6e_P",
        "colab": {}
      },
      "source": [
        "## Linear regression 예시\n",
        "# x: 공부시간, y: 시험성적\n",
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])\n",
        "\n",
        "# hypothesis를 설정하기\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD([W,b], lr = 0.01)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(1, nb_epochs+1):\n",
        "  hypothesis = x_train*W + b\n",
        "  # cost 구하기\n",
        "  cost = torch.mean((hypothesis - y_train)**2)\n",
        "  \n",
        "  # 모델 개선 by.stochastic gradient descent\n",
        "  optimizer.zero_grad()    # hypothesis 예측\n",
        "  cost.backward()    # Cost 계산\n",
        "  optimizer.step()    # optimizer로 학습"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mT9PWpxM6e_O"
      },
      "source": [
        "## Gradient Descent with Pytorch\n",
        "- Basic\n",
        "  - **torch .zeros ( , requires_grad = True )** : 초기화 시킬 때 사용, requires_grad=True는 학습할 것이라고 pytorch에게 명시하는 것  \n",
        "- **torch.optim**: 모델을 개선시킬 때 사용하는 라이브러리\n",
        "  - **opotim.SGD( [ , ], lr = )** : Stochastic gradient descent를 사용하기\n",
        "  - **zero_grad ( )**: gradient를 초기화\n",
        "  - **backward ( )**: gradient를 계산\n",
        "  - **step ( )**: 개선된 gradient의 방향대로 W(weight), b(bias)를 개선한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "84Hglysp6e_J",
        "colab": {}
      },
      "source": [
        "## Gradient Descent 예시\n",
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[1],[2],[3]])\n",
        "\n",
        "# 모델 초기화\n",
        "W = torch.zeros(1, requires_grad  = True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W], lr=0.15)\n",
        "\n",
        "nb_epochs = 10\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "  # H(x) 계산\n",
        "  hypothesis = x_train * W\n",
        "\n",
        "  # cost 계산\n",
        "  cost = torch.mean((hypothesis - y_train)**2)\n",
        "\n",
        "  print('Epoch {:4d}/{} W: {:.3f} Cost: {;.6f}'.format(epoch, nb_epochs, W.titem(),cost.item()))\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vg6i6rTL6e_F"
      },
      "source": [
        "## Multivariate Linear Regression  with Pytorch\n",
        "- Basic\n",
        "  - **.matmul ( )** : x의 길이가 바뀌어도 코드를 바꿀 필요가 없고 속도도 더 빠르다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pU1TZqmZ6e-_",
        "colab": {}
      },
      "source": [
        "## Multivariate linear regression 예시\n",
        "# 데이터\n",
        "x_train = torch.FloatTensor([73, 80, 75],\n",
        "                            [93, 88, 93],\n",
        "                            [89, 91, 90],\n",
        "                            [96, 98, 100],\n",
        "                            [73, 66, 70])\n",
        "y_train = torch.FloatTensor([[152],[180],[196],[142]])\n",
        "\n",
        "# 모델 초기화\n",
        "W = torch.zeros((3,1), requires_grad = True)\n",
        "b = torch.zeros(1, requires_grad = True)\n",
        "\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=le-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "  # H(x) 계산\n",
        "  hypothesis = x_train.matmul(W) + b\n",
        "\n",
        "  # cost 계산\n",
        "  cost = torch.mean((hypothesis - y_train)**2)\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print('Epoch {:4d}/{} W: {:.3f} Cost: {;.6f}'.format(epoch, nb_epochs, W.titem(),cost.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H8il_7gI6e-2",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2Q_WkdOaHqF",
        "colab_type": "text"
      },
      "source": [
        "# 0. Machine learning: Loss function, Fitting, Validation, Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p54mqIekrI7k",
        "colab_type": "text"
      },
      "source": [
        "## Loss function vs Cost function vx Objective function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQXxBFYZrMXv",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "![123123](https://postfiles.pstatic.net/MjAxODEwMjdfMjQ4/MDAxNTQwNjQxMDM2Nzk2.BBIktuYfZGDOltDPfnFZtGtGyAytqArZhHrc2uh2vCMg.Amk9px-LZyU2cH9WTmHwv_NA38VsVtgtV49FRbhRnX0g.PNG.qbxlvnf11/20181027_205024.png?type=w773)\n",
        "- Loss function은 data point! single data set을 다룬다는 느낌이다!\n",
        "\n",
        "![123123](https://postfiles.pstatic.net/MjAxODEwMjdfMTI3/MDAxNTQwNjQxMzQ3NDIy.Ud2tujcppuIOyhBsUgdf1X3eu9Ea-6K2zZfdqONRLiAg.RcUTI8Da51xFVHWXMsJsEjAJ_tTo6IaFoddR4MACVIgg.PNG.qbxlvnf11/20181027_205501.png?type=w773)\n",
        "- Cost function은 loss function의 합이다. 즉 entire data set을 다루는 것이다.\n",
        "- 순간순간의 loss를 판단할 땐 loss function, 학습이 완료된 후에는 cost function!\n",
        "\n",
        "![123123](https://postfiles.pstatic.net/MjAxODEwMjdfMjM1/MDAxNTQwNjQxMzQ3NDU2.cpPY6GJ0oeJLiz4h_Xs3pKVuv5V5f32aHSfbfX_rsEgg.a2QE606kUdtjPVt2JBlbpB4ZtgQST06b1dZN9KqOnSkg.PNG.qbxlvnf11/20181027_205532.png?type=w773)\n",
        "- 총 정리\n",
        "  - A loss function **is a part of** a cost function **which is a type of** an objective function!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rawrOgibaMlA",
        "colab_type": "text"
      },
      "source": [
        "## 과대적합(Overfitting)과 과소적합(Underfitting)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07yTtSLzaT2S",
        "colab_type": "text"
      },
      "source": [
        "**과대적합(Overfitting)**은 모델이 Train Dataset에 너무 잘 맞아서 일반성이 떨어지게 되는 문제입니다. 즉 Train Dataset을 너무 과하게 학습해 학습되지 않은 데이터가 들어오면 분류하지 못하게 되는 문제를 일으킵니다. 아래 그림의 오른쪽 그림들이 과대적합의 예시라고 할 수 있습니다. 보시다시피 Train Set을 거의 다 거치거나 분류해내며 굉장히 높은 성능을 보여주고 있지만, 새로운 변수에 대응하기 어렵습니다.\n",
        "<br>\n",
        "**과소적합(Underfitting)**은 반대의 개념이라고 할 수 있습니다. 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 발생하는 것입니다. 아래의 왼쪽 그림을 보시면 쉽게 이해할 수 있을 것입니다.\n",
        "<br>\n",
        "![123123](https://mblogthumb-phinf.pstatic.net/MjAxODA3MzBfMjMy/MDAxNTMyODkwNjUxMjY4.H_ocFIRFaG8MWrBsv8BWrTCaAMGLMKZZUh_Rd1krRLog.HAZRdDtrQMvVGKiEWfGls8bm0EhTyRKf7XzoSY1Cibsg.JPEG.qbxlvnf11/maxresdefault.jpg?type=w800)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq59BZ8taV87",
        "colab_type": "text"
      },
      "source": [
        "## Bias와 Variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkJDU95VaZFz",
        "colab_type": "text"
      },
      "source": [
        "위에 설명한 과대적합과 과소적합을 극복하기 위해 간단히 bias와 variance의 개념을 살펴봅시다.\n",
        "\n",
        "![bias](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile9.uf.tistory.com%2Fimage%2F99CDCC33599AC28F075E3C)\n",
        "\n",
        "Bias는 실제 값에서 멀어진 척도, Variance는 예측된 값들이 서로 얼마나 멀리 떨어져 있는지에 대한 척도로 보시면 되겠습니다. \n",
        "우리의 목표는 당연히 Bias도 낮고, Variance도 낮게, 즉 모두 정확하게 예측하는 왼쪽 위의 그림입니다. Overfitting 모델은 high variace 모델이라고도 하는데(오른쪽 위), Train Data의 지엽적인 특성까지 반영되어 학습된 것은 잘 예측하지만, **학습되지 않은 데이터에 대해서는 예측력이 떨어지게 됩니다.** Underfitting 모델은 High Bias 모델이라고 하는데(왼쪽 아래), 너무 적은 특성만을 반영하여, 예측의 범위가 좁고 정확도가 떨어지게 됩니다.\n",
        "\n",
        "다시 말하면, Bias 에러가 높아지는 것은 많은 데이터를 고려하지 않아(=모델이 너무 단순해) 정확한 예측을 하지 못하는 경우를 말하고, Variance(분산) 에러는 노이즈까지 전부 학습해(=모델이 너무 복잡해) 약간의 input에도 예측 Y 값이 크게 흔들리는 것을 말합니다. 이 두가지 에러가 **Trade-off** 관계에 있어서 이 둘을 모두 잡는 것은 불가능 한 딜레마가 생긴다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAqSwjHGacNA",
        "colab_type": "text"
      },
      "source": [
        "![graph](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile9.uf.tistory.com%2Fimage%2F996DB433599AC34225B9BD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osFKBMIeahau",
        "colab_type": "text"
      },
      "source": [
        "그렇다면 어떻게 Total Error가 최소인 지점을 찾을 수 있을까요? 효과적인 방법은 **Validation Set을 만드는 것**인데, 바로 살펴보겠습니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20wHD6tBajW2",
        "colab_type": "text"
      },
      "source": [
        "## 데이터를 train, valid, test로 나누어 사용하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu44Man1anJK",
        "colab_type": "text"
      },
      "source": [
        "#### Validation Set?\n",
        "![datasets](https://t1.daumcdn.net/cfile/tistory/9951E5445AAE1BE025)\n",
        "\n",
        "우리는 머신러닝/딥러닝의 모델을 학습시키기 위해서는 전체 데이터를 train dataset과 test dataset으로 나누고, train dataset으로 학습한 뒤, test dataset을 통해 이 모델이 제대로 동작하는지 검증하는 과정을 거친다고 배웠습니다.<br>\n",
        "그렇다면 Validation set은 무엇이며, 왜 필요할까요? Validation Set을 통해 우리는 모델의 성능을 대략적으로 파악할 수 있습니다. Train Set의 일부를 떼어낸 후, 남은 부분을 학습한 뒤, 모델을 통해 떼어낸 부분에 대한 예측을 도출합니다. 우리는 떼어낸 부분의 실제 값을 알고 있기 때문에 예측치와 비교하여 성능을 평가하는 여러 측정 공식을 통해 모델의 성능을 알아봅니다. 그러니 Validation Set은 모의고사 문제라고 보시면 되겠습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64SKm7tlao8h",
        "colab_type": "text"
      },
      "source": [
        "### 교차검증(Cross Validation) vs 홀드아웃 검증(Hold-out Validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUcC3t11az4V",
        "colab_type": "text"
      },
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KWBBgOja0A_",
        "colab_type": "text"
      },
      "source": [
        "그렇다면 Validation Set을 만드는 대표적인 두 유형에 대해 알아보겠습니다. 위에서 Validation Set을 만들 때, Train set에서 일부분을 뗴어 내 그것을 Validation Set으로 설정한다고 했습니다. 그러나 Validation Set을 뗄 만큼 데이터셋이 크지 않다면 어떻게 할까요? 이때는 너무 많은 양의 데이터를 Validation Set으로 뺏기지 않게 하기 위해 일반적으로 **Cross Validation** 이라 하는 기법을 사용합니다. Training Set을 여러 Subset으로 나누고 각 모델을 이 Subset의 조합으로 훈련시키고 나머지 부분으로 검증합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeRnNRA1a0Gk",
        "colab_type": "text"
      },
      "source": [
        "![validation](https://t1.daumcdn.net/cfile/tistory/990DD2465B72F1491E)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AloC9S0oa0Na",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "X = np.arange(16).reshape((8,-1)) ## 8개의 row, 2개의 column\n",
        "y = np.arange(8).reshape((-1,1))\n",
        "kf = KFold(n_splits=4) # 8개의 row를 각각 2줄짜리 4개의 set으로 분리합니다\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index] \n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "# 각각의 iteration을 print합니다. 첫 줄의 의미는 2~7번째 row를 학습하고 0,1번째 row를 validation set으로 하여 검증한다는 것입니다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsej6CYFa0U4",
        "colab_type": "text"
      },
      "source": [
        "### Hold-out Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuGbr1mObz7d",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Original Set을 무작위로 training set과 validation set, test set으로 구분한 뒤, training set과 validation set을 이용해 분석 모형을 구축하고, test set을 이용하여 분석 모형의 성능을 평가하는 방법입니다.<br><br>\n",
        "Hold-out Validation의 전체적인 pipeline은 다음과 같습니다.\n",
        "1. Original Set을 무작위로 training set과 validation set, test set으로 구분합니다.\n",
        "2. 하이퍼파라미터를 여러가지로 튜닝해 여러가지 세팅을 만들어본 뒤, 학습 알고리즘을 사용해 Training set에 모델을 학습시킵니다. 하이퍼파라미터 세팅에 대해서는 나중에 더 배우도록 하겠습니다.\n",
        "3. Validation Set로 모델의 성능을 평가합니다. 가장 좋은 성능을 기록한 하이퍼파라미터 세팅을 선택합니다.\n",
        "4. Training Set은 보통 클수록 좋습니다. 그러므로 모델 선택 후에 Training Set와 Validation Set을 합쳐 더 큰 데이터셋으로 3에서 선택한 최선의 하이퍼파라미터 세팅을 사용한 모델을 학습합니다.\n",
        "5. 이제 Test Set을 사용해 모델의 성능을 평가합니다.\n",
        "<br>\n",
        "\n",
        "<br>\n",
        "Cross Validation과의 가장 큰 차이점은 Hold-out Validation에서 Test Set의 경우, 모형에는 영향을 주지 않고, 모델의 성능 측정 만을 위해 사용된다는 점입니다.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IENdy_Z0b_UV",
        "colab_type": "text"
      },
      "source": [
        "## 측정공식(Evaluation Metric) vs 비용함수(Cost Function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmc87ejUi4fW",
        "colab_type": "text"
      },
      "source": [
        "* F1 score, precision, recall, accuracy, ROC, AUC\n",
        "  - https://frhyme.github.io/machine-learning/clf_%ED%8F%89%EA%B0%80%ED%95%98%EA%B8%B0/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvr1fw2HcERG",
        "colab_type": "text"
      },
      "source": [
        "### 1) 분류 모델\n",
        "<img src=\"https://t1.daumcdn.net/cfile/tistory/99DC064C5BE056CE10\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
        "\n",
        "모델(분류기)의 성능을 평가하는 더 좋은 방법은 Coufusion Matrix(오차행렬)을 만들어보는 것입니다. 정답이 True/False로 나누어져 있고, 모델 또한 True/False의 답을 내놓습니다. 그렇다면 위와 같이 2x2의 행렬이 만들어지겠죠? 각 case별로 살펴본다면 다음과 같습니다.<br>\n",
        "- True Positive(TP) : 실제 True인 정답을 True라고 예측 (정답)\n",
        "- False Positive(FP) : 실제 False인 정답을 True라고 예측 (오답)\n",
        "- False Negative(FN) : 실제 True인 정답을 False라고 예측 (오답)\n",
        "- True Negative(TN) : 실제 False인 정답을 False라고 예측 (정답)<br>\n",
        "\n",
        "그렇다면 confusion matrix를 통해 우리의 분류 모델 성능을 어떻게 평가할 수 있을까요? 손으로 쓴 숫자가 '3'인지 아닌지 분류하는 아주 간단한 모델을 만든다고 가정하고, 이 모델의 성능을 여러 지표로 확인해보겠습니다.\n",
        "<img src=\"mnist3.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9VKlwWMcEYm",
        "colab_type": "text"
      },
      "source": [
        "### 정확도(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQQs_U4McqGk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "정확도(accuracy)는 전체 샘플 중 맞게 예측한 샘플 수의 비율을 뜻합니다. 높을수록 좋은 모형입니다. 일반적으로 학습에서 최적화 목적함수로 사용됩니다.\n",
        "\n",
        "$$accuracy=\\frac{TP+TN}{TP+TN+FP+FN}$$<br>\n",
        "그러나, 정확도(Accuracy)의 가장 큰 문제점은, **클래스의 분포가 같을 때만 이용 가능하다는 점입니다**. 정답이 3일 때의 정확도는 5/7= 71.4%이지만, 정답이 3이 아닐 때의 정확도는 2/3 = 66.7%입니다. 전체 정확도를 70%라고 말한다면, 3이 아닐 때의 정확도가 미미하게 반영된다는 문제점이 있습니다.<br>\n",
        "이러한 **단점을 보완**하는 지표가 정밀도(Precision)와 재현율(Recall), ROC 곡선과 AUC입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD53j2CIc_yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_true = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "y_pred = [0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
        "\n",
        "accuracy_score(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gly25qHYcxOS",
        "colab_type": "text"
      },
      "source": [
        "### 정밀도(precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW5yhOcoczME",
        "colab_type": "text"
      },
      "source": [
        "정밀도(precision)은 positive 클래스에 속한다고 분류한 샘플 중 실제로 positive 클래스에 속하는 샘플 수의 비율을 말한다. 높을수록 좋은 모형입니다.\n",
        "\n",
        "$$precision=\\frac{TP}{TP+FP}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2GB7Zw0c257",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "y_true = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "y_pred = [0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
        "\n",
        "precision_score(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz7wL3hqcEf9",
        "colab_type": "text"
      },
      "source": [
        "### 재현율(recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyWF_fVJc5Cx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "재현율(recall)은 실제 positive 클래스에 속한 표본 중에 positive 클래스에 속한다고 출력한 표본의 수의 비율을 뜻합니다. 높을수록 좋은 모형이다. TPR(true positive rate) 또는 민감도(sensitivity)라고도 합니다.\n",
        "\n",
        "$$recall=\\frac{TP}{TP+FN}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7m54a6Wc93_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "y_true = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "y_pred = [0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
        "\n",
        "recall_score(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66RGY_whcEnC",
        "colab_type": "text"
      },
      "source": [
        "### F Score, F1 score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS3Ar-t3c5jy",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**정밀도**와 **재현율**의 **가중조화평균**을 F Score라고 합니다. 정밀도에 주어지는 가중치를 베타(beta)라고 합니다.\n",
        "\n",
        "$$F_β=\\frac{(1+β^2)(precision*recall)}{β^2precision+recall}$$\n",
        " \n",
        "베타가 1인 경우를 특별히 F1 Score라고 합니다.\n",
        "\n",
        "$$F_1=\\frac{2⋅precision⋅recall}{precision+recall}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtsgXeeBgPqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "y_true = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "y_pred = [0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
        "\n",
        "f1_score(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-EXkc1tgUF3",
        "colab_type": "text"
      },
      "source": [
        "sklearn 패키지의 metrics 패키지에서는 정밀도, 재현율, F1점수를 구하는 `classification_report` 명령을 제공합니다. 이 명령은 각각의 클래스를 양성(positive) 클래스로 보았을 때의 정밀도, 재현율, F1점수를 각각 구하고 그 평균값으로 전체 모형의 성능을 평가합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s31GeLcegVVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "y_pred = [0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=['class 0', 'class 1']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMhkEurtgcv7",
        "colab_type": "text"
      },
      "source": [
        "### ROC와 AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfI1FAStgc3r",
        "colab_type": "text"
      },
      "source": [
        "ROC 곡선에 대해 설명하기 위해 일단 다음의 두 가지 개념에 대해 먼저 알아보겠습니다.<br>\n",
        "위에서 설명한 재현율(Recall)은 참 양성 비율(True Positive Rate, **TPR**)이라고도 하며, 다음과 같이 정의됩니다. $$TPR=\\frac{TP}{TP+FN}$$<br>\n",
        "거짓 양성 비율(False Positive Rate, **FPR**)은 다음과 같이 정의됩니다.\n",
        "$$FPR=\\frac{FP}{FP+TN}$$<br>\n",
        "TPR과 FPR은 반비례 관계에 있습니다. 3인지 아닌지 판단할 때, 조금만 3처럼 보여도 모두 3이라고 분류할 경우, 이 때의 TPR은 1에 가까워질 것입니다. 그러나 반대로 FPR은 매우 낮아지겠죠? 반대로 조금만 비슷하지 않아도 모두 3이 아니라고 분류할 경우 TPR은 급격히 낮아져 0에 가까워지겠지만, FPR은 반대로 급격히 높아져 1에 가까워질 것입니다(3이라고 분류 자체를 안하므로, 잘못 분류하는 경우가 없는 것). 이처럼 TPR과 FPR은 어떤 기준(언제 3이라고 예측할까?)을 연속적으로 바꾸며 측정해야 합니다. 이를 한눈에 볼 수 있게 한 것이 바로 **ROC 곡선**입니다. \n",
        "![ROC_curve](https://t1.daumcdn.net/cfile/tistory/262E8E3F544837AD27)<br>\n",
        "위 그림처럼, ROC 곡선은 TPR과 FPR이 둘다 [0,1]의 범위이며, (0,0)에서 (1,1)을 잇는 곡선입니다. 이때 **ROC 곡선 아래 부분의 면적**을 **AUC(Area Under Curve)**라 하며 이 값이 1에 가까울수록 성능이 좋습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ITUByOJg53O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "y_true = np.array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])\n",
        "y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
        "roc_auc_score(y_true, y_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUlvdypug9xh",
        "colab_type": "text"
      },
      "source": [
        "#### 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEUPu6oFg-xp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, precision_recall_curve\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def learn_and_eval_clf(x, y_true):\n",
        "    clf = LogisticRegression(random_state=42)\n",
        "    clf.fit(x, y_true)\n",
        "\n",
        "    y_pred = clf.predict(x)\n",
        "    print(\"accuracy_score: {}\".format( accuracy_score(y_true, y_pred)))\n",
        "    print(\"precision_score: {}\".format( precision_score(y_true, y_pred)))\n",
        "    #print(\"AUC: Area Under Curve: {}\".format(roc_auc_score(y_true, y_pred_proba[:, 1])))\n",
        "    #print(\"Classificcation Report: \\n{}\".format(classification_report(y_true, y_pred)))\n",
        "    #print(\"Confusition matrix: \\n{}\".format(confusion_matrix(y_true, y_pred)))\n",
        "\n",
        "    y_score = clf.decision_function(x)\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
        "\n",
        "    f, axes = plt.subplots(1, 2, sharex=True, sharey=True)\n",
        "    f.set_size_inches((8, 4)) \n",
        "    axes[0].fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
        "    axes[0].set_title('Recall-Precision Curve')\n",
        "\n",
        "    axes[1].plot(fpr, tpr)\n",
        "    axes[1].plot([0, 1], [0, 1], linestyle='--')\n",
        "    axes[1].set_title('ROC curve')\n",
        "    #plt.save\n",
        "    return f\n",
        "\n",
        "## - 임의로 각각 평균이 0.0, 0.25인, 큰 차이가 나지 않는 샘플들을 뽑아서, 분류해본다. \n",
        "\n",
        "sample_size = 100\n",
        "x = np.vstack(\n",
        "    [np.random.normal(0, 1, sample_size*2).reshape(sample_size, 2), \n",
        "     np.random.normal(0.25, 1, sample_size*2).reshape(sample_size, 2), \n",
        "    ]\n",
        ")\n",
        "y_true = np.array([0 for i in range(0, sample_size)]+[1 for i in range(0, sample_size)])\n",
        "\n",
        "\n",
        "try1 = learn_and_eval_clf(x, y_true)\n",
        "\n",
        "### 임의로 각각 평균이 0.0, 2인, 큰 차이가 나지 않는 샘플들을 뽑아서, 분류해본다. \n",
        "\n",
        "sample_size = 100\n",
        "x = np.vstack(\n",
        "    [np.random.normal(0, 1, sample_size*2).reshape(sample_size, 2), \n",
        "     np.random.normal(2, 1, sample_size*2).reshape(sample_size, 2), \n",
        "    ]\n",
        ")\n",
        "y_true = np.array([0 for i in range(0, sample_size)]+[1 for i in range(0, sample_size)])\n",
        "try2 = learn_and_eval_clf(x, y_true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnUFIOZ7hp2U",
        "colab_type": "text"
      },
      "source": [
        "### 2) 회귀 모델\n",
        "이번에는 회귀 모델의 성능을 평가하는 방법에 대해 알아보겠습니다. 수치(float)값을 예측하는 모델은 Accuracy 등의 분류 모델 평가 기준으로 평가하는 것이 애매합니다. 분류 모델은 맞게 분류했는지/아닌지만 평가하면 되지만, 회귀모델은 정확하게 예측하지 못했더라도, 정답과 비슷하게 맞추면 성능이 좋다고 평가해야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_2XBHl6hrGL",
        "colab_type": "text"
      },
      "source": [
        "#### MAE(Mean Absolute Error)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KnuR971hrO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "mean_absolute_error(y_test, y_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV1s_1O6hrWI",
        "colab_type": "text"
      },
      "source": [
        "#### MSE(Mean Squared Error)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VgbB30Ghrdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mean_squared_error(y_test, y_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAdUWyWBiN_g",
        "colab_type": "text"
      },
      "source": [
        "#### MAPE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYC0mqMKicx3",
        "colab_type": "text"
      },
      "source": [
        "Scale Dependent Error의 단점을 보완하기 위한 방법입니다. 하지만 MAPE 역시 실제 예측 값이 1보다 작을 경우 분모가 작아져 무한대에 가까워질 수 있다는 단점이 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y65FCLQifw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import check_arrays\n",
        "def mean_absolute_percentage_error(y_true, y_pred): \n",
        "    y_true, y_pred = check_arrays(y_true, y_pred)\n",
        "\n",
        "    #if _is_1d(y_true): \n",
        "    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\n",
        "\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA2eofXEHNw0",
        "colab_type": "text"
      },
      "source": [
        "# 0. Machine learning: Dimensinality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL9YEt4yJ8Xv",
        "colab_type": "text"
      },
      "source": [
        "## 차원축소(Dimensinality Reduction)이란....?\n",
        "\n",
        "- 차원의 저주를 해결하기 위해 feature를 줄여주는 과정.\n",
        "- Feature를 줄이면 속도는 빨라지지만, 정보가 줄어들기 때문에 약간의 성능 저하가 있을 수 있어서 차원 축소를 하기 전에 먼저 Original data를 training 시켜보는 것이 좋다. 사람들은 2차원 까지만 생각할 수 있기 때문에 데이터 시각화에도 유용하다. 차원 축소는 대표적으로 PCA와 LLE가 있다.\n",
        "- 모델을 학습시키기 전에 학습 데이터셋의 차원을 감소시키면 학습 속도는 빨라지지만 모델의 성능은 항상 더 낫거나 간단한 모델이 되는 것은 아니다. 이것은 데이터셋이 어떠한 모양을 하고 있느냐에 따라 달라진다.\n",
        "\n",
        "## Curse of Dimensionality<br>\n",
        "- 차원이 커지면 커질수록 데이터 간의 거리가 멀어진다. 그래서 그래프 상으로 보게 되면 엄청 떨어져 있는 모습을 볼 수 있다. 이 상태로 모델을 돌리면 overfitting 될 가능성이 크다. 첫번째 방법은 feature만큼 row를 늘려줘서 density를 올려주는 방법이 있는데, 이는 row가 너무 많아질 가능성이 있기 때문에 좋은 방법은 아니다. 그래서 가장 많이 사용하는 방법은 Projection과 Manifold 방식이다. \n",
        "\n",
        "![123123](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile1.uf.tistory.com%2Fimage%2F99FF9F335B8A484A31820B)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WgSVgQdKFp8",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## PCA란?\n",
        "- PCA(Principal Component Analysis)는 주성분 분석이라고도 하며 고차원 데이터 집합이 주어졌을 때 원래의 고차원 데이터와 가장 비슷하면서 더 낮은 차원 데이터를 찾아내는 방법\n",
        "- 차원축소 방법이다. 최적의 초평면을 찾고, 그 다음에 data를 그 초평면에 projection 시켜주는 방식이다. \n",
        "\n",
        "\n",
        "### 분산보존\n",
        "\n",
        "최적의 lower-dimension hyperplane을 찾는 기준 중 하나는 분산보존이다. \n",
        "PCA는 데이터의 분산이 최대가 되는 축을 찾는다. 즉, 원본 데이터셋과 투영된 데이터셋 간의 평균제곱거리를 최소화 하는 축을 찾는다. C1을 축으로 한 데이터의 분산이 가장 잘 보존되어 있는걸 볼 수 있다.\n",
        "![123123](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile28.uf.tistory.com%2Fimage%2F99AC093E5B8A4904213CC3)\n",
        "\n",
        "\n",
        "## PCA 단계\n",
        "PCA는 다음과 같은 단계로 이루어진다. \n",
        "1. 학습 데이터셋에서 분산이 최대인 축(axis)을 찾는다. \n",
        "2. 이렇게 찾은 첫번째 축과 직교(orthogonal)하면서 분산이 최대인 두 번째 축을 찾는다.\n",
        "3. 첫 번째 축과 두 번째 축에 직교하고 분산을 최대한 보존하는 세 번째 축을 찾는다.\n",
        "4. 1~3과 같은 방법으로 데이터셋의 차원(특성 수)만큼의 축을 찾는다.\n",
        "PC의 방향은 항상 일정하지 않다. training set을 살짝 조정해서 PCA를 실행시키면, 새로운 PC가 원래의 PC랑 반대에 있을 가능성이 있다. 그러나 축이나 평면은 같다.\n",
        "![123123](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile6.uf.tistory.com%2Fimage%2F996F65335B8A493207D19B)\n",
        "\n",
        "\n",
        "- PC를 찾을 때 Singular Value Decomposition(SVD)를 사용해서 원래의 training set matrix를 3개의 matrices로 분해시켜준다.\n",
        "<br>\n",
        "PCA는 dataset이 origin 주변으로 center 되어있다고 가정한다. scikit-learn's에서는 이 부분을 자동으로 만들어주지만, 아닐 경우 이 부분에 대해서 잊어서는 안된다.\n",
        "\n",
        "## PCA for compression\n",
        "- PCA를 통해 없어진 변수는 다시 살릴 수 있다. 그러나 원래 데이터와 완전 똑같이 복원할 순 없다. Original과 Recover 된 데이터 사이의 mean square distance를 reconstruction error라고 부른다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgkDwpS3NSIX",
        "colab_type": "text"
      },
      "source": [
        "## PCA 종류\n",
        "### Randomized PCA\n",
        "- svd_solver라는 hyperparmeter를 'randomzied'로 설정하면, scikit_learn에서는 stochastic algorithm을 사용하는데 이를 Randomzied PCA라고 부른다. 이걸 사용하면 처음 d개의 주성분을 대략적으로 찾을 수 있다. d가 n개보다 훨씬 적게 되면 매우 빠른 성능을 볼 수 있다. 이 함수에 'auto'로 설정하면 n 값이 500개 이상이고 d 값이 n 값의 80%보다 적으면 자동으로 randomized로 진행되고, 그 외에는 full svd가 진행된다. \n",
        "\n",
        "### Incremental PCA (IPCA)\n",
        "- PCA를 실행시킬때 가장 큰 문제는 알고리즘을 돌리기 위해서 모든 training set을 memory에 fit 시켜줘야한다는 것이다. 이 문제는 IPCA로 해결 가능하다. IPCA는 학습 데이터셋을 미니배치로 나눈 뒤 IPCA 알고리즘에 하나의 미니배치를 입력으로 넣어준다. IPCA는 학습 데이터셋이 클때 유용하다.\n",
        "\n",
        "### Kernel PCA (KPCA)\n",
        "- SVM에서 데이터를 저차원에서 선형 고차원으로 매핑시켜 비선형 데이터셋에 SVM을 적용시키는 방식이 있다. 우리는 이것을 활용해서 비선형 투영을 사용해서 차원 축소를 할 수 있는데, 이를 KPCA라고 부른다. 이 방식은 projection 후 데이터들의 cluster를 유지시키는데 좋고, unrolling dataset에도 사용 가능하다. (twisted manifold와 매우 비슷하다) \n",
        "<br>\n",
        "- KPCA는 일종의 unsupervised learning이기 때문에, 어떤 hyperparameter와 어떤 kernel이 best인지 명확하게 알 수 없다. 그러나 차원 축소는 지도 학습의 준비단계라고 할 수 있다. gridsearch로 어떤 hyperparmeter가 최적인지 찾을 수 있다. KernelPCA에서도 inverse로 원래 데이터 형태로 돌릴 수 있다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf88nypWNXlO",
        "colab_type": "text"
      },
      "source": [
        "## 빈용 메소드 모음\n",
        "- **PCA ( n_components = 정수 )** : 기본 사용방법\n",
        "- **.fit_transform()**: 특정행렬을 낮은 차원의 근사행렬로 변환\n",
        "- **.inverse_transform()**: 변환된 근사행렬을 원래의 차원으로 복귀\n",
        "- **.mean_**: 데이터의 평균값을 반환\n",
        "- **.components_**: 단위기저벡터를 반환\n",
        "- **.explained_variance_ratio**: 각 주성분 축에 몇 %의 분산이 보존되어있는지 보여줌\n",
        "- **.inverse_transform()**: 압축했던 data를 다시 예전 차원으로 복원"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA82l8tuPgKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 분산으로도 적절한 차원의 수를 구할 수 있음\n",
        "from tensorflow.keras.datasets import mnist\n",
        "​\n",
        "# MNIST load\n",
        "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
        "​\n",
        "# reshape\n",
        "train_x = train_x.reshape(-1, 28*28) \n",
        "​\n",
        "pca = PCA(n_components=0.95)\n",
        "X_reduced = pca.fit_transform(train_x)  # PCA 계산 후 투영\n",
        "\n",
        "print('선택한 차원(픽셀) 수 :', pca.n_components_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEZj7mkea8mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=0.95)\n",
        "X_reduced = pca.fit_transform(train_x)\n",
        "print('선택한 차원(픽셀) 수 :', pca.n_components_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cOrz_QvLamL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Scikit learn으로 간단하게 구하기\n",
        "# 적절한 차원의 개수 구하기\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=3)\n",
        "pca.fit(X)\n",
        "\n",
        "print('singular value :', pca.singular_values_)\n",
        "print('singular vector :\\n', pca.components_.T)\n",
        "\n",
        "print('eigen_value :', pca.explained_variance_)\n",
        "print('explained variance ratio :', pca.explained_variance_ratio_)\n",
        "\n",
        "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
        "d = np.argmax(cumsum >= 0.95) + 1\n",
        "print('선택할 차원 수 :', d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ3CDVeMLlv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 다양한 차원축소법들 예제\n",
        "# KPCA 예제\n",
        "from sklearn.datasets import make_swiss_roll\n",
        "X, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42) \n",
        "\n",
        "# KernelPCA 예제\n",
        "from sklearn.decomposition import KernelPCA\n",
        "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.04)\n",
        "X_reduced = rbf_pca.fit_transform(X)\n",
        "\n",
        "# MDS 예제\n",
        "from sklearn.manifold import MDS\n",
        "mds = MDS(n_components=2, random_state=42)\n",
        "X_reduced_mds = mds.fit_transform(X)\n",
        "\n",
        "# Isomap 예제\n",
        "from sklearn.manifold import Isomap\n",
        "isomap = Isomap(n_components=2)\n",
        "X_reduced_isomap = isomap.fit_transform(X)\n",
        "\n",
        "# TSNE 예제\n",
        "from sklearn.manifold import TSNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "X_reduced_tsne = tsne.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1bGuT7XK9Jt",
        "colab_type": "text"
      },
      "source": [
        "# 0. Machine learning: Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVCisNbZ9AmF",
        "colab_type": "text"
      },
      "source": [
        "## Oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpJoLEAM88ul",
        "colab_type": "text"
      },
      "source": [
        "\n",
        " - RandomOverSampler: 소수 클래스의 데이터를 반복해서 넣는 방법\n",
        "```\n",
        "X_samp, y_samp = RandomOverSampler(random_state=0).fit_sample(X_imb, y_imb)\n",
        "```\n",
        " - ADASYN: 소수 클래스 데이터와 그 데이터에서 가장 가까운 k개의 소수 클래스 데이터 중 무작위로 선택된 데이터 사이의 직선상에 가상의 소수 클래스 데이터를 만드는 방법\n",
        "```\n",
        "X_samp, y_samp = ADASYN(random_state=0).fit_sample(X_imb, y_imb)\n",
        "```\n",
        " - SMOTE: ADASYN 방법처럼 데이터를 생성하지만 생성된 데이터를 무조건 소수 클래스라고 하지 않고 분류 모형에 따라 분류한다.\n",
        "```\n",
        "X_samp, y_samp = SMOTE(random_state=4).fit_sample(X_imb, y_imb)\n",
        "```\n",
        " - SMOTENC: SMOTE와 유사하나 categorical 변수도 sampling 시킬 수 있는 방법\n",
        "```\n",
        "X_res, y_res = SMOTENC(random_state=42, categorical_features=[18, 19]).fit_resample(X, y)\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOzO9VKj9E-G",
        "colab_type": "text"
      },
      "source": [
        "## Undersampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_korOR59Jgp",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        " - **RandomUnderSampler**: 무작위로 데이터를 없애는 단순 샘플링\n",
        "```\n",
        "  X_samp, y_samp = RandomUnderSampler(random_state=0).fit_sample(X_imb, y_imb)\n",
        "```\n",
        " - **TomekLinks**: 토멕링크(클래스가 다른 두 데이터 중 아주 가까이 붙어있는 데이터)를 찾아서 그 중 다수 클래스에 속한 데이터를 제외하는 방법\n",
        "```\n",
        "X_samp, y_samp = TomekLinks(random_state=0).fit_sample(X_imb, y_imb)\n",
        "```\n",
        " - **CondensedNearestNeighbour**: 1-NN 모형으로 분류되지 않는 데이터만 남기는 방법\n",
        "```\n",
        "X_samp, y_samp = CondensedNearestNeighbour(random_state=0).fit_sample(X_imb, y_imb)\n",
        "```\n",
        " - **OneSidedSelection**: 토맥링크 중 다수 클래스를 제외하고 나머지 데이터 중에서도 서로 붙어있는 다수 클래스 데이터는 1-NN 방법으로 제외한다.\n",
        "```\n",
        "X_samp, y_samp = OneSidedSelection(random_state=0).fit_sample(X_imb, y_imb)\n",
        "```\n",
        " - **EditedNearestNeighbours**: 다수 클래스 데이터 중 가장 가까운 k(n_neighbors)개의 데이터가 모두(kind_sel=\"all\") 또는 다수(kind_sel=\"mode\") 다수 클래스가 아니면 삭제하는 방법이다. 소수 클래스 주변의 다수 클래스 데이터는 사라진다.\n",
        "```\n",
        "X_samp, y_samp = EditedNearestNeighbours(kind_sel=\"all\", n_neighbors=5, random_state=0).fit_sample(X_imb, y_imb)\n",
        "```\n",
        " - **NeighbourhoodCleaningRule**: CNN(Condensed Nearest Neighbour) 방법과 ENN(Edited Nearest Neighbours) 방법을 섞은 것이다.\n",
        "```\n",
        "X_samp, y_samp = NeighbourhoodCleaningRule(kind_sel=\"all\", n_neighbors=5, random_state=0).fit_sample(X_imb, y_imb)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1GrLsHa9M5_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## 복합샘플링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5CLVsXtLD_x",
        "colab_type": "text"
      },
      "source": [
        "\n",
        " - SMOTEENN: SMOTE + ENN\n",
        "```\n",
        "X_samp, y_samp = SMOTEENN(random_state=0).fit_sample(X_imb, y_imb)\n",
        "```\n",
        " - SMOTETomek: SMOTE + Tomek\n",
        "```\n",
        "X_samp, y_samp = SMOTETomek(random_state=4).fit_sample(X_imb, y_imb)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06RGTAhROP-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.under_sampling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAWsESfTLI7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sampling 코드 모음\n",
        "X_samp, y_samp = RandomOverSampler(random_state=0).fit_sample(X_imb, y_imb)\n",
        "X_samp, y_samp = ADASYN(random_state=0).fit_sample(X_imb, y_imb)\n",
        "X_samp, y_samp = SMOTE(random_state=4).fit_sample(X_imb, y_imb)\n",
        "X_samp, y_samp = SMOTENC(random_state=42, categorical_features=[18, 19]).fit_resample(X_imb, y_imb)\n",
        "X_samp, y_samp = RandomUnderSampler(random_state=0).fit_sample(X_imb, y_imb)\n",
        "X_samp, y_samp = TomekLinks(random_state=0).fit_sample(X_imb, y_imb)\n",
        "X_samp, y_samp = CondensedNearestNeighbour(random_state=0).fit_sample(X_imb, y_imb)\n",
        "X_samp, y_samp = OneSidedSelection(random_state=0).fit_sample(X_imb, y_imb)\n",
        "X_samp, y_samp = EditedNearestNeighbours(kind_sel=\"all\", n_neighbors=5, random_state=0).fit_sample(X_imb, y_imb)\n",
        "X_samp, y_samp = NeighbourhoodCleaningRule(kind_sel=\"all\", n_neighbors=5, random_state=0).fit_sample(X_imb, y_imb)\n",
        "X_samp, y_samp = SMOTEENN(random_state=0).fit_sample(X_imb, y_imb)\n",
        "X_samp, y_samp = SMOTETomek(random_state=4).fit_sample(X_imb, y_imb)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVZGnPXmn0Gs",
        "colab_type": "text"
      },
      "source": [
        "# 0. Machine learning: Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "592LBZFKoWHT",
        "colab_type": "text"
      },
      "source": [
        "## Scaling이란.....\n",
        "- scaling을 통해서 다차원의 값들을 분석하기 쉽게 만들어주고 자료의 overflow, underflow를 방지할 수 있다! \n",
        "- 또한 최적화 과정에서의 안정성 및 수렴속도를 향상!\n",
        "- k-means 등 거리 기반의 모델에서는 scaling이 매우 중요하다\n",
        "\n",
        "## 종류\n",
        "- StandardScaler: 기본 스케일, 평균과 표준편차 사용\n",
        "- MinMaxScaler: 최대/최소값이 각각 1, 0이 되도록 하는 scaling\n",
        "- MaxAbsScaler: 최대절대값과 0이 각각 1, 0이 되도록 하는 scaling\n",
        "- RobustScaler: median과 IQR(interquartile range) 사용, outlier의 영향을 최소화한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV6cV1ajpAlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# StandardScaler\n",
        "## 예제1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "standardScaler = StandardScaler()\n",
        "print(standardScaler.fit(train_data))\n",
        "train_data_standardScaled = standardScaler.transform(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px21jdvPn_IN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MinMaxscaler\n",
        "## 예제1\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minMaxScaler = MinMaxScaler()\n",
        "print(minMaxScaler.fit(train_data))\n",
        "train_data_minMaxScaled = minMaxScaler.transform(train_data)\n",
        "\n",
        "## 예시2\n",
        "minmax = MinMaxScaler()\n",
        "train_X_mm = minmax.fit_transform(train_X_nu)\n",
        "train_X_mm_df = pd.DataFrame(train_X_mm, columns=train_X_nu.columns, index=train_X_nu.index)\n",
        "train_X_fin = pd.concat([train_X_mm_df, train_X_ca], axis=1)\n",
        "train_X_fin.index = range(len(train_X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hhjuCLapAfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MaxAbsScaler\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "maxAbsScaler = MaxAbsScaler()\n",
        "print(maxAbsScaler.fit(train_data))\n",
        "train_data_maxAbsScaled = maxAbsScaler.transform(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_nMPGOvpAYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RobustScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "robustScaler = RobustScaler()\n",
        "print(robustScaler.fit(train_data))\n",
        "train_data_robustScaled = robustScaler.transform(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXCo6vcWv-EG",
        "colab_type": "text"
      },
      "source": [
        "# 0. Machine learning: Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwMzfX66ndvT",
        "colab_type": "text"
      },
      "source": [
        "## Classifier란....??\n",
        "- 지도학습의 일환으로 주어진 군집을 학습한 다음 새로운 값이 주어졌을 때 어느 군집에 속할지 분류해주는 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGj5kBjswPll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SGD Classifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf=SGDClassifier(random_state=42) #SGDClassifier는 randomness에 기반하기 때문에, \n",
        "#고정 값을 정하고 싶다면, random_state parameter를 쓰자.\n",
        "sgd_clf.fit(X_train,y_train)\n",
        "\n",
        "sgd_clf.predict(X_test)\n",
        "\n",
        "y_pred = sgd_clf.predict(X_test)\n",
        "\n",
        "f1_score(y_test,y_pred, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qrvTGZIP2z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier, plot_importance\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "model.predict(X_test)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(y_test,y_pred, average='weighted')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_niQacgbZPlF",
        "colab_type": "text"
      },
      "source": [
        "# 0. Machine learning: Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S29RxeZbZSXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 만들어주기\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "model = DecisionTreeRegressor(random_state=1, max_depth=50)\n",
        "model\n",
        "\n",
        "# fitting 시키기\n",
        "model.fit(x_train,y_train_re)\n",
        "model.fit(x_train,y_train_ca)\n",
        "model.fit(x_train,y_train)\n",
        "\n",
        "# predict하기\n",
        "model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6CvgUU5kkvX",
        "colab_type": "text"
      },
      "source": [
        "# 0. Machine learning: Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq0VBFmVqPvC",
        "colab_type": "text"
      },
      "source": [
        "## Boosting이란 무엇인고....??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_5jNWflpykR",
        "colab_type": "text"
      },
      "source": [
        "![123123](https://user-images.githubusercontent.com/31475037/59011343-5a586280-886f-11e9-86ab-3143ad265195.png)\n",
        "\n",
        "\n",
        "![123123](https://quantdare.com/wp-content/uploads/2016/04/bb3.png)\n",
        "\n",
        "Boosting은 앙상블 모델이지만 Bagging과 다르게 이전 모델의 오차를 고려하여 학습을 하는 모델이다!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqHl6bOcqUiz",
        "colab_type": "text"
      },
      "source": [
        "![123123](https://image.slidesharecdn.com/mlstudyboostingv0-171128021615/95/boosting-bagging-vs-boosting-14-638.jpg?cb=1511939004)\n",
        "\n",
        "크게 Adaboost, GBM, Xgboost, Light GBM등이 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcGAU2xjofiD",
        "colab_type": "text"
      },
      "source": [
        "## 0) Xgboost, Lightgbm 등의 각종 parameter <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9goNFLrz8WS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "http://machinelearningkorea.com/2019/09/29/lightgbm-%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0/<br>\n",
        "간단하게 설명하면 <br>\n",
        "- max_depth[default=6]: 트리의 최대 깊이를 정의하는 parameter(DT에서 배웠음)\n",
        "- min_child_weight[default=1]: Overfitting을 컨트롤하는 파라미터로, 값이 높아지면, underfitting되는 경우가 있어 CV를 통해 튜닝되어야 함.\n",
        "- gamma[default=0]: 노드가 split되게 위한 loss function의 값이 감소하는 최소 값을 정의함. 값이 높아질수록 알고리즘은 보수적으로 변하고, loss function의 정의에 따라 적정값이 달라져 **반드시 튜닝되어야 한다**\n",
        "- subsample: 각 트리마다의 관측 데이터 샘플링 비율. 값을 적게 주면 over-fitting을 방지하지만 값을 너무 작게 주면 under-fitting(일반적으로 0.5~1).\n",
        "- colsample_bytree: 각 트리마다의 feature 샘플링 비율.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTHJmsUvHu_V",
        "colab_type": "text"
      },
      "source": [
        "## 1) Xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf7tAZ9DKhFt",
        "colab_type": "text"
      },
      "source": [
        "### Xgboost란?\n",
        "\n",
        "- Null값 있어도 상관없는 모델!\n",
        "- categorical variables는 모두 one-hot encoding을 통해서 바꿔줘야 함!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TFMrcGgxcGV",
        "colab_type": "text"
      },
      "source": [
        "### Xgboost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTxIja-fxdnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier, plot_importance\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "model.predict(X_test)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(y_test,y_pred, average='weighted')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvfXnJFjodiy",
        "colab_type": "text"
      },
      "source": [
        "### Plot_importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqaEHFdhoil8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 코드1\n",
        "from xgboost import plot_importance\n",
        "\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(X, y)\n",
        "sorted_idx = np.argsort(model.feature_importances_)[::-1]\n",
        "for index in sorted_idx:\n",
        "    print([X.columns[index], model.feature_importances_[index]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45Rpf8ZHovMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 코드2\n",
        "from xgboost import XGBClassifier, plot_importance\n",
        "model = XGBClassifier()\n",
        "model.fit(train, label)\n",
        "\n",
        "sorted_idx = np.argsort(model.feature_importances_)[::-1]\n",
        "\n",
        "for index in sorted_idx:\n",
        "    print([train.columns[index], model.feature_importances_[index]]) \n",
        "\n",
        "    plot_importance(model, max_num_features = 15)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv3aapPouXm4",
        "colab_type": "text"
      },
      "source": [
        "## 2) Catboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBqhuEbnugFM",
        "colab_type": "text"
      },
      "source": [
        "### Catboost는 뭐꼬?\n",
        "- Catboost는 Category와 Boosting을 합쳐서 만들어진 이름이다. \n",
        "- 여기에서 Boost는 Gradient boosting machine learnin algorithm에서 온 말인데 Gradient boosting은 추천 시스템, 예측 등 다양한 분야에서 활용되어지는 강력한 방법.\n",
        "- Deep Learning과 달리 적은 데이터로도 좋은 결과를 얻을 수 있는 효율적인 방법이다.\n",
        "- Catboost에서는 categorical 변수를 사용자가 다른 작업을 하지 않아도 자동으로 이를 변환하여 사용한다. model fitting할 때 지정해야됨!!!\n",
        "- default parameters값으로 더 나은 성능\n",
        "- hyper-parmeter tuning을 하지 않더라도 기본적인 세팅으로도 좋은 결과를 얻을 수 있어 활용성이 뛰어나다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n59AeEWKyTXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from catboost import CatBoostRegressor\n",
        "train_data = pd.read_csv('train_data.csv', encdoing='euc-kr')\n",
        "test_data = pd.read_csv('test_data.csv', encdoing='euc-kr')\n",
        "cat_features = [0,1,2]\n",
        "train_labels = [10,20,30]\n",
        "\n",
        "model = CatBoostRegressor(iterations=2, learning_rate=1, depth=2)\n",
        "\n",
        "model.fit(train_data, train_labels, cat_features) # cat_features를 꼭 지정해줘야한다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thpnVBUDFUvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import catboost as cb\n",
        "cat_features_index = [0,1,2,3,4,5,6]\n",
        "\n",
        "def auc(m, train, test): \n",
        "    return (metrics.roc_auc_score(y_train,m.predict_proba(train)[:,1]),\n",
        "                            metrics.roc_auc_score(y_test,m.predict_proba(test)[:,1]))\n",
        "\n",
        "params = {'depth': [4, 7, 10],\n",
        "          'learning_rate' : [0.03, 0.1, 0.15],\n",
        "         'l2_leaf_reg': [1,4,9],\n",
        "         'iterations': [300]}\n",
        "cb = cb.CatBoostClassifier()\n",
        "cb_model = GridSearchCV(cb, params, scoring=\"roc_auc\", cv = 3)\n",
        "cb_model.fit(train, y_train)\n",
        "\n",
        "# With Categorical features\n",
        "clf = cb.CatBoostClassifier(eval_metric=\"AUC\", depth=10, iterations= 500, l2_leaf_reg= 9, learning_rate= 0.15)\n",
        "clf.fit(train,y_train)\n",
        "auc(clf, train, test)\n",
        "\n",
        "# With Categorical features\n",
        "clf = cb.CatBoostClassifier(eval_metric=\"AUC\",one_hot_max_size=31, \\\n",
        "                            depth=10, iterations= 500, l2_leaf_reg= 9, learning_rate= 0.15)\n",
        "clf.fit(train,y_train, cat_features= cat_features_index)\n",
        "auc(clf, train, test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20lLx4cSucpO",
        "colab_type": "text"
      },
      "source": [
        "### best parameter 찾기<br>\n",
        "사실, Catboost 는 기본 파라미터가 기본적으로 최적화가 잘 되어있어서, 파라미터 튜닝에 크게 신경쓰지 않아도 된다고 한다. (반면 xgboost 나 light gbm 은 파라미터 튜닝에 매우 민감하다.) 사실 대부분 부스팅 모델들이 파라미터 튜닝하는 이유는, 트리의 다형성과 오버피팅 문제를 해결하기 위함인데, Catboost 는 이를 내부적인 알고리즘으로 해결하고 있으니, 굳이.. 파라미터 튜닝할 필요가 없는 것이다.\n",
        "굳이 한다면 learning_rate, random_strength, L2_regulariser 과 같은 파라미터 튜닝인데, 결과는 큰 차이가 없다고 한다.\n",
        "\n",
        "출처: https://dailyheumsi.tistory.com/136"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3BemIAEuZrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## best parameter 찾는 과정\n",
        "# 우선 부차적인 parameter 찾아주고\n",
        "cb = CatBoostClassifier(\n",
        " learning_rate =0.1,\n",
        " iterations=100 #n-estimator대신 iteration을 사용,\n",
        ")\n",
        "\n",
        "cb_params_1 = {\n",
        "    'depth' : [3,5,7],\n",
        "    'random_strength' : [1,3],\n",
        "    'bagging_temperature' : [0,0.5,1],\n",
        "    'l2_leaf_reg' : [1,3,5,7],\n",
        "}\n",
        "cb_grid_1 = GridSearchCV(cb, param_grid=cb_params_1, scoring=my_scorer, cv=5, verbose=1)\n",
        "cb_grid_1.fit(train[features], train['Survived'])\n",
        "\n",
        "print(\"Best Score : {}\".format(cb_grid_1.best_score_))\n",
        "print(\"Best Params : {}\".format(cb_grid_1.best_params_))\n",
        "best_cb_model = cb_grid_1.best_estimator_\n",
        "\n",
        "# 최적의 core parameter 찾기\n",
        "cb_params_2 = {\n",
        "    'learning_rate' : [0.03, 0.07, 0.1],\n",
        "    'iterations' : [n for n in range(80,130,20)]\n",
        "}\n",
        "cb_grid_2 = GridSearchCV(best_cb_model, param_grid=cb_params_2, scoring=my_scorer, cv=5, verbose=1)\n",
        "cb_grid_2.fit(train[features], train['Survived'])\n",
        "\n",
        "print(\"Best Score : {}\".format(cb_grid_2.best_score_))\n",
        "print(\"Best Params : {}\".format(cb_grid_2.best_params_))\n",
        "best_cb_model = cb_grid_2.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Ppo8GhRaCU",
        "colab_type": "text"
      },
      "source": [
        "## 3) Light GBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93Vr5rYd0CJb",
        "colab_type": "text"
      },
      "source": [
        "### Light GBM은 뭐꼬???\n",
        "- Tree based learning 알고리즘의 gradient boosting framework!\n",
        "- 작은 데이터셋 규모로 진행했을 때 overfitting될 가능성이 매우 높기 때문에 10,000 row 이상인 데이터셋에 적합하다.\n",
        "- Catboost와 마찬가지로 categorical "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNTmvYP-8Wue",
        "colab_type": "text"
      },
      "source": [
        "기본적인 lightgbm 사용방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVj1bHF3z_5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn import metrics\n",
        "\n",
        "def auc2(m, train, test): \n",
        "    return (metrics.roc_auc_score(y_train,m.predict(train)),\n",
        "                            metrics.roc_auc_score(y_test,m.predict(test)))\n",
        "\n",
        "lg = lgb.LGBMClassifier(silent=False)\n",
        "param_dist = {\"max_depth\": [25,50, 75],\n",
        "              \"learning_rate\" : [0.01,0.05,0.1],\n",
        "              \"num_leaves\": [300,900,1200],\n",
        "              \"n_estimators\": [200]\n",
        "             }\n",
        "grid_search = GridSearchCV(lg, n_jobs=-1, param_grid=param_dist, cv = 3, scoring=\"roc_auc\", verbose=5)\n",
        "grid_search.fit(train,y_train)\n",
        "grid_search.best_estimator_\n",
        "\n",
        "d_train = lgb.Dataset(train, label=y_train)\n",
        "params = {\"max_depth\": 50, \"learning_rate\" : 0.1, \"num_leaves\": 900,  \"n_estimators\": 300}\n",
        "\n",
        "# Without Categorical Features\n",
        "model2 = lgb.train(params, d_train)\n",
        "auc2(model2, train, test)\n",
        "\n",
        "#With Catgeorical Features\n",
        "cate_features_name = [\"MONTH\",\"DAY\",\"DAY_OF_WEEK\",\"AIRLINE\",\"DESTINATION_AIRPORT\",\n",
        "                 \"ORIGIN_AIRPORT\"]\n",
        "model2 = lgb.train(params, d_train, categorical_feature = cate_features_name)\n",
        "auc2(model2, train, test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwoyzKeP8KBZ",
        "colab_type": "text"
      },
      "source": [
        "### Card Fraud detection에서 썼던 코드 모음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu2H3HlgR75L",
        "colab_type": "text"
      },
      "source": [
        "#### 구글 드라이브 마운트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfb9w1C6R6xZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh5TdsC1R6f-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/gdrive/My \\Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj2muovPR6VT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 사용자에 맞게 바꾸기\n",
        "# cd Colab \\Notebooks/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiEMrXR5Rgzi",
        "colab_type": "text"
      },
      "source": [
        "#### Google Colab 사용 시 설치법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRJQGyryRg8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --recursive https://github.com/Microsoft/LightGBM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBY4HUgtRhJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd LightGBM/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f0KE_msRhQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir build"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDuYauo2RhfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cmake -DUSE_GPU=1 #avoid ..\n",
        "!make -j$(nproc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO3oQDyFRhkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get -y install python-pip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYVsU8rTRh0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo -H pip install setuptools pandas numpy scipy scikit-learn -U"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTwKo2aNRh7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd python-package/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQRRStvVRiJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo python setup.py install --precompile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mo9LJCKRieQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lgbm 설치시 pandas에서 오류가 나 재설정한 부분(선택적)\n",
        "!pip install pandas==0.18.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW4SD0goRir5",
        "colab_type": "text"
      },
      "source": [
        "#### LGBM 설치된 경로로 추가 설치과정 필요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2fkpSmdRhyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/gdrive/My \\Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PB-ByNGRhdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 사용자에 따른 선택적, 개별 드라이브 상황에 따라 경로 설정-> but LightGBM을 설치한 경로에 맞춰야 함\n",
        "cd 경로/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvQtPO35SLpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd LightGBM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y48rOD6gSJXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd python-package"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r0kleBVSJoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo python setup.py install --precompile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S6RpknSSJuJ",
        "colab_type": "text"
      },
      "source": [
        "분석을 위한 경로 재설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxfqggNfSJ9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3yPaJFUSKEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/gdrive/My \\Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAftnAzdSKTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 사용자에 따른 선택적, 개별 드라이브 상황에 따라 경로 설정-> but LightGBM을 설치한 경로에 맞춰야 함\n",
        "cd 경로"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TEB4Gp9SKaK",
        "colab_type": "text"
      },
      "source": [
        "#### 기본 패키지 및 설정, 데이터 적재"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-SZ3L1PSKp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbXLrqYpSKRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('final_train_merged.csv')    # 맞는 데이터 적재하기\n",
        "test = pd.read_csv('final_test_merged.csv')    # 맞는 데이터 적재하기"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYjRHWPPSJ7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test에 고객 아이디가 없어서 아이디 있는 파일 중 아무거나 가져옴. \n",
        "# test용 고객 아이디 있는 데이터면 수정해도 무방\n",
        "tt = pd.read_csv('pca_test_all_c_fraud.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ9HpvS6S2dc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del train['addr1_na']\n",
        "del test['addr1_na']\n",
        "\n",
        "del train['Unnamed: 0']\n",
        "del test['Unnamed: 0']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ytVuMLjS2kX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train.iloc[:, 1:].values\n",
        "y = train.iloc[:, 0].values\n",
        "\n",
        "X_test = test.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D__t8VKqS21H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X.shape, y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sS2cZErS25a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEItOgFcS3Iq",
        "colab_type": "text"
      },
      "source": [
        "#### LGBM 모델 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3YyeJbgS3QM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
        "from sklearn.metrics import (roc_curve, auc, accuracy_score)\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_AUfbAuS3cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\n",
        "    'task': 'train',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'binary',\n",
        "    'metric': {'binary_logloss', 'auc'},\n",
        "    'metric_freq': 1,\n",
        "    'is_training_metric': True,\n",
        "    'max_bin': 255,\n",
        "    'learning_rate': 0.01,\n",
        "    'num_leaves': 63,\n",
        "    'tree_learner': 'serial',\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'min_data_in_leaf': 50,\n",
        "    'min_sum_hessian_in_leaf': 5,\n",
        "    'is_enable_sparse': True,\n",
        "    'use_two_round_loading': False,\n",
        "    'is_save_binary_file': False,\n",
        "    'output_model': 'LightGBM_model.txt',\n",
        "    'num_machines': 1,\n",
        "    'local_listen_port': 12400,\n",
        "    'machine_list_file': 'mlist.txt',\n",
        "    'verbose': 0,\n",
        "    'subsample_for_bin': 200000,\n",
        "    'min_child_samples': 20,\n",
        "    'min_child_weight': 0.001,\n",
        "    'min_split_gain': 0.0,\n",
        "    'colsample_bytree': 1.0,\n",
        "    'reg_alpha': 0.0,\n",
        "    'reg_lambda': 0.0\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vFTCbAUS3gC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgb_train = lgb.Dataset(X_train, y_train)\n",
        "lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5aKP7QqS3Gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = lgb.train(params, lgb_train, 2500, lgb_eval, verbose_eval=10,  early_stopping_rounds=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta8d2_lbS2yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_valid_pred = model.predict(X_valid)\n",
        "roc_auc_score(y_valid, y_valid_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asTFo9xWSJmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19ivr7IpTOG9",
        "colab_type": "text"
      },
      "source": [
        "제출용 csv 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jNynH4iTOXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tt['isFraud'] = prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bu5b0JtTOdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tt2 = tt[['TransactionID', 'isFraud']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISxAP-siTOVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tt2.to_csv('lgbm_git_.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LkShFY26KE3e"
      },
      "source": [
        "# 0. Machine learning: GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-a_KzM2ZKE3Q"
      },
      "source": [
        "\n",
        "- **GridSearchCV ( estimator = , param_grid = , scoring = , cv = , n_jobs = , verbose = )** : grid search 하기\n",
        "- **.best_score_**: 최적의 score 점수를 보여줌\n",
        "- **.best_estimator_**: 최적의 parameter로 설정된 모델을 생성\n",
        "- **.best_params_**: 최적의 parameter를 반환\n",
        "- **.cv_results_**: 전체적인 결과값들을 보여줌"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B2F7YqwbKE2_",
        "colab": {}
      },
      "source": [
        "## Catboost best parameter 찾는 과정\n",
        "# 우선 부차적인 parameter 찾아주고\n",
        "cb = CatBoostClassifier(\n",
        " learning_rate =0.1,\n",
        " iterations=100 #n-estimator대신 iteration을 사용,\n",
        ")\n",
        "\n",
        "cb_params_1 = {\n",
        "    'depth' : [3,5,7],\n",
        "    'random_strength' : [1,3],\n",
        "    'bagging_temperature' : [0,0.5,1],\n",
        "    'l2_leaf_reg' : [1,3,5,7],\n",
        "}\n",
        "cb_grid_1 = GridSearchCV(cb, param_grid=cb_params_1, scoring=my_scorer, cv=5, verbose=1)\n",
        "cb_grid_1.fit(train[features], train['Survived'])\n",
        "\n",
        "print(\"Best Score : {}\".format(cb_grid_1.best_score_))\n",
        "print(\"Best Params : {}\".format(cb_grid_1.best_params_))\n",
        "best_cb_model = cb_grid_1.best_estimator_\n",
        "\n",
        "# 최적의 core parameter 찾기\n",
        "cb_params_2 = {\n",
        "    'learning_rate' : [0.03, 0.07, 0.1],\n",
        "    'iterations' : [n for n in range(80,130,20)]\n",
        "}\n",
        "cb_grid_2 = GridSearchCV(best_cb_model, param_grid=cb_params_2, scoring=my_scorer, cv=5, verbose=1)\n",
        "cb_grid_2.fit(train[features], train['Survived'])\n",
        "\n",
        "print(\"Best Score : {}\".format(cb_grid_2.best_score_))\n",
        "print(\"Best Params : {}\".format(cb_grid_2.best_params_))\n",
        "best_cb_model = cb_grid_2.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pTzslcTdKE20",
        "colab": {}
      },
      "source": [
        "### Xgboost best parameter 찾기\n",
        "## 처음에는 부차적인 parameter를 tuning하기\n",
        "# GridSearchCV에 들어갈 param_grid, estimator, scoring 만들어주기\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import auc, f1_score, accuracy_score\n",
        "my_scorer = make_scorer(accuracy_score, greater_is_better = True)\n",
        "\n",
        "xgb1 = XGBClassifier(\n",
        " learning_rate =0.1,\n",
        " n_estimators=100,\n",
        ")\n",
        "\n",
        "xgb_params_1 = {\n",
        "    'max_depth' : [3,5,7],\n",
        "    'min_child_weight' : [0.5, 1],\n",
        "    'gamma' : [0, 0.1],\n",
        "    'subsample' : [0.5, 0.7, 0.9],\n",
        "    'colsample_bytree' : [0.5, 0.7, 0.9],\n",
        "} #3x2x2x3x3=108가지 경우의 수\n",
        "\n",
        "# GridSearchCV 돌리기\n",
        "xgb_grid_1 = GridSearchCV(estimator=xgb1, param_grid=xgb_params_1, \n",
        "                          scoring=my_scorer, cv=5, n_jobs=1, verbose=1)\n",
        "xgb_grid_1.fit(train[features], train['Survived']) # Titanic data\n",
        "\n",
        "# 제일 좋은 모델 뽑기\n",
        "print(\"Best Score : {}\".format(xgb_grid_1.best_score_))\n",
        "print(\"Best Params : {}\".format(xgb_grid_1.best_params_))\n",
        "\n",
        "# 표로 한 번 뽑아보고\n",
        "results = pd.DataFrame(xgb_grid_1.cv_results_)\n",
        "results = results.sort_values(by='mean_test_score', ascending=False)\n",
        "results.head()\n",
        "\n",
        "# 다시 Core parameter 설정!\n",
        "best_xgb_model = xgb_grid_1.best_estimator_\n",
        "xgb_params_2 = {\n",
        "    'learning_rate' : [0.01, 0.05, 0.07, 0.1, 0.2],\n",
        "    'n_estimators' : [n for n in range(100,200,20)]\n",
        "}\n",
        "xgb_grid_2 = GridSearchCV(best_xgb_model, param_grid=xgb_params_2, scoring=my_scorer, cv=5, verbose=1)\n",
        "xgb_grid_2.fit(train[features], train['Survived'])\n",
        "\n",
        "# 제일 좋은 모델 뽑기\n",
        "print(\"Best Score : {}\".format(xgb_grid_2.best_score_))\n",
        "print(\"Best Params : {}\".format(xgb_grid_2.best_params_))\n",
        "best_xgb_model = xgb_grid_2.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sxs7kF6P0PE",
        "colab_type": "text"
      },
      "source": [
        "# 0. Machine learning: Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x49TXSDwJfl",
        "colab_type": "text"
      },
      "source": [
        "## Clustering이란....?\n",
        "\n",
        "- 대표적인 비지도학습. 집단이 주어지지 않은 데이터에 군집을 부여해주는 것\n",
        "- 방법은 크게 3개. Hierarchical clustering / K-means clustering / KNN clustering\n",
        "  - Hierarchical Clustering: Connectivity method를 활용하여 Bottom-Up 방식으로 덴드로그램을 그려주고 거기서 주관에 의해서 적절한 군집 갯수를 찾는 방식. 큰 데이터에는 적용하기 힘들다.\n",
        "    - 거리측정 방식: https://datascienceschool.net/view-notebook/094bcb7b86574711a2e8d81f26bce2f5/\n",
        "  - K-means Clustering: Centroid 방식을 활용하여 주어진 갯수에 맞게 군집을 나눠준다.\n",
        "\n",
        "  - KNN Clustering: 패턴 인식에서 분류나 회귀에 사용되는 비모수 방식이다. 데이터의 지역 구조에 민감하다. 쉽게 구현이 되나 계산량이 많다. 매우 일관성 있는 결과를 도출해낸다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkNfAwhWs9Ft",
        "colab_type": "text"
      },
      "source": [
        "### K-means 예시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzRP-a7MpJgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Kmeans 예시1\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "X = np.array([[1, 2], [1, 4], [1, 0],\n",
        "               [10, 2], [10, 4], [10, 0]])\n",
        "\n",
        "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)  # 2개의 cluster로 나눠라\n",
        "\n",
        "kmeans.labels_    # 각 데이터에 대한 클러스터 결과물\n",
        "# array([1, 1, 1, 0, 0, 0], dtype=int32)\n",
        "\n",
        "kmeans.predict([[0, 0], [12, 3]])\n",
        "# array([1, 0], dtype=int32)\n",
        "\n",
        "kmeans.cluster_centers_\n",
        "#array([[10.,  2.], [ 1.,  2.]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnxM7Z25pJnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Kmeans 예시2\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "df = pd.DataFrame([\n",
        "        [2, 1],\n",
        "        [3, 2],\n",
        "        [3, 4],\n",
        "        [5, 5],\n",
        "        [7, 5],\n",
        "        [2, 5],\n",
        "        [8, 9],\n",
        "        [9, 10],\n",
        "        [6, 12]\n",
        "    ], columns=['hour', 'attendance'])\n",
        "\n",
        "model = KMeans(n_clusters=3)\n",
        "\n",
        "model.fit(df)\n",
        "\n",
        "y_predict = model.fit_predict(df)\n",
        "print(y_predict) \n",
        "#[0 0 0 2 2 0 1 1 1]\n",
        "\n",
        "df['cluster'] = y_predict\n",
        "print(df)\n",
        "'''\n",
        "   hour  attendance  cluster\n",
        "0     2           1        0\n",
        "1     3           2        0\n",
        "2     3           4        0\n",
        "3     5           5        2\n",
        "4     7           5        2\n",
        "5     2           5        0\n",
        "6     8           9        1\n",
        "7     9          10        1\n",
        "8     6          12        1\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txB_GvvbtBcP",
        "colab_type": "text"
      },
      "source": [
        "### Hierarchical 예시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7g8_3TRrtTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hierarchical clustering 예시1 (by.sklearn)\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "cluster = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
        "cluster.fit_predict(X)\n",
        "\n",
        "print(cluster.labels_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzvUimTusCly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hierarchical clustering 예시2 (실제 data로 응용하는 법)\n",
        "import scipy.cluster.hierarchy as shc\n",
        "data = customer_data.iloc[:, 3:5].values    # iloc 의미, 전체 row와 3~4번째 column의 값을 nparray 형식으로 반환\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.title(\"Customer Dendograms\")\n",
        "dend = shc.dendrogram(shc.linkage(data, method='ward'))    # dendrogram에서 적정 군집 수를 파악하고\n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "cluster = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')    # 그 군집 수를 적용시켜줌\n",
        "cluster.fit_predict(data)\n",
        "\n",
        "print(cluster.labels_)\n",
        "\n",
        "# scatter plot 그리기\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(data[:,0], data[:,1], c=cluster.labels_, cmap='rainbow')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IVPcgSmrIyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hierarchical clustering 예시3\n",
        "linked = linkage(X, 'single')\n",
        "\n",
        "labelList = range(1, 11)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "dendrogram(linked,\n",
        "            orientation='top',\n",
        "            labels=labelList,\n",
        "            distance_sort='descending',\n",
        "            show_leaf_counts=True)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}